{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import VeryAccurateEmulator as VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Autoencoder-based Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3409e-05 - val_loss: 3.0435e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.4857e-06 - val_loss: 9.8906e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8862e-07 - val_loss: 5.0691e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4312e-07 - val_loss: 3.7318e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.8335e-07 - val_loss: 7.2117e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3169e-07 - val_loss: 2.3646e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1440e-07 - val_loss: 2.0770e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9720e-07 - val_loss: 1.7297e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6479e-07 - val_loss: 1.5201e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9887e-07 - val_loss: 1.9381e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4507e-07 - val_loss: 4.2765e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6389e-07 - val_loss: 1.8494e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7719e-07 - val_loss: 1.5588e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1430e-07 - val_loss: 1.1559e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0194e-07 - val_loss: 1.2826e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1943e-07 - val_loss: 1.5306e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0309e-07 - val_loss: 8.2783e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0916e-07 - val_loss: 1.4314e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.9532e-08 - val_loss: 1.0058e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1883e-07 - val_loss: 9.9538e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.7060e-08 - val_loss: 8.5167e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0484e-08 - val_loss: 7.4423e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9946e-08 - val_loss: 6.3504e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.1388e-07 - val_loss: 7.2122e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.1981e-08 - val_loss: 5.5731e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.3546e-08 - val_loss: 5.1403e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0943e-08 - val_loss: 6.9493e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0873e-08 - val_loss: 2.2990e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5065e-08 - val_loss: 4.4974e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.3258e-08 - val_loss: 5.3239e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2288e-08 - val_loss: 4.6439e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8656e-08 - val_loss: 9.6750e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5300e-08 - val_loss: 6.3924e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4696e-08 - val_loss: 5.0657e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5159e-08 - val_loss: 3.7453e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0046e-08 - val_loss: 3.6782e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.5705e-08 - val_loss: 3.3507e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5101e-08 - val_loss: 3.6174e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4676e-08 - val_loss: 5.2825e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7635e-08 - val_loss: 3.9662e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7118e-08 - val_loss: 3.1206e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7555e-08 - val_loss: 3.1696e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1010e-08 - val_loss: 3.2829e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2938e-08 - val_loss: 6.5438e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4421e-08 - val_loss: 2.9156e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2991e-08 - val_loss: 4.3138e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9017e-08 - val_loss: 2.7067e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6922e-08 - val_loss: 2.8041e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6602e-08 - val_loss: 2.7521e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6413e-08 - val_loss: 2.7408e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6431e-08 - val_loss: 2.6736e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4757e-08 - val_loss: 2.4164e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4419e-08 - val_loss: 2.4075e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3648e-08 - val_loss: 2.3893e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3802e-08 - val_loss: 2.4152e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6229e-08 - val_loss: 3.4407e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5344e-08 - val_loss: 2.4064e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2899e-08 - val_loss: 2.2936e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3638e-08 - val_loss: 2.4215e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2147e-08 - val_loss: 2.2268e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2148e-08 - val_loss: 2.3386e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2145e-08 - val_loss: 2.1419e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1250e-08 - val_loss: 2.1768e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1156e-08 - val_loss: 2.1139e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0809e-08 - val_loss: 2.1331e-08 - lr: 0.0053\n",
      "Epoch 66/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0932e-08 - val_loss: 2.1119e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0547e-08 - val_loss: 2.0785e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0209e-08 - val_loss: 2.1169e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0086e-08 - val_loss: 1.9781e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9741e-08 - val_loss: 2.0088e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9692e-08 - val_loss: 1.9994e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9838e-08 - val_loss: 1.9660e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9476e-08 - val_loss: 2.0101e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9782e-08 - val_loss: 1.9722e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9403e-08 - val_loss: 1.8892e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9069e-08 - val_loss: 1.9120e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8895e-08 - val_loss: 1.8758e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8784e-08 - val_loss: 1.9044e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8759e-08 - val_loss: 1.8779e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8589e-08 - val_loss: 1.8674e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8528e-08 - val_loss: 1.8432e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8247e-08 - val_loss: 1.8230e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8174e-08 - val_loss: 1.8174e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8092e-08 - val_loss: 1.8311e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8120e-08 - val_loss: 1.8022e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7895e-08 - val_loss: 1.8097e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7710e-08 - val_loss: 1.7782e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7596e-08 - val_loss: 1.7777e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7707e-08 - val_loss: 1.7673e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7665e-08 - val_loss: 1.7651e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7301e-08 - val_loss: 1.7250e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7295e-08 - val_loss: 1.7420e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7301e-08 - val_loss: 1.7594e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7207e-08 - val_loss: 1.7270e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7115e-08 - val_loss: 1.7267e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7017e-08 - val_loss: 1.7077e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6963e-08 - val_loss: 1.7254e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6919e-08 - val_loss: 1.6893e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6902e-08 - val_loss: 1.6865e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6812e-08 - val_loss: 1.6926e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6726e-08 - val_loss: 1.6655e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6559e-08 - val_loss: 1.6916e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6585e-08 - val_loss: 1.6631e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6560e-08 - val_loss: 1.6564e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6434e-08 - val_loss: 1.6505e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6363e-08 - val_loss: 1.6502e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6325e-08 - val_loss: 1.6512e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6315e-08 - val_loss: 1.6345e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6295e-08 - val_loss: 1.6487e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6218e-08 - val_loss: 1.6321e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6154e-08 - val_loss: 1.6215e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6088e-08 - val_loss: 1.6113e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6078e-08 - val_loss: 1.6077e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5994e-08 - val_loss: 1.6094e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6013e-08 - val_loss: 1.6062e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5949e-08 - val_loss: 1.5973e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5877e-08 - val_loss: 1.5879e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5883e-08 - val_loss: 1.5939e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5832e-08 - val_loss: 1.5857e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5786e-08 - val_loss: 1.5851e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5712e-08 - val_loss: 1.5825e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5705e-08 - val_loss: 1.5770e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5695e-08 - val_loss: 1.5756e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5672e-08 - val_loss: 1.5757e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5632e-08 - val_loss: 1.5695e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5593e-08 - val_loss: 1.5639e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5578e-08 - val_loss: 1.5610e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5545e-08 - val_loss: 1.5618e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5517e-08 - val_loss: 1.5589e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5488e-08 - val_loss: 1.5506e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5454e-08 - val_loss: 1.5515e-08 - lr: 0.0014\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5414e-08 - val_loss: 1.5475e-08 - lr: 0.0014\n",
      "Epoch 133/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5385e-08 - val_loss: 1.5504e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5394e-08 - val_loss: 1.5502e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5362e-08 - val_loss: 1.5460e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5337e-08 - val_loss: 1.5384e-08 - lr: 0.0012\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5298e-08 - val_loss: 1.5345e-08 - lr: 0.0012\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5267e-08 - val_loss: 1.5330e-08 - lr: 0.0012\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5253e-08 - val_loss: 1.5370e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5248e-08 - val_loss: 1.5320e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5218e-08 - val_loss: 1.5273e-08 - lr: 0.0011\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5201e-08 - val_loss: 1.5233e-08 - lr: 0.0011\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5168e-08 - val_loss: 1.5223e-08 - lr: 0.0011\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5175e-08 - val_loss: 1.5244e-08 - lr: 0.0011\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5131e-08 - val_loss: 1.5181e-08 - lr: 0.0011\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4069 - val_loss: 0.2018 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1358 - val_loss: 0.0970 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0727 - val_loss: 0.0500 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0485 - val_loss: 0.0393 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0535 - val_loss: 0.0305 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0371 - val_loss: 0.0248 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0293 - val_loss: 0.0324 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0349 - val_loss: 0.0838 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0451 - val_loss: 0.0316 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0195 - val_loss: 0.0198 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0301 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0221 - val_loss: 0.0681 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0446 - val_loss: 0.2393 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0660 - val_loss: 0.0149 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0110 - val_loss: 0.0077 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0220 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0133 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0126 - val_loss: 0.0161 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0343 - val_loss: 0.0890 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0270 - val_loss: 0.0210 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0120 - val_loss: 0.0161 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0120 - val_loss: 0.0063 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.0097 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0180 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0620 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0317 - val_loss: 0.0141 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0064 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0055 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0065 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0064 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0097 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0046 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0070 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0089 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0075 - val_loss: 0.0088 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0051 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0100 - val_loss: 0.0086 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0082 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0093 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0260 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0094 - val_loss: 0.0202 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0045 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0087 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0090 - val_loss: 0.0130 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0054 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0036 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0037 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0084 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0040 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0126 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0040 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0075 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0042 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 0.0043\n",
      "Epoch 59/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0083 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0026 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0071 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048 - lr: 0.0039\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0043 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0078 - lr: 0.0035\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0031 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0034 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0035 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0032 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0050 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0036 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0023 - lr: 0.0019\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0017\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0021 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6386e-04 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0020 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0019 - lr: 0.0014\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6322e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0019 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8842e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6694e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9920e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0626e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7654e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0321e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2736e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0974e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 9.8477e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3857e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2428e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3900e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8972e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6404e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1062e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2752e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0645e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9974e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6686e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5390e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4700e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8858e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9012e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7814e-04 - val_loss: 0.0014 - lr: 7.1790e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5299e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3938e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8322e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1629e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2227e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0106e-04 - val_loss: 0.0010 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1838e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9632e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9942e-04 - val_loss: 9.8999e-04 - lr: 5.8150e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9457e-04 - val_loss: 0.0010 - lr: 5.8150e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7410e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8234e-04 - val_loss: 9.8073e-04 - lr: 5.2335e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8136e-04 - val_loss: 9.7130e-04 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9094e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1889e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8123e-04 - val_loss: 9.5462e-04 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5150e-04 - val_loss: 9.5709e-04 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6399e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6956e-04 - val_loss: 9.5820e-04 - lr: 4.7101e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7466e-04 - val_loss: 9.9131e-04 - lr: 4.7101e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4048e-04 - val_loss: 8.9938e-04 - lr: 4.2391e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1646e-04 - val_loss: 9.9029e-04 - lr: 4.2391e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2563e-04 - val_loss: 9.4387e-04 - lr: 4.2391e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1290e-04 - val_loss: 9.3783e-04 - lr: 4.2391e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2147e-04 - val_loss: 9.2279e-04 - lr: 4.2391e-04\n",
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0372e-04 - val_loss: 9.1024e-04 - lr: 3.8152e-04\n",
      "Epoch 173/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2273e-04 - val_loss: 9.3776e-04 - lr: 3.8152e-04\n",
      "Epoch 174/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0046e-04 - val_loss: 9.1428e-04 - lr: 3.8152e-04\n",
      "Epoch 175/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9827e-04 - val_loss: 9.3130e-04 - lr: 3.8152e-04\n",
      "Epoch 176/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2598e-04 - val_loss: 9.1752e-04 - lr: 3.8152e-04\n",
      "Epoch 177/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8747e-04 - val_loss: 9.0346e-04 - lr: 3.4337e-04\n",
      "Epoch 178/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9803e-04 - val_loss: 9.2910e-04 - lr: 3.4337e-04\n",
      "Epoch 179/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9266e-04 - val_loss: 9.2746e-04 - lr: 3.4337e-04\n",
      "Epoch 180/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9166e-04 - val_loss: 9.1692e-04 - lr: 3.4337e-04\n",
      "Epoch 181/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8302e-04 - val_loss: 9.0943e-04 - lr: 3.4337e-04\n",
      "Epoch 182/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7061e-04 - val_loss: 8.9411e-04 - lr: 3.0903e-04\n",
      "Early Stopping\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5398e-05 - val_loss: 2.8402e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5995e-06 - val_loss: 9.7375e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4049e-07 - val_loss: 5.7748e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7594e-07 - val_loss: 3.8943e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5528e-07 - val_loss: 6.5228e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0918e-07 - val_loss: 2.3598e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4395e-07 - val_loss: 2.5345e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0759e-07 - val_loss: 1.6651e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6522e-07 - val_loss: 2.0493e-07 - lr: 0.0100\n",
      "Epoch 10/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9760e-07 - val_loss: 1.5364e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2843e-07 - val_loss: 1.2144e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3542e-07 - val_loss: 2.4471e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6309e-07 - val_loss: 3.5652e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3401e-07 - val_loss: 9.2994e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8591e-08 - val_loss: 8.6792e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3282e-08 - val_loss: 9.4025e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1809e-07 - val_loss: 8.6778e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7413e-08 - val_loss: 8.8058e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.3057e-08 - val_loss: 1.0004e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8794e-08 - val_loss: 6.8590e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2970e-08 - val_loss: 6.4647e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4104e-07 - val_loss: 6.1817e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6723e-07 - val_loss: 8.1580e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8601e-08 - val_loss: 6.2409e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5871e-08 - val_loss: 5.6346e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4514e-08 - val_loss: 5.2111e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8590e-08 - val_loss: 4.9337e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.9998e-08 - val_loss: 4.7665e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0929e-08 - val_loss: 4.5693e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3785e-08 - val_loss: 4.7893e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6700e-08 - val_loss: 8.6216e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3976e-07 - val_loss: 5.9760e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4944e-08 - val_loss: 4.1531e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9191e-08 - val_loss: 3.9138e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6880e-08 - val_loss: 3.7647e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6083e-08 - val_loss: 3.5182e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4385e-08 - val_loss: 3.5947e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3991e-08 - val_loss: 3.3402e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2735e-08 - val_loss: 3.2117e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2063e-08 - val_loss: 3.2570e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1561e-08 - val_loss: 3.0788e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9768e-08 - val_loss: 2.9961e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0607e-08 - val_loss: 3.0521e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8887e-08 - val_loss: 2.9384e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9769e-08 - val_loss: 3.0158e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8092e-08 - val_loss: 2.8375e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7999e-08 - val_loss: 2.9078e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6860e-08 - val_loss: 2.7110e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5963e-08 - val_loss: 2.6186e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5822e-08 - val_loss: 2.6782e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5910e-08 - val_loss: 2.5555e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4817e-08 - val_loss: 2.5319e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4175e-08 - val_loss: 2.4902e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4247e-08 - val_loss: 2.4584e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3885e-08 - val_loss: 2.4005e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3570e-08 - val_loss: 2.3587e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3215e-08 - val_loss: 2.3460e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2868e-08 - val_loss: 2.3841e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2513e-08 - val_loss: 2.2984e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2190e-08 - val_loss: 2.2444e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1890e-08 - val_loss: 2.2016e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1589e-08 - val_loss: 2.2438e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1855e-08 - val_loss: 2.1887e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1111e-08 - val_loss: 2.1181e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1078e-08 - val_loss: 2.1309e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0819e-08 - val_loss: 2.1222e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0638e-08 - val_loss: 2.0866e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0589e-08 - val_loss: 2.0908e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0118e-08 - val_loss: 2.0304e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0153e-08 - val_loss: 2.0410e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9975e-08 - val_loss: 1.9951e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9857e-08 - val_loss: 1.9878e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9718e-08 - val_loss: 2.0239e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9629e-08 - val_loss: 1.9714e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9298e-08 - val_loss: 1.9445e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9111e-08 - val_loss: 1.9287e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9646e-08 - val_loss: 1.9467e-08 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8748e-08 - val_loss: 1.9035e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8729e-08 - val_loss: 1.9022e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8625e-08 - val_loss: 1.8765e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8494e-08 - val_loss: 1.9325e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8606e-08 - val_loss: 1.8468e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8129e-08 - val_loss: 1.8395e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8026e-08 - val_loss: 1.8087e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7973e-08 - val_loss: 1.8214e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7862e-08 - val_loss: 1.8488e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7783e-08 - val_loss: 1.7851e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7638e-08 - val_loss: 1.7789e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7512e-08 - val_loss: 1.7747e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7514e-08 - val_loss: 1.7637e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7394e-08 - val_loss: 1.7505e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7251e-08 - val_loss: 1.7574e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7177e-08 - val_loss: 1.7421e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7066e-08 - val_loss: 1.7300e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6992e-08 - val_loss: 1.7177e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6957e-08 - val_loss: 1.7139e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6915e-08 - val_loss: 1.7052e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6789e-08 - val_loss: 1.6919e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6720e-08 - val_loss: 1.6957e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6635e-08 - val_loss: 1.6763e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6617e-08 - val_loss: 1.6772e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6575e-08 - val_loss: 1.6650e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6436e-08 - val_loss: 1.6662e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6439e-08 - val_loss: 1.6801e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6395e-08 - val_loss: 1.6510e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6347e-08 - val_loss: 1.6682e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6275e-08 - val_loss: 1.6342e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6171e-08 - val_loss: 1.6392e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6106e-08 - val_loss: 1.6337e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6082e-08 - val_loss: 1.6207e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6025e-08 - val_loss: 1.6212e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6015e-08 - val_loss: 1.6167e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5929e-08 - val_loss: 1.6089e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5896e-08 - val_loss: 1.6099e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5898e-08 - val_loss: 1.6041e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5819e-08 - val_loss: 1.6057e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5830e-08 - val_loss: 1.5944e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5704e-08 - val_loss: 1.5976e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5663e-08 - val_loss: 1.5880e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5665e-08 - val_loss: 1.5966e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5624e-08 - val_loss: 1.5731e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5606e-08 - val_loss: 1.5796e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5554e-08 - val_loss: 1.5705e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5507e-08 - val_loss: 1.5766e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5461e-08 - val_loss: 1.5733e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5451e-08 - val_loss: 1.5696e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5416e-08 - val_loss: 1.5592e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5388e-08 - val_loss: 1.5585e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5363e-08 - val_loss: 1.5526e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5328e-08 - val_loss: 1.5517e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5309e-08 - val_loss: 1.5480e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5248e-08 - val_loss: 1.5495e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5244e-08 - val_loss: 1.5426e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5235e-08 - val_loss: 1.5402e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5186e-08 - val_loss: 1.5391e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5180e-08 - val_loss: 1.5388e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5146e-08 - val_loss: 1.5372e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5127e-08 - val_loss: 1.5352e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2172 - val_loss: 0.1952 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1362 - val_loss: 0.1798 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0802 - val_loss: 0.0488 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0496 - val_loss: 0.0469 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0538 - val_loss: 0.0579 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0350 - val_loss: 0.0336 - lr: 0.0100\n",
      "Epoch 7/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0303 - val_loss: 0.0354 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0234 - val_loss: 0.0194 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0555 - val_loss: 0.0222 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0251 - val_loss: 0.0232 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0263 - val_loss: 0.0182 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0290 - val_loss: 0.0291 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0194 - val_loss: 0.0112 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.0089 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0353 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0123 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0188 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0084 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0121 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0120 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0146 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0088 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0094 - val_loss: 0.0108 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0058 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0104 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0120 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0101 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0148 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0246 - val_loss: 0.0121 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0053 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0056 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0044 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0123 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0073 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0047 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0066 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0054 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0124 - val_loss: 0.0392 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.0130 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0052 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0061 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.0077 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0055 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0052 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0411 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0250 - val_loss: 0.0108 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0028 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0032 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0026 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0026 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0033 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0025 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0054 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0043 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0021 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0049 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0049 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0052 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0040 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0044 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0031 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0041 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0034 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0055 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0028 - lr: 0.0025\n",
      "Early Stopping\n",
      "2\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3346e-05 - val_loss: 3.0563e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6260e-06 - val_loss: 8.9091e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5259e-07 - val_loss: 5.4771e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6516e-07 - val_loss: 3.8391e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.8650e-07 - val_loss: 2.8984e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6051e-07 - val_loss: 2.3159e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5608e-07 - val_loss: 2.0555e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4329e-07 - val_loss: 2.6403e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7360e-07 - val_loss: 1.7410e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7580e-07 - val_loss: 1.6509e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7419e-07 - val_loss: 1.4292e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2691e-07 - val_loss: 1.1761e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.1623e-07 - val_loss: 1.0833e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6017e-07 - val_loss: 4.4781e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2305e-07 - val_loss: 1.6237e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0721e-07 - val_loss: 8.7809e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3222e-08 - val_loss: 1.6311e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2705e-08 - val_loss: 8.3126e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0524e-07 - val_loss: 8.8909e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5527e-08 - val_loss: 1.0862e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.2952e-08 - val_loss: 1.2374e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8523e-08 - val_loss: 5.8784e-08 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6829e-08 - val_loss: 5.7342e-08 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2563e-08 - val_loss: 5.2447e-08 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0286e-08 - val_loss: 5.0385e-08 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4864e-08 - val_loss: 6.8779e-08 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6356e-08 - val_loss: 8.2634e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7778e-07 - val_loss: 9.4985e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4270e-08 - val_loss: 5.2134e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3059e-08 - val_loss: 4.0683e-08 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.0585e-08 - val_loss: 3.9776e-08 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.0102e-08 - val_loss: 3.9923e-08 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8151e-08 - val_loss: 3.8384e-08 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7192e-08 - val_loss: 3.9516e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7487e-08 - val_loss: 3.8410e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5585e-08 - val_loss: 3.6641e-08 - lr: 0.0073\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4555e-08 - val_loss: 3.4788e-08 - lr: 0.0073\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3546e-08 - val_loss: 3.9382e-08 - lr: 0.0073\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3912e-08 - val_loss: 3.4083e-08 - lr: 0.0073\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.5238e-08 - val_loss: 3.3140e-08 - lr: 0.0073\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6986e-08 - val_loss: 3.7543e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1903e-08 - val_loss: 3.1353e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0441e-08 - val_loss: 3.0879e-08 - lr: 0.0066\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9338e-08 - val_loss: 2.9800e-08 - lr: 0.0066\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9240e-08 - val_loss: 2.9027e-08 - lr: 0.0066\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0658e-08 - val_loss: 3.0283e-08 - lr: 0.0066\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8220e-08 - val_loss: 2.7610e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8642e-08 - val_loss: 2.7883e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7352e-08 - val_loss: 2.7344e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7898e-08 - val_loss: 2.7471e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6220e-08 - val_loss: 2.6658e-08 - lr: 0.0059\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5836e-08 - val_loss: 2.5589e-08 - lr: 0.0059\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5261e-08 - val_loss: 2.5469e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5250e-08 - val_loss: 2.5831e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5021e-08 - val_loss: 2.5183e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4535e-08 - val_loss: 2.5179e-08 - lr: 0.0053\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3923e-08 - val_loss: 2.3880e-08 - lr: 0.0053\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3602e-08 - val_loss: 2.4977e-08 - lr: 0.0053\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3499e-08 - val_loss: 2.3668e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3178e-08 - val_loss: 2.3528e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3146e-08 - val_loss: 2.3015e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3022e-08 - val_loss: 2.3525e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2340e-08 - val_loss: 2.2643e-08 - lr: 0.0048\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2311e-08 - val_loss: 2.3762e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2307e-08 - val_loss: 2.2257e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1732e-08 - val_loss: 2.2252e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1779e-08 - val_loss: 2.1856e-08 - lr: 0.0048\n",
      "Epoch 68/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1276e-08 - val_loss: 2.1525e-08 - lr: 0.0043\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1280e-08 - val_loss: 2.1584e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1047e-08 - val_loss: 2.1420e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0948e-08 - val_loss: 2.1250e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0678e-08 - val_loss: 2.1557e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0466e-08 - val_loss: 2.0807e-08 - lr: 0.0039\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0388e-08 - val_loss: 2.0370e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0269e-08 - val_loss: 2.0398e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0149e-08 - val_loss: 2.0321e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9919e-08 - val_loss: 2.0351e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9772e-08 - val_loss: 1.9863e-08 - lr: 0.0035\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9561e-08 - val_loss: 2.0048e-08 - lr: 0.0035\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9535e-08 - val_loss: 2.0016e-08 - lr: 0.0035\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9469e-08 - val_loss: 1.9673e-08 - lr: 0.0035\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9293e-08 - val_loss: 1.9441e-08 - lr: 0.0035\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9122e-08 - val_loss: 1.9234e-08 - lr: 0.0031\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9009e-08 - val_loss: 1.9103e-08 - lr: 0.0031\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8995e-08 - val_loss: 1.9218e-08 - lr: 0.0031\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8909e-08 - val_loss: 1.9141e-08 - lr: 0.0031\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8822e-08 - val_loss: 1.8923e-08 - lr: 0.0031\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8681e-08 - val_loss: 1.8825e-08 - lr: 0.0028\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8555e-08 - val_loss: 1.8769e-08 - lr: 0.0028\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8443e-08 - val_loss: 1.8610e-08 - lr: 0.0028\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8388e-08 - val_loss: 1.8591e-08 - lr: 0.0028\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8421e-08 - val_loss: 1.8619e-08 - lr: 0.0028\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8302e-08 - val_loss: 1.8321e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8155e-08 - val_loss: 1.8383e-08 - lr: 0.0025\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8067e-08 - val_loss: 1.8247e-08 - lr: 0.0025\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7972e-08 - val_loss: 1.8111e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7937e-08 - val_loss: 1.8103e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7898e-08 - val_loss: 1.8000e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7754e-08 - val_loss: 1.7875e-08 - lr: 0.0023\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7710e-08 - val_loss: 1.7936e-08 - lr: 0.0023\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7665e-08 - val_loss: 1.7724e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7603e-08 - val_loss: 1.7787e-08 - lr: 0.0023\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7533e-08 - val_loss: 1.7634e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7465e-08 - val_loss: 1.7686e-08 - lr: 0.0021\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7439e-08 - val_loss: 1.7595e-08 - lr: 0.0021\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7367e-08 - val_loss: 1.7535e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7317e-08 - val_loss: 1.7522e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7274e-08 - val_loss: 1.7452e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7223e-08 - val_loss: 1.7398e-08 - lr: 0.0019\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7157e-08 - val_loss: 1.7303e-08 - lr: 0.0019\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7128e-08 - val_loss: 1.7267e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7057e-08 - val_loss: 1.7164e-08 - lr: 0.0019\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7015e-08 - val_loss: 1.7181e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6967e-08 - val_loss: 1.7174e-08 - lr: 0.0017\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6962e-08 - val_loss: 1.7077e-08 - lr: 0.0017\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6903e-08 - val_loss: 1.7068e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6867e-08 - val_loss: 1.7075e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6832e-08 - val_loss: 1.6939e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6765e-08 - val_loss: 1.6941e-08 - lr: 0.0015\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6758e-08 - val_loss: 1.6889e-08 - lr: 0.0015\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6714e-08 - val_loss: 1.6855e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6685e-08 - val_loss: 1.6806e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6633e-08 - val_loss: 1.6784e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6593e-08 - val_loss: 1.6744e-08 - lr: 0.0014\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6546e-08 - val_loss: 1.6690e-08 - lr: 0.0014\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6545e-08 - val_loss: 1.6675e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6493e-08 - val_loss: 1.6649e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6491e-08 - val_loss: 1.6655e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6442e-08 - val_loss: 1.6605e-08 - lr: 0.0012\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6418e-08 - val_loss: 1.6560e-08 - lr: 0.0012\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6394e-08 - val_loss: 1.6520e-08 - lr: 0.0012\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6362e-08 - val_loss: 1.6491e-08 - lr: 0.0012\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6338e-08 - val_loss: 1.6528e-08 - lr: 0.0012\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6301e-08 - val_loss: 1.6436e-08 - lr: 0.0011\n",
      "Epoch 135/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6296e-08 - val_loss: 1.6392e-08 - lr: 0.0011\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6265e-08 - val_loss: 1.6404e-08 - lr: 0.0011\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6246e-08 - val_loss: 1.6385e-08 - lr: 0.0011\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6219e-08 - val_loss: 1.6352e-08 - lr: 0.0011\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6198e-08 - val_loss: 1.6367e-08 - lr: 9.8477e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6159e-08 - val_loss: 1.6357e-08 - lr: 9.8477e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6134e-08 - val_loss: 1.6299e-08 - lr: 9.8477e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6131e-08 - val_loss: 1.6258e-08 - lr: 9.8477e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6114e-08 - val_loss: 1.6221e-08 - lr: 9.8477e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6071e-08 - val_loss: 1.6211e-08 - lr: 8.8629e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6063e-08 - val_loss: 1.6186e-08 - lr: 8.8629e-04\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0971 - val_loss: 0.2444 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1108 - val_loss: 0.1026 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0888 - val_loss: 0.0620 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0444 - val_loss: 0.0462 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0391 - val_loss: 0.0244 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0295 - val_loss: 0.0314 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0288 - val_loss: 0.0194 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0307 - val_loss: 0.0351 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0355 - val_loss: 0.0292 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0436 - val_loss: 0.0428 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0237 - val_loss: 0.0166 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0149 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0316 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0080 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0094 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0137 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0329 - val_loss: 0.0192 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0200 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0105 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0074 - val_loss: 0.0099 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.0120 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0096 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0274 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0059 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0058 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0062 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0087 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0267 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0293 - val_loss: 0.0104 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0086 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0038 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0040 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0031 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0115 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0080 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0041 - lr: 0.0053\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0059 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0128 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0051 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0040 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0023 - lr: 0.0048\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0062 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0055 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0056 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - val_loss: 0.0048 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0040 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0050 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0066 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0038 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0046 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0033 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0021 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0062 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0103 - lr: 0.0039\n",
      "Epoch 61/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0032 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0055 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0017 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0065 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0031 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0027 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0023\n",
      "Early Stopping\n",
      "3\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2266e-05 - val_loss: 2.8933e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6436e-06 - val_loss: 9.1372e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.9892e-07 - val_loss: 5.3517e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6014e-07 - val_loss: 3.9928e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2590e-07 - val_loss: 2.7424e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8594e-07 - val_loss: 2.3504e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1449e-07 - val_loss: 1.9135e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5510e-07 - val_loss: 1.8947e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4855e-07 - val_loss: 1.4162e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2988e-07 - val_loss: 1.3530e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5123e-07 - val_loss: 1.1186e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1100e-07 - val_loss: 1.0226e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7471e-07 - val_loss: 9.6955e-08 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2513e-08 - val_loss: 8.6159e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5247e-08 - val_loss: 9.6281e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5502e-07 - val_loss: 2.7543e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1595e-07 - val_loss: 7.3432e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0085e-08 - val_loss: 7.3843e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5219e-07 - val_loss: 1.5299e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7199e-08 - val_loss: 8.2280e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2351e-08 - val_loss: 5.7812e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6921e-08 - val_loss: 5.6933e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.7348e-08 - val_loss: 5.3443e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1548e-08 - val_loss: 6.5229e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0509e-08 - val_loss: 6.9622e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3340e-08 - val_loss: 6.7401e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8098e-08 - val_loss: 4.4186e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4897e-08 - val_loss: 4.3375e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1586e-08 - val_loss: 4.5902e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2268e-08 - val_loss: 3.9998e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5770e-08 - val_loss: 4.5727e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6698e-07 - val_loss: 2.9278e-07 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4432e-08 - val_loss: 3.8269e-08 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7713e-08 - val_loss: 3.7938e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5276e-08 - val_loss: 3.5532e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.4303e-08 - val_loss: 3.4414e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3976e-08 - val_loss: 3.4445e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5224e-08 - val_loss: 3.5177e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3654e-08 - val_loss: 3.1545e-08 - lr: 0.0073\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0915e-08 - val_loss: 3.1992e-08 - lr: 0.0073\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1196e-08 - val_loss: 3.1308e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0232e-08 - val_loss: 3.0634e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9906e-08 - val_loss: 3.0263e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9677e-08 - val_loss: 3.0332e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8799e-08 - val_loss: 2.8741e-08 - lr: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8249e-08 - val_loss: 2.8503e-08 - lr: 0.0066\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8314e-08 - val_loss: 2.9594e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7284e-08 - val_loss: 2.8033e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7236e-08 - val_loss: 3.0384e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8363e-08 - val_loss: 2.6918e-08 - lr: 0.0059\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6218e-08 - val_loss: 2.6747e-08 - lr: 0.0059\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5537e-08 - val_loss: 2.5869e-08 - lr: 0.0059\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5398e-08 - val_loss: 2.6302e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5573e-08 - val_loss: 2.5494e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5520e-08 - val_loss: 2.5498e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4651e-08 - val_loss: 2.4773e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4284e-08 - val_loss: 2.4495e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3809e-08 - val_loss: 2.4660e-08 - lr: 0.0053\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3736e-08 - val_loss: 2.4000e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3427e-08 - val_loss: 2.3625e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3409e-08 - val_loss: 2.4053e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3155e-08 - val_loss: 2.3349e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2601e-08 - val_loss: 2.3496e-08 - lr: 0.0048\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2400e-08 - val_loss: 2.3013e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2249e-08 - val_loss: 2.2739e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2040e-08 - val_loss: 2.2484e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2084e-08 - val_loss: 2.2665e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1587e-08 - val_loss: 2.1813e-08 - lr: 0.0043\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1370e-08 - val_loss: 2.2052e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1229e-08 - val_loss: 2.1433e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1017e-08 - val_loss: 2.1412e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1066e-08 - val_loss: 2.2095e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0719e-08 - val_loss: 2.1167e-08 - lr: 0.0039\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0641e-08 - val_loss: 2.0832e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0560e-08 - val_loss: 2.0856e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0319e-08 - val_loss: 2.0630e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0133e-08 - val_loss: 2.0595e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0066e-08 - val_loss: 2.0474e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9975e-08 - val_loss: 2.0340e-08 - lr: 0.0039\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9760e-08 - val_loss: 2.0066e-08 - lr: 0.0035\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9632e-08 - val_loss: 2.0098e-08 - lr: 0.0035\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9530e-08 - val_loss: 1.9940e-08 - lr: 0.0035\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9462e-08 - val_loss: 1.9931e-08 - lr: 0.0035\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9396e-08 - val_loss: 1.9760e-08 - lr: 0.0035\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9195e-08 - val_loss: 1.9679e-08 - lr: 0.0031\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9100e-08 - val_loss: 1.9507e-08 - lr: 0.0031\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9084e-08 - val_loss: 1.9480e-08 - lr: 0.0031\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8887e-08 - val_loss: 1.9243e-08 - lr: 0.0031\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8894e-08 - val_loss: 1.9216e-08 - lr: 0.0031\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8771e-08 - val_loss: 1.9251e-08 - lr: 0.0028\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8665e-08 - val_loss: 1.8981e-08 - lr: 0.0028\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8669e-08 - val_loss: 1.9377e-08 - lr: 0.0028\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8570e-08 - val_loss: 1.8936e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8413e-08 - val_loss: 1.9031e-08 - lr: 0.0028\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8384e-08 - val_loss: 1.8761e-08 - lr: 0.0025\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8265e-08 - val_loss: 1.8535e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8190e-08 - val_loss: 1.8584e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8131e-08 - val_loss: 1.8717e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8071e-08 - val_loss: 1.8551e-08 - lr: 0.0025\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7978e-08 - val_loss: 1.8439e-08 - lr: 0.0023\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7897e-08 - val_loss: 1.8436e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7883e-08 - val_loss: 1.8209e-08 - lr: 0.0023\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7782e-08 - val_loss: 1.8107e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7730e-08 - val_loss: 1.8117e-08 - lr: 0.0023\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7716e-08 - val_loss: 1.7926e-08 - lr: 0.0021\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7624e-08 - val_loss: 1.8026e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7580e-08 - val_loss: 1.7956e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7559e-08 - val_loss: 1.7887e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7469e-08 - val_loss: 1.7800e-08 - lr: 0.0021\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7400e-08 - val_loss: 1.7723e-08 - lr: 0.0019\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7382e-08 - val_loss: 1.7687e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7333e-08 - val_loss: 1.7750e-08 - lr: 0.0019\n",
      "Epoch 113/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7292e-08 - val_loss: 1.7741e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7270e-08 - val_loss: 1.7548e-08 - lr: 0.0019\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7203e-08 - val_loss: 1.7531e-08 - lr: 0.0017\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7126e-08 - val_loss: 1.7510e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7087e-08 - val_loss: 1.7537e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7071e-08 - val_loss: 1.7412e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7068e-08 - val_loss: 1.7397e-08 - lr: 0.0017\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6981e-08 - val_loss: 1.7310e-08 - lr: 0.0015\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6947e-08 - val_loss: 1.7301e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6926e-08 - val_loss: 1.7225e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6875e-08 - val_loss: 1.7234e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6877e-08 - val_loss: 1.7196e-08 - lr: 0.0015\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6808e-08 - val_loss: 1.7153e-08 - lr: 0.0014\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6782e-08 - val_loss: 1.7171e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6754e-08 - val_loss: 1.7149e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6710e-08 - val_loss: 1.7090e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6684e-08 - val_loss: 1.7026e-08 - lr: 0.0014\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6662e-08 - val_loss: 1.6982e-08 - lr: 0.0012\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6645e-08 - val_loss: 1.6914e-08 - lr: 0.0012\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6610e-08 - val_loss: 1.6894e-08 - lr: 0.0012\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6598e-08 - val_loss: 1.6900e-08 - lr: 0.0012\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6565e-08 - val_loss: 1.6869e-08 - lr: 0.0012\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6537e-08 - val_loss: 1.6881e-08 - lr: 0.0011\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6507e-08 - val_loss: 1.6823e-08 - lr: 0.0011\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6474e-08 - val_loss: 1.6790e-08 - lr: 0.0011\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6454e-08 - val_loss: 1.6782e-08 - lr: 0.0011\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6447e-08 - val_loss: 1.6753e-08 - lr: 0.0011\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6398e-08 - val_loss: 1.6716e-08 - lr: 9.8477e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6378e-08 - val_loss: 1.6720e-08 - lr: 9.8477e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6363e-08 - val_loss: 1.6710e-08 - lr: 9.8477e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6334e-08 - val_loss: 1.6664e-08 - lr: 9.8477e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6326e-08 - val_loss: 1.6619e-08 - lr: 9.8477e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6298e-08 - val_loss: 1.6614e-08 - lr: 8.8629e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6272e-08 - val_loss: 1.6580e-08 - lr: 8.8629e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6271e-08 - val_loss: 1.6601e-08 - lr: 8.8629e-04\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2181 - val_loss: 0.2410 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1515 - val_loss: 0.0816 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0654 - val_loss: 0.0498 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0513 - val_loss: 0.0418 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0385 - val_loss: 0.0353 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0301 - val_loss: 0.0368 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0228 - val_loss: 0.0192 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0354 - val_loss: 0.0355 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0273 - val_loss: 0.0164 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0231 - val_loss: 0.0207 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0386 - val_loss: 0.0163 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0134 - val_loss: 0.0100 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0147 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0134 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0210 - val_loss: 0.0344 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0096 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0253 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0158 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0232 - val_loss: 0.0180 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0365 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0103 - val_loss: 0.0065 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0058 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0078 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0312 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0091 - val_loss: 0.0063 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0067 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0059 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0064 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0092 - val_loss: 0.0093 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0121 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 35/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0074 - val_loss: 0.0111 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0088 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0093 - val_loss: 0.0061 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0086 - val_loss: 0.0081 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0115 - val_loss: 0.0081 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0065 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0032 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0128 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0060 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0087 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0042 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0051 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0050 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0033 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0042 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0047 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0036 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0037 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0036 - lr: 0.0043\n",
      "Early Stopping\n",
      "4\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3027e-05 - val_loss: 2.7106e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5148e-06 - val_loss: 8.3609e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0002e-07 - val_loss: 7.9864e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5206e-07 - val_loss: 3.9012e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8672e-07 - val_loss: 3.7063e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9558e-07 - val_loss: 2.4513e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4874e-07 - val_loss: 2.3854e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6311e-07 - val_loss: 2.0113e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5816e-07 - val_loss: 2.3513e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4946e-07 - val_loss: 1.7245e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6631e-07 - val_loss: 1.3873e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2809e-07 - val_loss: 1.3871e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3431e-07 - val_loss: 1.5061e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2438e-07 - val_loss: 1.0424e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5192e-08 - val_loss: 1.0495e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7916e-08 - val_loss: 1.0542e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2333e-07 - val_loss: 1.5222e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0800e-07 - val_loss: 7.5667e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1362e-07 - val_loss: 7.2180e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5675e-08 - val_loss: 1.0827e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3365e-08 - val_loss: 5.7014e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9783e-08 - val_loss: 6.7406e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7898e-07 - val_loss: 1.4699e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.8980e-08 - val_loss: 5.2695e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.4220e-08 - val_loss: 4.8403e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7730e-08 - val_loss: 5.5435e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7686e-08 - val_loss: 5.7041e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4499e-08 - val_loss: 4.6663e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2317e-08 - val_loss: 1.8411e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.7068e-08 - val_loss: 4.2898e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4051e-08 - val_loss: 4.0203e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.7448e-08 - val_loss: 4.3148e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5560e-08 - val_loss: 5.8341e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1197e-08 - val_loss: 5.8883e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5353e-08 - val_loss: 9.1268e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3329e-08 - val_loss: 5.5617e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8323e-08 - val_loss: 3.2997e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6416e-08 - val_loss: 3.9509e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4249e-08 - val_loss: 3.1359e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0734e-08 - val_loss: 3.2123e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6605e-08 - val_loss: 4.7646e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4713e-08 - val_loss: 3.8898e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0848e-08 - val_loss: 2.9501e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8591e-08 - val_loss: 2.9501e-08 - lr: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8596e-08 - val_loss: 2.8722e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7650e-08 - val_loss: 2.7654e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7886e-08 - val_loss: 2.9943e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0587e-08 - val_loss: 2.7771e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4578e-08 - val_loss: 3.6266e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3599e-08 - val_loss: 4.4458e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7969e-08 - val_loss: 2.9408e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5617e-08 - val_loss: 2.4992e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5304e-08 - val_loss: 2.5120e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4672e-08 - val_loss: 2.4937e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6889e-08 - val_loss: 5.0641e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6088e-08 - val_loss: 2.6551e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3471e-08 - val_loss: 2.2798e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2818e-08 - val_loss: 2.2714e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4585e-08 - val_loss: 2.3395e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2482e-08 - val_loss: 2.7640e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5105e-08 - val_loss: 2.3159e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1874e-08 - val_loss: 2.1992e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1574e-08 - val_loss: 2.2199e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1550e-08 - val_loss: 2.1745e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1168e-08 - val_loss: 2.1668e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1235e-08 - val_loss: 2.1172e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1056e-08 - val_loss: 2.1427e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0523e-08 - val_loss: 2.1269e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0383e-08 - val_loss: 2.1205e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0328e-08 - val_loss: 2.0441e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0058e-08 - val_loss: 2.0814e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0081e-08 - val_loss: 2.0537e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9820e-08 - val_loss: 1.9940e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9615e-08 - val_loss: 2.0153e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9532e-08 - val_loss: 1.9972e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9397e-08 - val_loss: 1.9782e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9264e-08 - val_loss: 1.9595e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9041e-08 - val_loss: 1.9312e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9050e-08 - val_loss: 1.9289e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8942e-08 - val_loss: 1.9132e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8786e-08 - val_loss: 1.8960e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8759e-08 - val_loss: 1.8950e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8527e-08 - val_loss: 1.9073e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8427e-08 - val_loss: 1.8785e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8420e-08 - val_loss: 1.8748e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8359e-08 - val_loss: 1.8748e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8321e-08 - val_loss: 1.8667e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8128e-08 - val_loss: 1.8398e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8018e-08 - val_loss: 1.8256e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8003e-08 - val_loss: 1.8215e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7862e-08 - val_loss: 1.8292e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7844e-08 - val_loss: 1.8153e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7694e-08 - val_loss: 1.7847e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7571e-08 - val_loss: 1.7903e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7601e-08 - val_loss: 1.8055e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7474e-08 - val_loss: 1.7835e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7419e-08 - val_loss: 1.7737e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7349e-08 - val_loss: 1.7824e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7368e-08 - val_loss: 1.7609e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7235e-08 - val_loss: 1.7750e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7204e-08 - val_loss: 1.7660e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7147e-08 - val_loss: 1.7379e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7057e-08 - val_loss: 1.7309e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7022e-08 - val_loss: 1.7372e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6937e-08 - val_loss: 1.7248e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6905e-08 - val_loss: 1.7179e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6894e-08 - val_loss: 1.7275e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6805e-08 - val_loss: 1.7234e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6755e-08 - val_loss: 1.7160e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6745e-08 - val_loss: 1.7009e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6704e-08 - val_loss: 1.6943e-08 - lr: 0.0023\n",
      "Epoch 112/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6656e-08 - val_loss: 1.6973e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6623e-08 - val_loss: 1.6909e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6582e-08 - val_loss: 1.6887e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6577e-08 - val_loss: 1.6864e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6521e-08 - val_loss: 1.6801e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6450e-08 - val_loss: 1.6815e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6398e-08 - val_loss: 1.6785e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6422e-08 - val_loss: 1.6660e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6344e-08 - val_loss: 1.6690e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6313e-08 - val_loss: 1.6680e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6263e-08 - val_loss: 1.6750e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6251e-08 - val_loss: 1.6582e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6207e-08 - val_loss: 1.6535e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6198e-08 - val_loss: 1.6493e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6172e-08 - val_loss: 1.6485e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6119e-08 - val_loss: 1.6491e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6080e-08 - val_loss: 1.6453e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6075e-08 - val_loss: 1.6311e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6027e-08 - val_loss: 1.6320e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5988e-08 - val_loss: 1.6342e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5963e-08 - val_loss: 1.6297e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5952e-08 - val_loss: 1.6277e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5911e-08 - val_loss: 1.6207e-08 - lr: 0.0015\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8449 - val_loss: 0.5738 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.3473 - val_loss: 0.1976 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1337 - val_loss: 0.0980 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0838 - val_loss: 0.0581 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0768 - val_loss: 0.0569 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0487 - val_loss: 0.0372 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0347 - val_loss: 0.0416 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0384 - val_loss: 0.0297 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0426 - val_loss: 0.0621 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0345 - val_loss: 0.0276 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0274 - val_loss: 0.0303 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0262 - val_loss: 0.0177 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0303 - val_loss: 0.0209 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0250 - val_loss: 0.0302 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0230 - val_loss: 0.0226 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0232 - val_loss: 0.0192 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0347 - val_loss: 0.0391 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0123 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0106 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0262 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0155 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0128 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0214 - val_loss: 0.0241 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0113 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0153 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0269 - val_loss: 0.0152 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0086 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0149 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0091 - val_loss: 0.0102 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0070 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0128 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0153 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0106 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0106 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0086 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0063 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0096 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0103 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0203 - val_loss: 0.0350 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0113 - val_loss: 0.0077 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0052 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0058 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0054 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0073 - val_loss: 0.0062 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0104 - val_loss: 0.0125 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0054 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0055 - lr: 0.0053\n",
      "Epoch 48/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0063 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0071 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0124 - val_loss: 0.0157 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0048 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0069 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0124 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0091 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0113 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0048 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0058 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0087 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0042 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0061 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0050 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0045 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0060 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0058 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0044 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0047 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0039 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0095 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0065 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0042 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0053 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0042 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0035 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0033 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0048 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0034 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0037 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0048 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0035 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0032 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0033 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0040 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0050 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0057 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0044 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0038 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0029 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0030 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0044 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0026 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0029 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0034 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0037 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0029 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0030 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0026 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0023 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0025 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0027 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0022 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0023 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0027 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0023 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0012\n",
      "Epoch 120/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0012\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0025 - lr: 0.0012\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0021 - lr: 0.0012\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0012\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0012\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0011\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0011\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 0.0011\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0011\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0011\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 9.8477e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0018 - lr: 9.8477e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 9.8477e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 9.8477e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 9.8477e-04\n",
      "Early Stopping\n",
      "5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3514e-05 - val_loss: 2.9236e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5395e-06 - val_loss: 8.8032e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2761e-07 - val_loss: 5.7129e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3355e-07 - val_loss: 4.6942e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7760e-07 - val_loss: 3.1214e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1289e-07 - val_loss: 2.6726e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6934e-07 - val_loss: 2.5781e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0195e-07 - val_loss: 1.8295e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6830e-07 - val_loss: 1.5745e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6274e-07 - val_loss: 1.7623e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1107e-07 - val_loss: 1.2327e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3571e-07 - val_loss: 1.3386e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1933e-07 - val_loss: 1.1083e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0925e-07 - val_loss: 1.4098e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2381e-07 - val_loss: 1.5205e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0786e-07 - val_loss: 8.6748e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4364e-08 - val_loss: 7.9553e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5127e-08 - val_loss: 9.9462e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0796e-07 - val_loss: 3.4571e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3484e-07 - val_loss: 8.2084e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1076e-08 - val_loss: 1.6383e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9408e-08 - val_loss: 6.4017e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4615e-08 - val_loss: 1.3328e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9383e-08 - val_loss: 6.3804e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6414e-08 - val_loss: 5.7608e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3207e-08 - val_loss: 5.3650e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0649e-08 - val_loss: 6.0898e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4696e-07 - val_loss: 1.5269e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1705e-08 - val_loss: 4.6561e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4821e-08 - val_loss: 4.3946e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8363e-08 - val_loss: 4.6000e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6920e-08 - val_loss: 4.5374e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6739e-08 - val_loss: 4.2212e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1513e-08 - val_loss: 2.5004e-07 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6646e-08 - val_loss: 3.7403e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5866e-08 - val_loss: 3.5939e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6358e-08 - val_loss: 3.4977e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8169e-08 - val_loss: 3.4569e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5547e-08 - val_loss: 3.4455e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2827e-08 - val_loss: 3.2670e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3482e-08 - val_loss: 3.1856e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1651e-08 - val_loss: 3.1716e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9779e-08 - val_loss: 3.0423e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1115e-08 - val_loss: 3.7066e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0956e-08 - val_loss: 3.5367e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2208e-08 - val_loss: 3.1234e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7836e-08 - val_loss: 2.8040e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7692e-08 - val_loss: 2.6633e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6732e-08 - val_loss: 2.7682e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6659e-08 - val_loss: 2.5947e-08 - lr: 0.0073\n",
      "Epoch 51/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6931e-08 - val_loss: 2.9620e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8035e-08 - val_loss: 2.8387e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1449e-08 - val_loss: 2.7464e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4641e-08 - val_loss: 2.4570e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3807e-08 - val_loss: 2.3909e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4023e-08 - val_loss: 2.4002e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4371e-08 - val_loss: 3.7581e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4544e-08 - val_loss: 2.3425e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2642e-08 - val_loss: 2.2538e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2377e-08 - val_loss: 2.2905e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2070e-08 - val_loss: 2.2614e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2014e-08 - val_loss: 2.2103e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1562e-08 - val_loss: 2.1904e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1443e-08 - val_loss: 2.2430e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1375e-08 - val_loss: 2.0944e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0998e-08 - val_loss: 2.1003e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0966e-08 - val_loss: 2.0912e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0744e-08 - val_loss: 2.0567e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0611e-08 - val_loss: 2.1024e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0525e-08 - val_loss: 2.0688e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9839e-08 - val_loss: 1.9881e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9865e-08 - val_loss: 1.9548e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9637e-08 - val_loss: 1.9692e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9478e-08 - val_loss: 1.9919e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9431e-08 - val_loss: 1.9386e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9296e-08 - val_loss: 1.9216e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9123e-08 - val_loss: 1.9232e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8856e-08 - val_loss: 1.9311e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8775e-08 - val_loss: 1.9008e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8809e-08 - val_loss: 1.8839e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8473e-08 - val_loss: 1.8465e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8460e-08 - val_loss: 1.8346e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8277e-08 - val_loss: 1.8541e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8192e-08 - val_loss: 1.8493e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8148e-08 - val_loss: 1.8379e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7936e-08 - val_loss: 1.8105e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7844e-08 - val_loss: 1.7912e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7947e-08 - val_loss: 1.8047e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7708e-08 - val_loss: 1.7966e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7664e-08 - val_loss: 1.7702e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7465e-08 - val_loss: 1.7538e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7440e-08 - val_loss: 1.7361e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7286e-08 - val_loss: 1.7419e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7260e-08 - val_loss: 1.7334e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7233e-08 - val_loss: 1.7431e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7088e-08 - val_loss: 1.7151e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6984e-08 - val_loss: 1.7311e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7037e-08 - val_loss: 1.7128e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6935e-08 - val_loss: 1.7045e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6860e-08 - val_loss: 1.7042e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6821e-08 - val_loss: 1.6946e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6701e-08 - val_loss: 1.6777e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6648e-08 - val_loss: 1.6774e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6587e-08 - val_loss: 1.6620e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6557e-08 - val_loss: 1.6676e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6470e-08 - val_loss: 1.6577e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6444e-08 - val_loss: 1.6576e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6393e-08 - val_loss: 1.6566e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6357e-08 - val_loss: 1.6558e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6333e-08 - val_loss: 1.6420e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6254e-08 - val_loss: 1.6322e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6208e-08 - val_loss: 1.6278e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6159e-08 - val_loss: 1.6274e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6127e-08 - val_loss: 1.6224e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6084e-08 - val_loss: 1.6241e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6072e-08 - val_loss: 1.6125e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6009e-08 - val_loss: 1.6091e-08 - lr: 0.0019\n",
      "Epoch 118/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5951e-08 - val_loss: 1.6062e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5955e-08 - val_loss: 1.5999e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5896e-08 - val_loss: 1.5978e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5830e-08 - val_loss: 1.5926e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5839e-08 - val_loss: 1.5894e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5778e-08 - val_loss: 1.5848e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5774e-08 - val_loss: 1.5857e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5727e-08 - val_loss: 1.5829e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5712e-08 - val_loss: 1.5799e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5660e-08 - val_loss: 1.5728e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5644e-08 - val_loss: 1.5720e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5618e-08 - val_loss: 1.5655e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5596e-08 - val_loss: 1.5695e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5570e-08 - val_loss: 1.5720e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5535e-08 - val_loss: 1.5673e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5501e-08 - val_loss: 1.5554e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5468e-08 - val_loss: 1.5551e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5460e-08 - val_loss: 1.5498e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5438e-08 - val_loss: 1.5517e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5407e-08 - val_loss: 1.5426e-08 - lr: 0.0012\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5390e-08 - val_loss: 1.5481e-08 - lr: 0.0012\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5355e-08 - val_loss: 1.5439e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5346e-08 - val_loss: 1.5396e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5317e-08 - val_loss: 1.5391e-08 - lr: 0.0012\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5293e-08 - val_loss: 1.5362e-08 - lr: 0.0011\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2078 - val_loss: 0.1847 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1302 - val_loss: 0.0640 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0610 - val_loss: 0.0470 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0647 - val_loss: 0.0430 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0337 - val_loss: 0.0499 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0390 - val_loss: 0.0763 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0251 - val_loss: 0.0564 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0331 - val_loss: 0.0263 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0124 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0357 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0159 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0218 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0231 - val_loss: 0.0304 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0231 - val_loss: 0.0381 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0109 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0075 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.0089 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0241 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.0103 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0097 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0118 - val_loss: 0.0113 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0077 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0275 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0208 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0114 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0040 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0075 - val_loss: 0.0076 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0078 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0104 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0075 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0109 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0043 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0073 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0071 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0107 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0110 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0057 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0057 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0055 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0030 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0054 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0048 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0078 - val_loss: 0.0060 - lr: 0.0053\n",
      "Epoch 46/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0073 - val_loss: 0.0165 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0027 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0044 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0060 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0043 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0029 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0052 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0037 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0024 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0031 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0031 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0046 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0035 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0112 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0031 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0036 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0025 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0014 - lr: 0.0017\n",
      "Early Stopping\n",
      "6\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2731e-05 - val_loss: 2.6341e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6034e-06 - val_loss: 8.9606e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7175e-07 - val_loss: 5.1849e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7535e-07 - val_loss: 3.8279e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9406e-07 - val_loss: 3.1393e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6286e-07 - val_loss: 2.3372e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2323e-07 - val_loss: 2.2058e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1093e-07 - val_loss: 1.6895e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5274e-07 - val_loss: 2.4904e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5923e-07 - val_loss: 2.1214e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4724e-07 - val_loss: 1.1970e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2434e-07 - val_loss: 1.1548e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3404e-07 - val_loss: 1.0895e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1792e-07 - val_loss: 2.5779e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3922e-07 - val_loss: 1.0992e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8937e-08 - val_loss: 7.9331e-08 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1734e-07 - val_loss: 3.7345e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1772e-07 - val_loss: 7.7168e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1330e-08 - val_loss: 1.4908e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9754e-08 - val_loss: 7.2004e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3089e-07 - val_loss: 9.1824e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0948e-07 - val_loss: 1.1872e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9696e-08 - val_loss: 8.8434e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7571e-08 - val_loss: 5.9003e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4669e-08 - val_loss: 7.9080e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7723e-08 - val_loss: 5.2819e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6522e-07 - val_loss: 3.0175e-07 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8546e-08 - val_loss: 5.7442e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4494e-08 - val_loss: 5.1507e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9653e-08 - val_loss: 4.7835e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6890e-08 - val_loss: 4.7012e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4480e-08 - val_loss: 5.6023e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5705e-08 - val_loss: 4.2411e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3133e-08 - val_loss: 4.6490e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3596e-08 - val_loss: 4.6863e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2539e-08 - val_loss: 4.9267e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.0263e-08 - val_loss: 3.7957e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7373e-08 - val_loss: 3.7039e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6080e-08 - val_loss: 3.5086e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5568e-08 - val_loss: 3.4826e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5803e-08 - val_loss: 3.6977e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9929e-08 - val_loss: 3.9433e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2748e-08 - val_loss: 3.2966e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2355e-08 - val_loss: 3.2442e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1768e-08 - val_loss: 3.2422e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0919e-08 - val_loss: 3.0082e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9893e-08 - val_loss: 3.1017e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1074e-08 - val_loss: 2.9746e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0645e-08 - val_loss: 3.0420e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8582e-08 - val_loss: 2.8304e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8214e-08 - val_loss: 2.8222e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8030e-08 - val_loss: 2.7636e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9935e-08 - val_loss: 2.7968e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2417e-08 - val_loss: 2.6939e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7046e-08 - val_loss: 2.6685e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7083e-08 - val_loss: 3.3269e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8167e-08 - val_loss: 3.4165e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9620e-08 - val_loss: 2.8530e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6759e-08 - val_loss: 2.5783e-08 - lr: 0.0073\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5224e-08 - val_loss: 2.5124e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4828e-08 - val_loss: 2.4795e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4613e-08 - val_loss: 2.4930e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5128e-08 - val_loss: 2.5822e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4664e-08 - val_loss: 2.5658e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3747e-08 - val_loss: 2.5064e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5233e-08 - val_loss: 2.4656e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3673e-08 - val_loss: 2.3474e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3155e-08 - val_loss: 2.3274e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3254e-08 - val_loss: 2.3994e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3018e-08 - val_loss: 2.2623e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2421e-08 - val_loss: 2.2512e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2282e-08 - val_loss: 2.2505e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2544e-08 - val_loss: 2.2528e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2029e-08 - val_loss: 2.1852e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2137e-08 - val_loss: 2.3372e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1828e-08 - val_loss: 2.2119e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1834e-08 - val_loss: 2.1568e-08 - lr: 0.0053\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1605e-08 - val_loss: 2.1739e-08 - lr: 0.0053\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1268e-08 - val_loss: 2.1591e-08 - lr: 0.0053\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1127e-08 - val_loss: 2.3784e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1456e-08 - val_loss: 2.1125e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1207e-08 - val_loss: 2.1328e-08 - lr: 0.0048\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0718e-08 - val_loss: 2.1197e-08 - lr: 0.0048\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0805e-08 - val_loss: 2.0820e-08 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0378e-08 - val_loss: 2.0305e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0242e-08 - val_loss: 2.0152e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0172e-08 - val_loss: 2.0212e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0149e-08 - val_loss: 2.0467e-08 - lr: 0.0043\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0116e-08 - val_loss: 2.0186e-08 - lr: 0.0043\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9888e-08 - val_loss: 1.9975e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9764e-08 - val_loss: 1.9893e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9643e-08 - val_loss: 1.9583e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9653e-08 - val_loss: 1.9788e-08 - lr: 0.0039\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9538e-08 - val_loss: 1.9421e-08 - lr: 0.0039\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9368e-08 - val_loss: 1.9552e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9320e-08 - val_loss: 1.9310e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9139e-08 - val_loss: 1.9201e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9114e-08 - val_loss: 1.9162e-08 - lr: 0.0035\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9099e-08 - val_loss: 1.9290e-08 - lr: 0.0035\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8980e-08 - val_loss: 1.9215e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8896e-08 - val_loss: 1.9029e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8881e-08 - val_loss: 1.9004e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8768e-08 - val_loss: 1.8794e-08 - lr: 0.0031\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8695e-08 - val_loss: 1.8665e-08 - lr: 0.0031\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8590e-08 - val_loss: 1.8622e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8538e-08 - val_loss: 1.8643e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8447e-08 - val_loss: 1.8505e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8444e-08 - val_loss: 1.8602e-08 - lr: 0.0028\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8383e-08 - val_loss: 1.8394e-08 - lr: 0.0028\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8338e-08 - val_loss: 1.8329e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8249e-08 - val_loss: 1.8330e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8203e-08 - val_loss: 1.8233e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8175e-08 - val_loss: 1.8150e-08 - lr: 0.0025\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8158e-08 - val_loss: 1.8152e-08 - lr: 0.0025\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8044e-08 - val_loss: 1.8076e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8006e-08 - val_loss: 1.8156e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7956e-08 - val_loss: 1.8040e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7934e-08 - val_loss: 1.8017e-08 - lr: 0.0023\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7908e-08 - val_loss: 1.7988e-08 - lr: 0.0023\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7816e-08 - val_loss: 1.7947e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7737e-08 - val_loss: 1.7918e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7749e-08 - val_loss: 1.7957e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7711e-08 - val_loss: 1.7721e-08 - lr: 0.0021\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7672e-08 - val_loss: 1.7692e-08 - lr: 0.0021\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7597e-08 - val_loss: 1.7628e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7604e-08 - val_loss: 1.7772e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7556e-08 - val_loss: 1.7705e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7509e-08 - val_loss: 1.7569e-08 - lr: 0.0019\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7498e-08 - val_loss: 1.7588e-08 - lr: 0.0019\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7443e-08 - val_loss: 1.7554e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7411e-08 - val_loss: 1.7531e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7393e-08 - val_loss: 1.7447e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7371e-08 - val_loss: 1.7462e-08 - lr: 0.0017\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7366e-08 - val_loss: 1.7435e-08 - lr: 0.0017\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7322e-08 - val_loss: 1.7418e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7278e-08 - val_loss: 1.7336e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7240e-08 - val_loss: 1.7340e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7212e-08 - val_loss: 1.7329e-08 - lr: 0.0015\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7218e-08 - val_loss: 1.7318e-08 - lr: 0.0015\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7170e-08 - val_loss: 1.7287e-08 - lr: 0.0014\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7159e-08 - val_loss: 1.7188e-08 - lr: 0.0014\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7123e-08 - val_loss: 1.7176e-08 - lr: 0.0014\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7092e-08 - val_loss: 1.7155e-08 - lr: 0.0014\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7085e-08 - val_loss: 1.7157e-08 - lr: 0.0014\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7068e-08 - val_loss: 1.7102e-08 - lr: 0.0012\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7033e-08 - val_loss: 1.7122e-08 - lr: 0.0012\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7002e-08 - val_loss: 1.7113e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2887 - val_loss: 0.2067 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1237 - val_loss: 0.0600 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0538 - val_loss: 0.0553 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0396 - val_loss: 0.0296 - lr: 0.0100\n",
      "Epoch 5/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0457 - val_loss: 0.0311 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0548 - val_loss: 0.0758 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0432 - val_loss: 0.0187 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0517 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.0288 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0120 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0123 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0218 - val_loss: 0.0741 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0369 - val_loss: 0.0461 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0194 - val_loss: 0.0111 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0124 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0128 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0085 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0148 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0249 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0344 - val_loss: 0.0287 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0100 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.0053 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0045 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0093 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0164 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0134 - val_loss: 0.0119 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0245 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0073 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0069 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0087 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0071 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0115 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0046 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0054 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0086 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0072 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0102 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - val_loss: 0.0076 - lr: 0.0059\n",
      "Early Stopping\n",
      "7\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4818e-05 - val_loss: 2.7102e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5257e-06 - val_loss: 9.4072e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2121e-07 - val_loss: 5.2321e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8901e-07 - val_loss: 4.0740e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8850e-07 - val_loss: 4.1041e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8945e-07 - val_loss: 2.4670e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6094e-07 - val_loss: 2.3864e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0653e-07 - val_loss: 2.0224e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6530e-07 - val_loss: 7.0997e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3288e-07 - val_loss: 1.5008e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7831e-07 - val_loss: 1.3411e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2760e-07 - val_loss: 1.2866e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6316e-07 - val_loss: 2.2820e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1184e-07 - val_loss: 1.2581e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0687e-07 - val_loss: 9.5696e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9965e-08 - val_loss: 8.7996e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1893e-08 - val_loss: 1.2468e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8539e-07 - val_loss: 8.8171e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0252e-08 - val_loss: 7.7279e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2184e-08 - val_loss: 7.6073e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8167e-08 - val_loss: 1.7322e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9956e-08 - val_loss: 6.3362e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0314e-08 - val_loss: 7.0766e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6894e-08 - val_loss: 3.5646e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4613e-07 - val_loss: 6.6100e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2460e-07 - val_loss: 1.2671e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.2302e-08 - val_loss: 6.0514e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9030e-08 - val_loss: 4.9859e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6974e-08 - val_loss: 4.7223e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7640e-08 - val_loss: 4.8080e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5054e-08 - val_loss: 4.4645e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4613e-08 - val_loss: 5.8731e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3016e-08 - val_loss: 4.5432e-08 - lr: 0.0090\n",
      "Epoch 34/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4305e-08 - val_loss: 5.8966e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3276e-08 - val_loss: 4.2310e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7341e-08 - val_loss: 2.1804e-07 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5692e-08 - val_loss: 3.8862e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6299e-08 - val_loss: 3.6883e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6119e-08 - val_loss: 3.7648e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4988e-08 - val_loss: 3.6690e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5115e-08 - val_loss: 3.8178e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5391e-08 - val_loss: 3.3678e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4407e-08 - val_loss: 3.5872e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9726e-08 - val_loss: 4.8271e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0057e-08 - val_loss: 3.5494e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2479e-08 - val_loss: 3.7408e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6811e-08 - val_loss: 3.3592e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9804e-08 - val_loss: 2.9946e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9218e-08 - val_loss: 3.0306e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0096e-08 - val_loss: 2.9972e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9028e-08 - val_loss: 3.0918e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9443e-08 - val_loss: 3.1233e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7443e-08 - val_loss: 2.8354e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7223e-08 - val_loss: 2.7366e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6386e-08 - val_loss: 2.6892e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7248e-08 - val_loss: 2.6749e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6979e-08 - val_loss: 2.6731e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5845e-08 - val_loss: 3.3149e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6895e-08 - val_loss: 2.5868e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4786e-08 - val_loss: 2.6917e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5025e-08 - val_loss: 2.5814e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5078e-08 - val_loss: 2.5476e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4341e-08 - val_loss: 2.5060e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3898e-08 - val_loss: 2.4915e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3823e-08 - val_loss: 2.4317e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4180e-08 - val_loss: 2.4109e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3419e-08 - val_loss: 2.3687e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3498e-08 - val_loss: 2.4612e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2820e-08 - val_loss: 2.2906e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2934e-08 - val_loss: 2.3047e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2545e-08 - val_loss: 2.2921e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2262e-08 - val_loss: 2.2821e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2159e-08 - val_loss: 2.3001e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2207e-08 - val_loss: 2.2581e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1701e-08 - val_loss: 2.2004e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1641e-08 - val_loss: 2.2001e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1430e-08 - val_loss: 2.1998e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1311e-08 - val_loss: 2.1572e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1151e-08 - val_loss: 2.1976e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0966e-08 - val_loss: 2.1562e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0896e-08 - val_loss: 2.1448e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0852e-08 - val_loss: 2.1280e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1242e-08 - val_loss: 2.0905e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0592e-08 - val_loss: 2.1609e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0372e-08 - val_loss: 2.0760e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0371e-08 - val_loss: 2.0452e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0124e-08 - val_loss: 2.0377e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0089e-08 - val_loss: 2.0511e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0054e-08 - val_loss: 2.0763e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9928e-08 - val_loss: 2.0246e-08 - lr: 0.0031\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9770e-08 - val_loss: 2.0148e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9715e-08 - val_loss: 2.0101e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9689e-08 - val_loss: 1.9862e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9536e-08 - val_loss: 2.0061e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9412e-08 - val_loss: 1.9875e-08 - lr: 0.0028\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9329e-08 - val_loss: 1.9732e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9272e-08 - val_loss: 1.9633e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9242e-08 - val_loss: 1.9488e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9139e-08 - val_loss: 1.9385e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9029e-08 - val_loss: 1.9543e-08 - lr: 0.0025\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8985e-08 - val_loss: 1.9409e-08 - lr: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8923e-08 - val_loss: 1.9393e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8911e-08 - val_loss: 1.9198e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8847e-08 - val_loss: 1.9395e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8717e-08 - val_loss: 1.9110e-08 - lr: 0.0023\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8715e-08 - val_loss: 1.9051e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8640e-08 - val_loss: 1.9190e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8570e-08 - val_loss: 1.9025e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8534e-08 - val_loss: 1.8854e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8465e-08 - val_loss: 1.8786e-08 - lr: 0.0021\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8378e-08 - val_loss: 1.8773e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8363e-08 - val_loss: 1.8778e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8358e-08 - val_loss: 1.8685e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8293e-08 - val_loss: 1.8681e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8186e-08 - val_loss: 1.8644e-08 - lr: 0.0019\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8183e-08 - val_loss: 1.8434e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8135e-08 - val_loss: 1.8443e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8086e-08 - val_loss: 1.8447e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8067e-08 - val_loss: 1.8398e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8007e-08 - val_loss: 1.8354e-08 - lr: 0.0017\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7989e-08 - val_loss: 1.8339e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7981e-08 - val_loss: 1.8226e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7906e-08 - val_loss: 1.8195e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7913e-08 - val_loss: 1.8282e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7806e-08 - val_loss: 1.8106e-08 - lr: 0.0015\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7762e-08 - val_loss: 1.8132e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7774e-08 - val_loss: 1.8120e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7737e-08 - val_loss: 1.8127e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7719e-08 - val_loss: 1.8026e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7662e-08 - val_loss: 1.7988e-08 - lr: 0.0014\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7639e-08 - val_loss: 1.7963e-08 - lr: 0.0014\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7587e-08 - val_loss: 1.7940e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7582e-08 - val_loss: 1.7874e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7553e-08 - val_loss: 1.7868e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7537e-08 - val_loss: 1.7861e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7498e-08 - val_loss: 1.7810e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7497e-08 - val_loss: 1.7769e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7461e-08 - val_loss: 1.7783e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7421e-08 - val_loss: 1.7721e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7409e-08 - val_loss: 1.7714e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4073 - val_loss: 0.2427 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1376 - val_loss: 0.0704 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0607 - val_loss: 0.0602 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0413 - val_loss: 0.0348 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0336 - val_loss: 0.0256 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0516 - val_loss: 0.0698 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0399 - val_loss: 0.0204 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0196 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0329 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0370 - val_loss: 0.0149 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0191 - val_loss: 0.0147 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0229 - val_loss: 0.0105 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0178 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0154 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.0161 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0124 - val_loss: 0.0108 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0114 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0203 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0111 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0342 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0358 - val_loss: 0.0293 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0111 - val_loss: 0.0083 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0103 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0071 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0064 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0103 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0074 - val_loss: 0.0076 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0072 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0084 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - val_loss: 0.0066 - lr: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0094 - val_loss: 0.0084 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0055 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0086 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0099 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0039 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0091 - val_loss: 0.0183 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0095 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0090 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - val_loss: 0.0048 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0045 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0030 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0074 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0165 - lr: 0.0059\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0161 - lr: 0.0059\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0038 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0079 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0108 - val_loss: 0.0044 - lr: 0.0053\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0057 - lr: 0.0053\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0033 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0070 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0055 - lr: 0.0048\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048 - lr: 0.0048\n",
      "Early Stopping\n",
      "8\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3326e-05 - val_loss: 2.5718e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6537e-06 - val_loss: 1.3973e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9625e-07 - val_loss: 5.7491e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8697e-07 - val_loss: 4.1567e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.0706e-07 - val_loss: 3.0733e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7104e-07 - val_loss: 2.5031e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3532e-07 - val_loss: 2.1873e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9164e-07 - val_loss: 1.9176e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8479e-07 - val_loss: 1.6058e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0093e-07 - val_loss: 2.2533e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4165e-07 - val_loss: 1.2160e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.2430e-07 - val_loss: 1.5247e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.3645e-07 - val_loss: 1.1520e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9457e-07 - val_loss: 1.1251e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0073e-07 - val_loss: 9.7459e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8925e-08 - val_loss: 8.0649e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1440e-07 - val_loss: 2.3852e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0885e-07 - val_loss: 7.3052e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8767e-08 - val_loss: 7.2140e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9376e-08 - val_loss: 7.7309e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7955e-08 - val_loss: 6.5165e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3247e-08 - val_loss: 1.7876e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0381e-07 - val_loss: 7.7454e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.3414e-08 - val_loss: 1.1003e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.1134e-08 - val_loss: 5.3358e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.1625e-08 - val_loss: 5.3882e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.4052e-08 - val_loss: 1.0445e-07 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5725e-07 - val_loss: 5.2084e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6450e-08 - val_loss: 4.6695e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4254e-07 - val_loss: 6.6090e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8016e-08 - val_loss: 6.3308e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4731e-08 - val_loss: 1.2276e-07 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9684e-08 - val_loss: 8.1047e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3736e-08 - val_loss: 3.9623e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9870e-08 - val_loss: 3.7975e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.8410e-08 - val_loss: 3.6601e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.7686e-08 - val_loss: 3.8456e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4629e-08 - val_loss: 3.5904e-08 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7384e-08 - val_loss: 8.9653e-08 - lr: 0.0100\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4994e-08 - val_loss: 3.4498e-08 - lr: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.2157e-08 - val_loss: 3.4082e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.5081e-08 - val_loss: 3.3400e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.5352e-08 - val_loss: 3.6968e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0576e-08 - val_loss: 2.9946e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1101e-08 - val_loss: 3.7390e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9133e-08 - val_loss: 2.7301e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7453e-08 - val_loss: 2.6983e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8185e-08 - val_loss: 2.7554e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7349e-08 - val_loss: 2.8418e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0010e-07 - val_loss: 8.5726e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.8880e-08 - val_loss: 2.7129e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5135e-08 - val_loss: 2.6387e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4909e-08 - val_loss: 2.4532e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4269e-08 - val_loss: 2.4736e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4052e-08 - val_loss: 2.4237e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4370e-08 - val_loss: 3.0968e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3479e-08 - val_loss: 2.2936e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3137e-08 - val_loss: 2.4489e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2564e-08 - val_loss: 2.2860e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2234e-08 - val_loss: 2.3292e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2262e-08 - val_loss: 2.3123e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1834e-08 - val_loss: 2.2031e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1516e-08 - val_loss: 2.1617e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1082e-08 - val_loss: 2.1231e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0978e-08 - val_loss: 2.1225e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0706e-08 - val_loss: 2.1052e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0888e-08 - val_loss: 2.1215e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0404e-08 - val_loss: 2.0514e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0106e-08 - val_loss: 2.0155e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0177e-08 - val_loss: 2.0219e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9739e-08 - val_loss: 2.0275e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9757e-08 - val_loss: 1.9516e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9495e-08 - val_loss: 1.9286e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9106e-08 - val_loss: 1.9343e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8940e-08 - val_loss: 1.8894e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8928e-08 - val_loss: 1.8939e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8901e-08 - val_loss: 1.9062e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8592e-08 - val_loss: 1.8866e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8503e-08 - val_loss: 1.8876e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8305e-08 - val_loss: 1.8462e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8249e-08 - val_loss: 1.8250e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8073e-08 - val_loss: 1.8207e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8016e-08 - val_loss: 1.8126e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7833e-08 - val_loss: 1.7849e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7807e-08 - val_loss: 1.8019e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7773e-08 - val_loss: 1.7784e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7653e-08 - val_loss: 1.7929e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7497e-08 - val_loss: 1.7554e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7430e-08 - val_loss: 1.7621e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7438e-08 - val_loss: 1.7297e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7250e-08 - val_loss: 1.7402e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7271e-08 - val_loss: 1.7201e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7005e-08 - val_loss: 1.7186e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6950e-08 - val_loss: 1.7150e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6917e-08 - val_loss: 1.6966e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6914e-08 - val_loss: 1.6870e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6803e-08 - val_loss: 1.6818e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6723e-08 - val_loss: 1.6772e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6669e-08 - val_loss: 1.6779e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6619e-08 - val_loss: 1.6909e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6574e-08 - val_loss: 1.6659e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6467e-08 - val_loss: 1.6722e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6370e-08 - val_loss: 1.6537e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6364e-08 - val_loss: 1.6614e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6359e-08 - val_loss: 1.6294e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6166e-08 - val_loss: 1.6270e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6142e-08 - val_loss: 1.6230e-08 - lr: 0.0025\n",
      "Epoch 108/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6126e-08 - val_loss: 1.6280e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6078e-08 - val_loss: 1.6184e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6027e-08 - val_loss: 1.6081e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5946e-08 - val_loss: 1.6115e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5911e-08 - val_loss: 1.5939e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5874e-08 - val_loss: 1.5971e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5794e-08 - val_loss: 1.5943e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5760e-08 - val_loss: 1.6024e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5724e-08 - val_loss: 1.5863e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5708e-08 - val_loss: 1.5750e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5630e-08 - val_loss: 1.5741e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5608e-08 - val_loss: 1.5681e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5559e-08 - val_loss: 1.5689e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5510e-08 - val_loss: 1.5594e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5494e-08 - val_loss: 1.5662e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5415e-08 - val_loss: 1.5543e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5399e-08 - val_loss: 1.5553e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5385e-08 - val_loss: 1.5484e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5340e-08 - val_loss: 1.5444e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5323e-08 - val_loss: 1.5395e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5291e-08 - val_loss: 1.5399e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5248e-08 - val_loss: 1.5338e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5224e-08 - val_loss: 1.5291e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5157e-08 - val_loss: 1.5368e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5142e-08 - val_loss: 1.5266e-08 - lr: 0.0015\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2891 - val_loss: 0.2157 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1460 - val_loss: 0.1379 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0949 - val_loss: 0.0535 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0535 - val_loss: 0.0660 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0406 - val_loss: 0.0236 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0326 - val_loss: 0.0277 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0256 - val_loss: 0.0282 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0401 - val_loss: 0.0339 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0386 - val_loss: 0.0593 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0277 - val_loss: 0.0192 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0195 - val_loss: 0.0151 - lr: 0.0090\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0118 - lr: 0.0090\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0162 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0196 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0132 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0128 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0156 - lr: 0.0081\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0201 - val_loss: 0.0186 - lr: 0.0081\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0118 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0117 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0231 - val_loss: 0.0594 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0224 - val_loss: 0.0107 - lr: 0.0073\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0063 - lr: 0.0073\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0171 - lr: 0.0073\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0085 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0335 - val_loss: 0.0404 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0222 - val_loss: 0.0135 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0113 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0060 - lr: 0.0066\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0058 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0046 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0064 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0167 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.0051 - lr: 0.0059\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0051 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0063 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0070 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0065 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0073 - lr: 0.0053\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0074 - lr: 0.0053\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0092 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0052 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0131 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0069 - lr: 0.0048\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 46/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0076 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0046 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0064 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0046 - lr: 0.0043\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0044 - lr: 0.0043\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0037 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0073 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0129 - val_loss: 0.0162 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0043 - lr: 0.0039\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0039 - lr: 0.0039\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0048 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0124 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0138 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0048 - lr: 0.0031\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0037 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0050 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0038 - lr: 0.0028\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0037 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0040 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0039 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0045 - lr: 0.0023\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0030 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0021\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0025 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0025 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0019\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0028 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0022 - lr: 0.0017\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0024 - lr: 0.0017\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 0.0017\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0024 - lr: 0.0015\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0023 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0019 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0014\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0014\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0022 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1532e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4268e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0011\n",
      "Epoch 118/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0022 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5084e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9392e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8103e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0835e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1174e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2226e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0140e-04 - val_loss: 0.0015 - lr: 8.8629e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9945e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.5730e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4825e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7574e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6669e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1205e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3455e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6381e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8702e-04 - val_loss: 0.0013 - lr: 7.1790e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9842e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8816e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7412e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8199e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6310e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3231e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4929e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7888e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 6.5659e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6658e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5976e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7387e-04 - val_loss: 0.0014 - lr: 5.8150e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6375e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6808e-04 - val_loss: 0.0012 - lr: 5.2335e-04\n",
      "Early Stopping\n",
      "9\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3658e-05 - val_loss: 3.1260e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6323e-06 - val_loss: 9.7575e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6906e-07 - val_loss: 6.4246e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.2348e-07 - val_loss: 4.1373e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7207e-07 - val_loss: 3.8709e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1678e-07 - val_loss: 2.7297e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5537e-07 - val_loss: 2.1191e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0423e-07 - val_loss: 1.8509e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8831e-07 - val_loss: 3.5334e-06 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8206e-07 - val_loss: 1.6788e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4593e-07 - val_loss: 1.3628e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2715e-07 - val_loss: 1.2106e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1490e-07 - val_loss: 1.1873e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0582e-07 - val_loss: 1.0466e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9045e-08 - val_loss: 9.7052e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0460e-08 - val_loss: 8.8581e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3231e-08 - val_loss: 9.2116e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3597e-08 - val_loss: 7.9759e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4723e-08 - val_loss: 8.1587e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1323e-08 - val_loss: 6.6934e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9288e-08 - val_loss: 6.9083e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9866e-08 - val_loss: 8.2704e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7942e-08 - val_loss: 6.3222e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.1551e-08 - val_loss: 6.0293e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0667e-08 - val_loss: 7.2129e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1352e-07 - val_loss: 6.7178e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1294e-08 - val_loss: 5.9959e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1166e-08 - val_loss: 5.1437e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9021e-08 - val_loss: 4.6679e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8821e-08 - val_loss: 2.4674e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1542e-07 - val_loss: 5.8415e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.4259e-08 - val_loss: 4.2250e-08 - lr: 0.0100\n",
      "Epoch 33/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1723e-08 - val_loss: 4.7783e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.5391e-08 - val_loss: 5.0428e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5780e-08 - val_loss: 4.0770e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0281e-08 - val_loss: 4.0092e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3149e-08 - val_loss: 3.6701e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7855e-08 - val_loss: 4.0250e-08 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7116e-08 - val_loss: 3.8498e-08 - lr: 0.0100\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2799e-07 - val_loss: 3.2362e-07 - lr: 0.0100\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2898e-07 - val_loss: 4.0909e-08 - lr: 0.0100\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3900e-08 - val_loss: 3.6288e-08 - lr: 0.0100\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3640e-08 - val_loss: 4.0559e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1705e-08 - val_loss: 3.0404e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0624e-08 - val_loss: 2.9900e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0097e-08 - val_loss: 2.9737e-08 - lr: 0.0090\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9382e-08 - val_loss: 2.9687e-08 - lr: 0.0090\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9053e-08 - val_loss: 3.0092e-08 - lr: 0.0090\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8474e-08 - val_loss: 2.7594e-08 - lr: 0.0090\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7298e-08 - val_loss: 2.7895e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6853e-08 - val_loss: 2.6876e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6367e-08 - val_loss: 2.6805e-08 - lr: 0.0081\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5861e-08 - val_loss: 2.6627e-08 - lr: 0.0081\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5889e-08 - val_loss: 2.5546e-08 - lr: 0.0081\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4885e-08 - val_loss: 2.5372e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4696e-08 - val_loss: 2.4615e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4769e-08 - val_loss: 2.4519e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4124e-08 - val_loss: 2.4155e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4611e-08 - val_loss: 2.4223e-08 - lr: 0.0073\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4068e-08 - val_loss: 2.4501e-08 - lr: 0.0073\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3170e-08 - val_loss: 2.3062e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3006e-08 - val_loss: 2.3367e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2564e-08 - val_loss: 2.3170e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2419e-08 - val_loss: 2.4522e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2742e-08 - val_loss: 2.2025e-08 - lr: 0.0066\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1564e-08 - val_loss: 2.2025e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1349e-08 - val_loss: 2.1606e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1081e-08 - val_loss: 2.1316e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0915e-08 - val_loss: 2.1288e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0899e-08 - val_loss: 2.0886e-08 - lr: 0.0059\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0424e-08 - val_loss: 2.0524e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0418e-08 - val_loss: 2.0347e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0303e-08 - val_loss: 2.0543e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9947e-08 - val_loss: 2.0457e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0144e-08 - val_loss: 1.9934e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9844e-08 - val_loss: 2.0429e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9769e-08 - val_loss: 1.9532e-08 - lr: 0.0053\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9282e-08 - val_loss: 1.9340e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9133e-08 - val_loss: 1.9104e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9078e-08 - val_loss: 1.9568e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8966e-08 - val_loss: 1.9118e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8857e-08 - val_loss: 1.8930e-08 - lr: 0.0048\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8663e-08 - val_loss: 1.8640e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8540e-08 - val_loss: 1.8686e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8384e-08 - val_loss: 1.8445e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8250e-08 - val_loss: 1.8804e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8324e-08 - val_loss: 1.8420e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8001e-08 - val_loss: 1.8135e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7925e-08 - val_loss: 1.8188e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7874e-08 - val_loss: 1.8006e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7761e-08 - val_loss: 1.7783e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7687e-08 - val_loss: 1.7981e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7572e-08 - val_loss: 1.7563e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7441e-08 - val_loss: 1.7538e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7459e-08 - val_loss: 1.7701e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7369e-08 - val_loss: 1.7600e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7249e-08 - val_loss: 1.7369e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7142e-08 - val_loss: 1.7334e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6997e-08 - val_loss: 1.7096e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6950e-08 - val_loss: 1.7139e-08 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6890e-08 - val_loss: 1.7107e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6825e-08 - val_loss: 1.6900e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6723e-08 - val_loss: 1.6811e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6728e-08 - val_loss: 1.6801e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6650e-08 - val_loss: 1.6791e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6558e-08 - val_loss: 1.6757e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6511e-08 - val_loss: 1.6611e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6447e-08 - val_loss: 1.6671e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6386e-08 - val_loss: 1.6534e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6325e-08 - val_loss: 1.6426e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6293e-08 - val_loss: 1.6482e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6248e-08 - val_loss: 1.6352e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6164e-08 - val_loss: 1.6392e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6111e-08 - val_loss: 1.6289e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6089e-08 - val_loss: 1.6215e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6044e-08 - val_loss: 1.6104e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5986e-08 - val_loss: 1.6098e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5939e-08 - val_loss: 1.6148e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5901e-08 - val_loss: 1.6047e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5869e-08 - val_loss: 1.5956e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5824e-08 - val_loss: 1.6000e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5783e-08 - val_loss: 1.5895e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5731e-08 - val_loss: 1.5863e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5704e-08 - val_loss: 1.5846e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5654e-08 - val_loss: 1.5783e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5626e-08 - val_loss: 1.5763e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5612e-08 - val_loss: 1.5757e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5557e-08 - val_loss: 1.5688e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5512e-08 - val_loss: 1.5663e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5480e-08 - val_loss: 1.5607e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5472e-08 - val_loss: 1.5576e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5427e-08 - val_loss: 1.5590e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5403e-08 - val_loss: 1.5570e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5370e-08 - val_loss: 1.5479e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5345e-08 - val_loss: 1.5531e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5329e-08 - val_loss: 1.5463e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5301e-08 - val_loss: 1.5426e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5248e-08 - val_loss: 1.5414e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5246e-08 - val_loss: 1.5396e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4017 - val_loss: 0.2134 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1370 - val_loss: 0.0620 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0617 - val_loss: 0.0759 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0514 - val_loss: 0.0471 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0475 - val_loss: 0.0519 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0355 - val_loss: 0.0228 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0245 - val_loss: 0.0246 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0560 - val_loss: 0.0403 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0173 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.0292 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0265 - val_loss: 0.0263 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0413 - val_loss: 0.1019 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0314 - val_loss: 0.0307 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0121 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0115 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0211 - val_loss: 0.0356 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0216 - val_loss: 0.0124 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0152 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0130 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0153 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.0257 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.0100 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0108 - val_loss: 0.0102 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0147 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0114 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0052 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0084 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0111 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0124 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0105 - lr: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0169 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0069 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0047 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0217 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0223 - val_loss: 0.0112 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0073 - val_loss: 0.0049 - lr: 0.0073\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0055 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0033 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0055 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0191 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0123 - lr: 0.0066\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0038 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0060 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0065 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0132 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0048 - lr: 0.0059\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0059 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0053 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0075 - lr: 0.0053\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0061 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0046 - lr: 0.0048\n",
      "Early Stopping\n",
      "10\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3008e-05 - val_loss: 3.1684e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6531e-06 - val_loss: 8.9545e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8974e-07 - val_loss: 6.0893e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1847e-07 - val_loss: 6.1212e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.0989e-07 - val_loss: 3.2430e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1648e-07 - val_loss: 2.9148e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1627e-07 - val_loss: 3.8108e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4740e-07 - val_loss: 2.2162e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1812e-07 - val_loss: 1.7995e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7492e-07 - val_loss: 1.8497e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8967e-07 - val_loss: 1.3607e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3875e-07 - val_loss: 1.3308e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2804e-07 - val_loss: 1.3207e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7282e-07 - val_loss: 1.8069e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3032e-07 - val_loss: 1.6544e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7615e-07 - val_loss: 9.5624e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9693e-08 - val_loss: 9.5570e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6340e-08 - val_loss: 8.4510e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7427e-08 - val_loss: 1.2919e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9411e-07 - val_loss: 1.0512e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6823e-08 - val_loss: 6.8318e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9915e-08 - val_loss: 6.8188e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4216e-08 - val_loss: 6.3794e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3715e-08 - val_loss: 8.2659e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0983e-08 - val_loss: 5.9529e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2024e-08 - val_loss: 9.3649e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4285e-08 - val_loss: 7.0336e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3589e-08 - val_loss: 5.9940e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4551e-08 - val_loss: 8.1896e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9134e-08 - val_loss: 5.8032e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8744e-08 - val_loss: 4.7485e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5081e-08 - val_loss: 4.4216e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2807e-08 - val_loss: 4.3814e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5925e-08 - val_loss: 4.9517e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4253e-08 - val_loss: 5.5931e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6483e-08 - val_loss: 4.6829e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1427e-08 - val_loss: 3.9053e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9298e-08 - val_loss: 3.8317e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7894e-08 - val_loss: 3.7374e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8109e-08 - val_loss: 3.6216e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6445e-08 - val_loss: 3.9493e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.7072e-08 - val_loss: 3.8396e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 3.9199e-08 - val_loss: 3.6240e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 3.4050e-08 - val_loss: 3.4400e-08 - lr: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4681e-08 - val_loss: 3.3723e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3005e-08 - val_loss: 3.7307e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3593e-08 - val_loss: 3.4355e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3396e-08 - val_loss: 3.3169e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3605e-08 - val_loss: 3.5440e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2457e-08 - val_loss: 3.0513e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2409e-08 - val_loss: 2.9557e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0217e-08 - val_loss: 3.0186e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9599e-08 - val_loss: 2.8810e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9224e-08 - val_loss: 2.9961e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9139e-08 - val_loss: 3.0436e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7843e-08 - val_loss: 2.8147e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7962e-08 - val_loss: 2.7704e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7506e-08 - val_loss: 2.7754e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7349e-08 - val_loss: 2.6726e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6312e-08 - val_loss: 2.6595e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9266e-08 - val_loss: 3.7668e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7148e-08 - val_loss: 2.5783e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5855e-08 - val_loss: 2.5984e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5275e-08 - val_loss: 2.6580e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5884e-08 - val_loss: 2.5640e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5076e-08 - val_loss: 2.5385e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4644e-08 - val_loss: 2.5141e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4717e-08 - val_loss: 2.5180e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4361e-08 - val_loss: 2.4360e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4026e-08 - val_loss: 2.4040e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3968e-08 - val_loss: 2.3883e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3559e-08 - val_loss: 2.3566e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3501e-08 - val_loss: 2.3453e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3077e-08 - val_loss: 2.3694e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3172e-08 - val_loss: 2.3940e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2901e-08 - val_loss: 2.3110e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2757e-08 - val_loss: 2.2923e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2783e-08 - val_loss: 2.3190e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2626e-08 - val_loss: 2.2742e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2622e-08 - val_loss: 2.2536e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2275e-08 - val_loss: 2.2269e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2096e-08 - val_loss: 2.2464e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1809e-08 - val_loss: 2.1971e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1713e-08 - val_loss: 2.2093e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1650e-08 - val_loss: 2.1689e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1517e-08 - val_loss: 2.1634e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1243e-08 - val_loss: 2.1219e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1151e-08 - val_loss: 2.1523e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1110e-08 - val_loss: 2.1163e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0958e-08 - val_loss: 2.1030e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0856e-08 - val_loss: 2.0819e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0607e-08 - val_loss: 2.0915e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0604e-08 - val_loss: 2.0610e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0573e-08 - val_loss: 2.0553e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0538e-08 - val_loss: 2.0446e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0334e-08 - val_loss: 2.0563e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0264e-08 - val_loss: 2.0382e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0064e-08 - val_loss: 2.0232e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0061e-08 - val_loss: 2.0364e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0007e-08 - val_loss: 2.0184e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9916e-08 - val_loss: 2.0025e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9757e-08 - val_loss: 1.9903e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9723e-08 - val_loss: 1.9895e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9676e-08 - val_loss: 1.9779e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9582e-08 - val_loss: 1.9639e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9535e-08 - val_loss: 1.9624e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9442e-08 - val_loss: 1.9533e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9338e-08 - val_loss: 1.9469e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9319e-08 - val_loss: 1.9497e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9228e-08 - val_loss: 1.9538e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9227e-08 - val_loss: 1.9440e-08 - lr: 0.0023\n",
      "Epoch 112/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9105e-08 - val_loss: 1.9244e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9076e-08 - val_loss: 1.9252e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9064e-08 - val_loss: 1.9236e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8982e-08 - val_loss: 1.9129e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8952e-08 - val_loss: 1.9090e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8861e-08 - val_loss: 1.9007e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8812e-08 - val_loss: 1.8918e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8745e-08 - val_loss: 1.8920e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8707e-08 - val_loss: 1.8828e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8684e-08 - val_loss: 1.8893e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8600e-08 - val_loss: 1.8835e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8600e-08 - val_loss: 1.8710e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8545e-08 - val_loss: 1.8741e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8486e-08 - val_loss: 1.8606e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8488e-08 - val_loss: 1.8559e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8390e-08 - val_loss: 1.8513e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8361e-08 - val_loss: 1.8488e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8352e-08 - val_loss: 1.8478e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8305e-08 - val_loss: 1.8452e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8292e-08 - val_loss: 1.8341e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8234e-08 - val_loss: 1.8336e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8196e-08 - val_loss: 1.8344e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8149e-08 - val_loss: 1.8281e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8150e-08 - val_loss: 1.8286e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8127e-08 - val_loss: 1.8245e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8064e-08 - val_loss: 1.8252e-08 - lr: 0.0012\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8037e-08 - val_loss: 1.8163e-08 - lr: 0.0012\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8025e-08 - val_loss: 1.8134e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7985e-08 - val_loss: 1.8124e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7957e-08 - val_loss: 1.8084e-08 - lr: 0.0012\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7953e-08 - val_loss: 1.8092e-08 - lr: 0.0012\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7908e-08 - val_loss: 1.8104e-08 - lr: 0.0012\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7901e-08 - val_loss: 1.8092e-08 - lr: 0.0012\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7865e-08 - val_loss: 1.8051e-08 - lr: 0.0012\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7863e-08 - val_loss: 1.7956e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9816 - val_loss: 0.1554 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1097 - val_loss: 0.0702 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0468 - val_loss: 0.0505 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0598 - val_loss: 0.0432 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0313 - val_loss: 0.0430 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0346 - val_loss: 0.0259 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0272 - val_loss: 0.0346 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0196 - val_loss: 0.0213 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0287 - val_loss: 0.0213 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0120 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0122 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0247 - val_loss: 0.0746 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0364 - val_loss: 0.0222 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0254 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0147 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0088 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0097 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0125 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0100 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0080 - val_loss: 0.0141 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0057 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0078 - val_loss: 0.0052 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0078 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0386 - val_loss: 0.0562 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0074 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0065 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - val_loss: 0.0051 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0047 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0061 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0066 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0088 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0054 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0051 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0050 - lr: 0.0066\n",
      "Epoch 35/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0154 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0085 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0053 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0032 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0059 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0120 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0042 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0043 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0036 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0046 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0130 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0040 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0091 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0064 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0071 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0041 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0027 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0046 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0028 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0028 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0023 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0087 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0037 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0022 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0020 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0048 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0057 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0016 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0019\n",
      "Early Stopping\n",
      "11\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5585e-05 - val_loss: 2.7045e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5552e-06 - val_loss: 9.0726e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8624e-07 - val_loss: 5.1111e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8963e-07 - val_loss: 3.7203e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3639e-07 - val_loss: 3.5712e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9967e-07 - val_loss: 3.0935e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7638e-07 - val_loss: 2.2782e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4688e-07 - val_loss: 2.1667e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9708e-07 - val_loss: 2.1094e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9085e-07 - val_loss: 1.6952e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7657e-07 - val_loss: 1.5796e-07 - lr: 0.0100\n",
      "Epoch 12/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9474e-07 - val_loss: 3.6086e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1767e-07 - val_loss: 1.1859e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0641e-07 - val_loss: 1.0517e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7570e-08 - val_loss: 1.0260e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9784e-08 - val_loss: 9.1406e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7197e-08 - val_loss: 8.7636e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1142e-07 - val_loss: 9.0823e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0109e-07 - val_loss: 7.9169e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.4800e-08 - val_loss: 7.2321e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0234e-07 - val_loss: 6.4867e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1910e-07 - val_loss: 1.1772e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5545e-08 - val_loss: 6.6460e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1134e-08 - val_loss: 3.1025e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4756e-08 - val_loss: 9.5725e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7106e-08 - val_loss: 5.9925e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1228e-08 - val_loss: 5.0352e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9025e-08 - val_loss: 4.9489e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9563e-08 - val_loss: 5.3403e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9617e-08 - val_loss: 4.7254e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7211e-08 - val_loss: 5.0889e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7066e-08 - val_loss: 5.4052e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5794e-08 - val_loss: 4.4587e-08 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0764e-08 - val_loss: 4.1255e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1341e-08 - val_loss: 4.0830e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9841e-08 - val_loss: 4.0077e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9148e-08 - val_loss: 4.0288e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.9812e-08 - val_loss: 3.7967e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9858e-08 - val_loss: 7.8644e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0690e-08 - val_loss: 4.0672e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7396e-08 - val_loss: 4.7245e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8621e-08 - val_loss: 3.7566e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0501e-08 - val_loss: 6.7717e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.7754e-08 - val_loss: 3.5916e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4109e-08 - val_loss: 3.5648e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3870e-08 - val_loss: 3.3485e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2765e-08 - val_loss: 3.2810e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1910e-08 - val_loss: 3.3591e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3149e-08 - val_loss: 4.3684e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4446e-08 - val_loss: 3.5442e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2481e-08 - val_loss: 3.2168e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.1399e-08 - val_loss: 4.6719e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3754e-08 - val_loss: 3.0031e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9104e-08 - val_loss: 2.9238e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8563e-08 - val_loss: 2.8886e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8724e-08 - val_loss: 2.8677e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8570e-08 - val_loss: 2.9566e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7448e-08 - val_loss: 2.8135e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7312e-08 - val_loss: 2.7606e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7221e-08 - val_loss: 2.7908e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6774e-08 - val_loss: 2.7140e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6412e-08 - val_loss: 2.8087e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6522e-08 - val_loss: 2.6902e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7238e-08 - val_loss: 3.0541e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5852e-08 - val_loss: 2.5932e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5112e-08 - val_loss: 2.5725e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5235e-08 - val_loss: 2.6306e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4752e-08 - val_loss: 2.5394e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4455e-08 - val_loss: 2.4971e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4199e-08 - val_loss: 2.5102e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4316e-08 - val_loss: 2.5164e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3878e-08 - val_loss: 2.4313e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3754e-08 - val_loss: 2.4008e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3711e-08 - val_loss: 2.4009e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3225e-08 - val_loss: 2.3815e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3030e-08 - val_loss: 2.3326e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3103e-08 - val_loss: 2.3611e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2826e-08 - val_loss: 2.3609e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2846e-08 - val_loss: 2.3368e-08 - lr: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2538e-08 - val_loss: 2.3268e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2407e-08 - val_loss: 2.2789e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2293e-08 - val_loss: 2.2986e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2195e-08 - val_loss: 2.2763e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2017e-08 - val_loss: 2.2386e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1937e-08 - val_loss: 2.2401e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1949e-08 - val_loss: 2.2585e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1689e-08 - val_loss: 2.2058e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1605e-08 - val_loss: 2.2055e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1602e-08 - val_loss: 2.2120e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1311e-08 - val_loss: 2.1948e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1232e-08 - val_loss: 2.1724e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1119e-08 - val_loss: 2.1528e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1064e-08 - val_loss: 2.1540e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1014e-08 - val_loss: 2.1340e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0815e-08 - val_loss: 2.1152e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0685e-08 - val_loss: 2.1327e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0626e-08 - val_loss: 2.1135e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0549e-08 - val_loss: 2.0937e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0485e-08 - val_loss: 2.0743e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0291e-08 - val_loss: 2.0693e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0292e-08 - val_loss: 2.0777e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0234e-08 - val_loss: 2.0559e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0166e-08 - val_loss: 2.0585e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0051e-08 - val_loss: 2.0389e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9997e-08 - val_loss: 2.0348e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9903e-08 - val_loss: 2.0131e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9862e-08 - val_loss: 2.0321e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9835e-08 - val_loss: 2.0215e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9758e-08 - val_loss: 2.0123e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9648e-08 - val_loss: 1.9954e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9599e-08 - val_loss: 1.9948e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9521e-08 - val_loss: 1.9969e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9506e-08 - val_loss: 1.9928e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9499e-08 - val_loss: 1.9914e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9411e-08 - val_loss: 1.9786e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9343e-08 - val_loss: 1.9687e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9261e-08 - val_loss: 1.9621e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9203e-08 - val_loss: 1.9521e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9165e-08 - val_loss: 1.9477e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9129e-08 - val_loss: 1.9520e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9074e-08 - val_loss: 1.9435e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9038e-08 - val_loss: 1.9354e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9011e-08 - val_loss: 1.9532e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8962e-08 - val_loss: 1.9235e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8934e-08 - val_loss: 1.9304e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8841e-08 - val_loss: 1.9189e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8834e-08 - val_loss: 1.9111e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8779e-08 - val_loss: 1.9142e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8771e-08 - val_loss: 1.9076e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8719e-08 - val_loss: 1.8965e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8690e-08 - val_loss: 1.9057e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8656e-08 - val_loss: 1.9052e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8643e-08 - val_loss: 1.8964e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8572e-08 - val_loss: 1.8899e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8539e-08 - val_loss: 1.8816e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8523e-08 - val_loss: 1.8849e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8493e-08 - val_loss: 1.8809e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8468e-08 - val_loss: 1.8834e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8438e-08 - val_loss: 1.8788e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2549 - val_loss: 0.2160 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1444 - val_loss: 0.0676 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0766 - val_loss: 0.0628 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0540 - val_loss: 0.0288 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0361 - val_loss: 0.0619 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0418 - val_loss: 0.0350 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0500 - val_loss: 0.0956 - lr: 0.0100\n",
      "Epoch 8/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0484 - val_loss: 0.0264 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0213 - val_loss: 0.0182 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0244 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0209 - val_loss: 0.0162 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0125 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0314 - val_loss: 0.0176 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0130 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0184 - val_loss: 0.0191 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0216 - val_loss: 0.0113 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0214 - val_loss: 0.0182 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0118 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0083 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0238 - val_loss: 0.0317 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0085 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0135 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0129 - val_loss: 0.0115 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0110 - val_loss: 0.0114 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0063 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0066 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0139 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0240 - val_loss: 0.0292 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0196 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0219 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0129 - val_loss: 0.0071 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0100 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0060 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0100 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0067 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0057 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0042 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0075 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0107 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0197 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0047 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0050 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0036 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0066 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0052 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0060 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0038 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0035 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0142 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0062 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0033 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0039 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0077 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0057 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0033 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0038 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0058 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0026 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0069 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0062 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0058 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0040 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0038 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0039 - lr: 0.0028\n",
      "Epoch 80/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0032 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0027 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0033 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0040 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.001 - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0030 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0024 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0026 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0020 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0025 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0020 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3812e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5789e-04 - val_loss: 0.0018 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4958e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4566e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3811e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9927e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6316e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2282e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1748e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3774e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7419e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4252e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1480e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2649e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0562e-04 - val_loss: 0.0016 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1297e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7036e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8579e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0382e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5783e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4903e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3011e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1764e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7213e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8599e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4713e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1830e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2434e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4001e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0251e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1537e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 150/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4660e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7664e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1091e-04 - val_loss: 0.0010 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4011e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5419e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3125e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2918e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9017e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8339e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1186e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9122e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1176e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7884e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5575e-04 - val_loss: 9.9591e-04 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8045e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Early Stopping\n",
      "12\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 2s 15ms/step - loss: 2.4581e-05 - val_loss: 4.1154e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9341e-06 - val_loss: 1.0070e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4651e-07 - val_loss: 5.5273e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5820e-07 - val_loss: 4.2707e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5419e-07 - val_loss: 3.1932e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8951e-07 - val_loss: 2.6846e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3601e-07 - val_loss: 2.0150e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9854e-07 - val_loss: 2.0061e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9154e-07 - val_loss: 1.5097e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4818e-07 - val_loss: 2.5861e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6806e-07 - val_loss: 1.0848e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0794e-07 - val_loss: 1.0223e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1864e-07 - val_loss: 1.1854e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1976e-07 - val_loss: 8.8281e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8085e-08 - val_loss: 1.3758e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3780e-07 - val_loss: 1.3449e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8009e-08 - val_loss: 7.6444e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3648e-08 - val_loss: 6.7516e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0271e-07 - val_loss: 1.3262e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6056e-07 - val_loss: 8.2866e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9487e-08 - val_loss: 8.2463e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7771e-08 - val_loss: 5.6938e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.6398e-08 - val_loss: 5.7167e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2509e-08 - val_loss: 7.0528e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1841e-08 - val_loss: 5.0194e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5817e-08 - val_loss: 1.3596e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7602e-08 - val_loss: 5.9977e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1414e-07 - val_loss: 2.2347e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7055e-07 - val_loss: 8.3437e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6694e-08 - val_loss: 4.7143e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7344e-08 - val_loss: 4.5628e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2637e-08 - val_loss: 4.0095e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0470e-08 - val_loss: 3.9255e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7428e-08 - val_loss: 3.6831e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6997e-08 - val_loss: 3.6435e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.5304e-08 - val_loss: 3.6103e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4710e-08 - val_loss: 3.5038e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5857e-08 - val_loss: 3.5882e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5763e-08 - val_loss: 4.0180e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9088e-08 - val_loss: 7.2318e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8411e-08 - val_loss: 3.5205e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1861e-08 - val_loss: 3.0692e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9213e-08 - val_loss: 2.8837e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8948e-08 - val_loss: 3.0190e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9421e-08 - val_loss: 2.9328e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7926e-08 - val_loss: 2.8314e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8460e-08 - val_loss: 6.3588e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8219e-08 - val_loss: 2.7793e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6853e-08 - val_loss: 2.7758e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5751e-08 - val_loss: 2.5924e-08 - lr: 0.0073\n",
      "Epoch 51/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5109e-08 - val_loss: 2.5889e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5280e-08 - val_loss: 2.5495e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6007e-08 - val_loss: 2.5642e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4159e-08 - val_loss: 2.4558e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3792e-08 - val_loss: 2.4857e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4030e-08 - val_loss: 2.4355e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3393e-08 - val_loss: 2.3404e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3198e-08 - val_loss: 2.3286e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3052e-08 - val_loss: 2.3929e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3628e-08 - val_loss: 2.3291e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2838e-08 - val_loss: 2.2634e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2210e-08 - val_loss: 2.2438e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1887e-08 - val_loss: 2.2271e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1728e-08 - val_loss: 2.2165e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1632e-08 - val_loss: 2.1569e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1327e-08 - val_loss: 2.2863e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1308e-08 - val_loss: 2.1926e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0858e-08 - val_loss: 2.0795e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0516e-08 - val_loss: 2.0713e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0459e-08 - val_loss: 2.0743e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0326e-08 - val_loss: 2.0459e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0157e-08 - val_loss: 2.1583e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9784e-08 - val_loss: 2.0146e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9675e-08 - val_loss: 2.0685e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9589e-08 - val_loss: 1.9726e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9647e-08 - val_loss: 1.9966e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9643e-08 - val_loss: 1.9738e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9103e-08 - val_loss: 1.9440e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8951e-08 - val_loss: 1.9371e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8875e-08 - val_loss: 1.9972e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8747e-08 - val_loss: 1.9209e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8570e-08 - val_loss: 1.8840e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8422e-08 - val_loss: 1.8776e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8278e-08 - val_loss: 1.8600e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8234e-08 - val_loss: 1.8555e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8172e-08 - val_loss: 1.8552e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8149e-08 - val_loss: 1.8506e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7981e-08 - val_loss: 1.8358e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7861e-08 - val_loss: 1.8163e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7759e-08 - val_loss: 1.8046e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7698e-08 - val_loss: 1.8130e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7658e-08 - val_loss: 1.8008e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7558e-08 - val_loss: 1.7983e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7459e-08 - val_loss: 1.7990e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7393e-08 - val_loss: 1.7727e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7321e-08 - val_loss: 1.7595e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7273e-08 - val_loss: 1.7601e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7173e-08 - val_loss: 1.7527e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7087e-08 - val_loss: 1.7310e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6970e-08 - val_loss: 1.7289e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6940e-08 - val_loss: 1.7303e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6911e-08 - val_loss: 1.7169e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6860e-08 - val_loss: 1.7118e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.6785e-08 - val_loss: 1.7122e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.6741e-08 - val_loss: 1.7057e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.6639e-08 - val_loss: 1.6951e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6634e-08 - val_loss: 1.6928e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6581e-08 - val_loss: 1.6762e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6499e-08 - val_loss: 1.6787e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6429e-08 - val_loss: 1.6739e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6402e-08 - val_loss: 1.6751e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6373e-08 - val_loss: 1.6599e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6322e-08 - val_loss: 1.6695e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6270e-08 - val_loss: 1.6542e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6221e-08 - val_loss: 1.6531e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6175e-08 - val_loss: 1.6462e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6172e-08 - val_loss: 1.6376e-08 - lr: 0.0021\n",
      "Epoch 118/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6126e-08 - val_loss: 1.6373e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6039e-08 - val_loss: 1.6358e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6019e-08 - val_loss: 1.6331e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5987e-08 - val_loss: 1.6294e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5935e-08 - val_loss: 1.6276e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5943e-08 - val_loss: 1.6297e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5876e-08 - val_loss: 1.6166e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5860e-08 - val_loss: 1.6110e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5814e-08 - val_loss: 1.6096e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5793e-08 - val_loss: 1.6063e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5764e-08 - val_loss: 1.6088e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5723e-08 - val_loss: 1.5978e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5686e-08 - val_loss: 1.6030e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5658e-08 - val_loss: 1.5936e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5639e-08 - val_loss: 1.5963e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5631e-08 - val_loss: 1.5950e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5574e-08 - val_loss: 1.5847e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5540e-08 - val_loss: 1.5851e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5531e-08 - val_loss: 1.5821e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5516e-08 - val_loss: 1.5757e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5495e-08 - val_loss: 1.5758e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5449e-08 - val_loss: 1.5719e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5436e-08 - val_loss: 1.5709e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5418e-08 - val_loss: 1.5713e-08 - lr: 0.0012\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5405e-08 - val_loss: 1.5707e-08 - lr: 0.0012\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5390e-08 - val_loss: 1.5681e-08 - lr: 0.0012\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5352e-08 - val_loss: 1.5653e-08 - lr: 0.0011\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5148 - val_loss: 0.2958 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1649 - val_loss: 0.1231 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0952 - val_loss: 0.0966 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0645 - val_loss: 0.0427 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0379 - val_loss: 0.0248 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0502 - val_loss: 0.0314 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0397 - val_loss: 0.0271 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0321 - val_loss: 0.0401 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0354 - val_loss: 0.0211 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0365 - val_loss: 0.0299 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0152 - lr: 0.0090\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.0208 - lr: 0.0090\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0300 - val_loss: 0.0653 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0265 - val_loss: 0.0123 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0280 - val_loss: 0.0317 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.0135 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0112 - lr: 0.0081\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0256 - lr: 0.0081\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0148 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0209 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0176 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0102 - lr: 0.0073\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0105 - lr: 0.0073\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0115 - lr: 0.0073\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0179 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0121 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0085 - lr: 0.0066\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0099 - lr: 0.0066\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0095 - lr: 0.0066\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0119 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0070 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0105 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0072 - lr: 0.0059\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0079 - lr: 0.0059\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0072 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0075 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0356 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0059 - lr: 0.0053\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0145 - lr: 0.0053\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0050 - lr: 0.0053\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0095 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0194 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0050 - lr: 0.0048\n",
      "Epoch 44/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0058 - lr: 0.0048\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0043 - lr: 0.0048\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0039 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0052 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0039 - lr: 0.0043\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0043 - lr: 0.0043\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0076 - lr: 0.0043\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0077 - val_loss: 0.0085 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0059 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0044 - lr: 0.0039\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0057 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0082 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0058 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0038 - lr: 0.0035\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0043 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0039 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0036 - lr: 0.0031\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0057 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0053 - val_loss: 0.0070 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0074 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0039 - lr: 0.0028\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0034 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0045 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0026 - val_loss: 0.0043 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0028 - lr: 0.0023\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0036 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0045 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0026 - lr: 0.0021\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0027 - lr: 0.0019\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0032 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0017\n",
      "Early Stopping\n",
      "13\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3342e-05 - val_loss: 2.7876e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5419e-06 - val_loss: 8.6576e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.7385e-07 - val_loss: 5.1846e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7367e-07 - val_loss: 3.6199e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.4589e-07 - val_loss: 2.7167e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8464e-07 - val_loss: 2.8072e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7411e-07 - val_loss: 2.9121e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1344e-07 - val_loss: 1.7412e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5531e-07 - val_loss: 1.4513e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6788e-07 - val_loss: 1.7711e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6599e-07 - val_loss: 1.8519e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7254e-07 - val_loss: 7.8321e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5957e-07 - val_loss: 1.3830e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1040e-07 - val_loss: 1.0006e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2978e-08 - val_loss: 9.0075e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.5482e-08 - val_loss: 8.4663e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.8814e-08 - val_loss: 7.4504e-08 - lr: 0.0100\n",
      "Epoch 18/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2826e-08 - val_loss: 1.0127e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7342e-08 - val_loss: 6.9244e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4099e-08 - val_loss: 8.1262e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0380e-08 - val_loss: 6.0695e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4189e-08 - val_loss: 1.2104e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8243e-08 - val_loss: 6.2585e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3942e-08 - val_loss: 8.7747e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1656e-07 - val_loss: 1.6463e-07 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9109e-08 - val_loss: 5.0379e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7131e-08 - val_loss: 4.5923e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5370e-08 - val_loss: 4.5512e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3234e-08 - val_loss: 4.6036e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4769e-08 - val_loss: 5.0264e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.5619e-08 - val_loss: 4.3406e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6406e-08 - val_loss: 4.4104e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6872e-08 - val_loss: 3.7702e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1442e-08 - val_loss: 5.4881e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9862e-08 - val_loss: 6.0004e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9769e-08 - val_loss: 4.2174e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0095e-08 - val_loss: 4.9594e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6189e-08 - val_loss: 5.9023e-08 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6294e-08 - val_loss: 3.2362e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2918e-08 - val_loss: 3.4141e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0985e-08 - val_loss: 3.3275e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2604e-08 - val_loss: 3.1497e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7450e-08 - val_loss: 4.3081e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2199e-08 - val_loss: 2.9991e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7111e-08 - val_loss: 2.7539e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6666e-08 - val_loss: 2.7462e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6627e-08 - val_loss: 2.7182e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5818e-08 - val_loss: 2.6053e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5750e-08 - val_loss: 2.6855e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8432e-08 - val_loss: 2.5761e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6501e-08 - val_loss: 2.7663e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4993e-08 - val_loss: 2.3781e-08 - lr: 0.0081\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3454e-08 - val_loss: 2.3198e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3446e-08 - val_loss: 2.3214e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3219e-08 - val_loss: 2.3856e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6499e-08 - val_loss: 2.3077e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3459e-08 - val_loss: 2.2531e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1946e-08 - val_loss: 2.3099e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1680e-08 - val_loss: 2.1707e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1540e-08 - val_loss: 2.2183e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1650e-08 - val_loss: 2.1088e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1253e-08 - val_loss: 2.0880e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1532e-08 - val_loss: 2.1103e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0552e-08 - val_loss: 2.0676e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0155e-08 - val_loss: 2.0529e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0017e-08 - val_loss: 2.2516e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0008e-08 - val_loss: 2.0888e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9608e-08 - val_loss: 1.9992e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9548e-08 - val_loss: 1.9560e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9113e-08 - val_loss: 1.9357e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9065e-08 - val_loss: 1.9184e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9011e-08 - val_loss: 1.9271e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8852e-08 - val_loss: 1.9288e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8808e-08 - val_loss: 1.9693e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8497e-08 - val_loss: 1.9642e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8380e-08 - val_loss: 1.8708e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8506e-08 - val_loss: 1.8553e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8076e-08 - val_loss: 1.8550e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8144e-08 - val_loss: 1.8414e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7806e-08 - val_loss: 1.8066e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7679e-08 - val_loss: 1.7842e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7626e-08 - val_loss: 1.8402e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7695e-08 - val_loss: 1.7712e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7409e-08 - val_loss: 1.7713e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7278e-08 - val_loss: 1.7480e-08 - lr: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7107e-08 - val_loss: 1.7372e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7108e-08 - val_loss: 1.7452e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6967e-08 - val_loss: 1.7445e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6995e-08 - val_loss: 1.6996e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6774e-08 - val_loss: 1.7056e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6764e-08 - val_loss: 1.6966e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6685e-08 - val_loss: 1.7095e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6625e-08 - val_loss: 1.6939e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6634e-08 - val_loss: 1.6951e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.6490e-08 - val_loss: 1.6765e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6407e-08 - val_loss: 1.6613e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6333e-08 - val_loss: 1.6650e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6259e-08 - val_loss: 1.6651e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6325e-08 - val_loss: 1.6417e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6163e-08 - val_loss: 1.6748e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6229e-08 - val_loss: 1.6367e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6060e-08 - val_loss: 1.6413e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5948e-08 - val_loss: 1.6215e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5932e-08 - val_loss: 1.6443e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5869e-08 - val_loss: 1.6093e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5852e-08 - val_loss: 1.6219e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5777e-08 - val_loss: 1.6006e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5680e-08 - val_loss: 1.5963e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5665e-08 - val_loss: 1.5914e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5627e-08 - val_loss: 1.5971e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5590e-08 - val_loss: 1.5837e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5491e-08 - val_loss: 1.5866e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5487e-08 - val_loss: 1.5774e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5447e-08 - val_loss: 1.5770e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5439e-08 - val_loss: 1.5734e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5423e-08 - val_loss: 1.5657e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5349e-08 - val_loss: 1.5596e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5285e-08 - val_loss: 1.5757e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5295e-08 - val_loss: 1.5683e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5239e-08 - val_loss: 1.5506e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5194e-08 - val_loss: 1.5496e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5148e-08 - val_loss: 1.5455e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5151e-08 - val_loss: 1.5454e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5106e-08 - val_loss: 1.5384e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5070e-08 - val_loss: 1.5342e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5050e-08 - val_loss: 1.5299e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4995e-08 - val_loss: 1.5284e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4951e-08 - val_loss: 1.5207e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4943e-08 - val_loss: 1.5225e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4937e-08 - val_loss: 1.5219e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4896e-08 - val_loss: 1.5181e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4862e-08 - val_loss: 1.5134e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4847e-08 - val_loss: 1.5084e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4824e-08 - val_loss: 1.5141e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4803e-08 - val_loss: 1.5057e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4770e-08 - val_loss: 1.5040e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4752e-08 - val_loss: 1.5057e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4706e-08 - val_loss: 1.5020e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4694e-08 - val_loss: 1.5007e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2717 - val_loss: 0.2276 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1393 - val_loss: 0.0688 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0740 - val_loss: 0.0626 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0547 - val_loss: 0.0377 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0499 - val_loss: 0.0345 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0364 - val_loss: 0.0512 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0377 - val_loss: 0.0418 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0389 - val_loss: 0.0217 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0259 - val_loss: 0.0310 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0243 - val_loss: 0.0250 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0283 - val_loss: 0.0280 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0368 - val_loss: 0.0165 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0154 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0131 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0263 - val_loss: 0.0685 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0284 - val_loss: 0.0106 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0294 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0245 - val_loss: 0.0282 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0624 - val_loss: 0.0238 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.0096 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0099 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0129 - val_loss: 0.0076 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0086 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0091 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0100 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0073 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0066 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0047 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0249 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0068 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0130 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0237 - val_loss: 0.0217 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0087 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0062 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0038 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0084 - lr: 0.0073\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0064 - lr: 0.0073\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0071 - val_loss: 0.0078 - lr: 0.0073\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0035 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0056 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0051 - lr: 0.0066\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0139 - lr: 0.0066\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0153 - lr: 0.0066\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0281 - lr: 0.0059\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0126 - val_loss: 0.0047 - lr: 0.0059\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0145 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 - lr: 0.0053\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0032 - lr: 0.0053\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0076 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047 - lr: 0.0048\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0052 - lr: 0.0048\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0054 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0031 - lr: 0.0043\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0096 - lr: 0.0043\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0036 - lr: 0.0043\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0027 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0027 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0040 - lr: 0.0039\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0020 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0046 - lr: 0.0035\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0041 - lr: 0.0035\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0031 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0035 - lr: 0.0031\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 0.0028\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 87/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0031 - lr: 0.0025\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0030 - lr: 0.0025\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0036 - lr: 0.0023\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0026 - lr: 0.0019\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2835e-04 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5488e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7219e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8243e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3584e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9637e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3907e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9951e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8383e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5114e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2935e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1645e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3120e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0374e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9003e-04 - val_loss: 0.0010 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7761e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3712e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1217e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3784e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6648e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5775e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9799e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0622e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9358e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1386e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0549e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4883e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4191e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8733e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7403e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2044e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9343e-04 - val_loss: 9.6375e-04 - lr: 7.1790e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0316e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8483e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7458e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Early Stopping\n",
      "14\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2510e-05 - val_loss: 2.7034e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5683e-06 - val_loss: 8.5675e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5232e-07 - val_loss: 4.7333e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3879e-07 - val_loss: 3.5460e-07 - lr: 0.0100\n",
      "Epoch 5/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 3.3793e-07 - val_loss: 2.7602e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7247e-07 - val_loss: 2.3209e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0091e-07 - val_loss: 2.3292e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7859e-07 - val_loss: 1.6502e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6601e-07 - val_loss: 1.7431e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6037e-07 - val_loss: 1.8790e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6664e-07 - val_loss: 1.1454e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0915e-07 - val_loss: 1.0165e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0270e-07 - val_loss: 1.0141e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3056e-07 - val_loss: 1.3386e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0704e-07 - val_loss: 1.3503e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4235e-07 - val_loss: 2.9351e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2202e-07 - val_loss: 7.9420e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7701e-08 - val_loss: 7.4143e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3266e-08 - val_loss: 8.7841e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0050e-07 - val_loss: 6.4726e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9520e-08 - val_loss: 9.5363e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3339e-08 - val_loss: 7.1383e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4988e-08 - val_loss: 5.5143e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1929e-08 - val_loss: 1.2266e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0996e-07 - val_loss: 5.2391e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4705e-08 - val_loss: 6.1734e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4806e-08 - val_loss: 5.1092e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5677e-08 - val_loss: 1.0632e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7071e-08 - val_loss: 8.5448e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7567e-08 - val_loss: 3.9677e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.0715e-08 - val_loss: 4.5289e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.5210e-08 - val_loss: 4.0626e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8671e-08 - val_loss: 3.6579e-07 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6808e-08 - val_loss: 4.3279e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7005e-08 - val_loss: 3.5787e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4127e-08 - val_loss: 3.4933e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4093e-08 - val_loss: 3.2986e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2664e-08 - val_loss: 3.4553e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.3682e-08 - val_loss: 3.2312e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2076e-08 - val_loss: 3.1450e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2109e-08 - val_loss: 3.2713e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8685e-08 - val_loss: 3.0937e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9125e-08 - val_loss: 2.8803e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9214e-08 - val_loss: 3.0507e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9424e-08 - val_loss: 2.7801e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8735e-08 - val_loss: 2.8159e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7912e-08 - val_loss: 2.8759e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1585e-08 - val_loss: 3.7679e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8851e-08 - val_loss: 2.7673e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7037e-08 - val_loss: 4.2198e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8370e-08 - val_loss: 2.6053e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5277e-08 - val_loss: 2.5120e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4827e-08 - val_loss: 2.4623e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4482e-08 - val_loss: 2.6089e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5222e-08 - val_loss: 2.4360e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3758e-08 - val_loss: 2.4263e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3678e-08 - val_loss: 2.3476e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4017e-08 - val_loss: 2.3170e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3759e-08 - val_loss: 2.5247e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3048e-08 - val_loss: 2.2712e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3073e-08 - val_loss: 2.3472e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6591e-08 - val_loss: 2.4302e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3045e-08 - val_loss: 2.3380e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4192e-08 - val_loss: 3.0810e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3515e-08 - val_loss: 2.1700e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1384e-08 - val_loss: 2.1375e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1351e-08 - val_loss: 2.1305e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1209e-08 - val_loss: 2.0853e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0846e-08 - val_loss: 2.1319e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0997e-08 - val_loss: 2.0846e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0525e-08 - val_loss: 2.0352e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0258e-08 - val_loss: 2.0310e-08 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0095e-08 - val_loss: 2.0437e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0016e-08 - val_loss: 2.0040e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9812e-08 - val_loss: 2.0023e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9621e-08 - val_loss: 1.9617e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9983e-08 - val_loss: 1.9705e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9426e-08 - val_loss: 1.9369e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9266e-08 - val_loss: 1.9384e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9193e-08 - val_loss: 1.9234e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8984e-08 - val_loss: 1.9001e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8888e-08 - val_loss: 1.9091e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8898e-08 - val_loss: 1.8883e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8656e-08 - val_loss: 1.8459e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8553e-08 - val_loss: 1.8678e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8383e-08 - val_loss: 1.8420e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8387e-08 - val_loss: 1.8421e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8186e-08 - val_loss: 1.8470e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8172e-08 - val_loss: 1.8263e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8109e-08 - val_loss: 1.8167e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7984e-08 - val_loss: 1.8126e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7857e-08 - val_loss: 1.7870e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7839e-08 - val_loss: 1.7755e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7675e-08 - val_loss: 1.7733e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7675e-08 - val_loss: 1.7841e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7590e-08 - val_loss: 1.7601e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7487e-08 - val_loss: 1.7590e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7472e-08 - val_loss: 1.7508e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7395e-08 - val_loss: 1.7566e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7352e-08 - val_loss: 1.7349e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7333e-08 - val_loss: 1.7282e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7201e-08 - val_loss: 1.7135e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7097e-08 - val_loss: 1.7047e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7087e-08 - val_loss: 1.7094e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7068e-08 - val_loss: 1.7152e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6980e-08 - val_loss: 1.6987e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6910e-08 - val_loss: 1.6974e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6871e-08 - val_loss: 1.6835e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6797e-08 - val_loss: 1.6779e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6767e-08 - val_loss: 1.6702e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6730e-08 - val_loss: 1.6667e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6667e-08 - val_loss: 1.6796e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6615e-08 - val_loss: 1.6577e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6561e-08 - val_loss: 1.6650e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6546e-08 - val_loss: 1.6493e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6522e-08 - val_loss: 1.6610e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6443e-08 - val_loss: 1.6493e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6404e-08 - val_loss: 1.6328e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6377e-08 - val_loss: 1.6338e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6348e-08 - val_loss: 1.6378e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6325e-08 - val_loss: 1.6300e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6244e-08 - val_loss: 1.6272e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6216e-08 - val_loss: 1.6175e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6204e-08 - val_loss: 1.6199e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6155e-08 - val_loss: 1.6138e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6135e-08 - val_loss: 1.6134e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6084e-08 - val_loss: 1.6061e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6080e-08 - val_loss: 1.6029e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6045e-08 - val_loss: 1.5976e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6021e-08 - val_loss: 1.6010e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6015e-08 - val_loss: 1.5977e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5963e-08 - val_loss: 1.5909e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5908e-08 - val_loss: 1.5927e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7459 - val_loss: 0.3289 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1756 - val_loss: 0.1444 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0926 - val_loss: 0.0524 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0587 - val_loss: 0.0441 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0380 - val_loss: 0.0385 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0335 - val_loss: 0.0473 - lr: 0.0100\n",
      "Epoch 7/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0395 - val_loss: 0.0444 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0268 - val_loss: 0.0201 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0455 - val_loss: 0.0254 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0203 - val_loss: 0.0239 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0413 - val_loss: 0.0224 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0258 - val_loss: 0.0174 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0209 - val_loss: 0.0163 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0118 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0120 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0074 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0239 - val_loss: 0.0168 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0269 - val_loss: 0.0130 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0202 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0128 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0062 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0060 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0207 - val_loss: 0.0833 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0435 - val_loss: 0.0128 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0084 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0082 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0058 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0045 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0133 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0065 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0209 - val_loss: 0.0403 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0094 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0043 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0095 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0091 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0074 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0042 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0068 - val_loss: 0.0076 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0068 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0051 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0292 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0168 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0048 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0036 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0028 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0027 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0040 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0118 - val_loss: 0.0082 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0074 - val_loss: 0.0056 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0037 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0028 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0036 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0046 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0084 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0033 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0031 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0062 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0104 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0027 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0029 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0038 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0039 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0035 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0037 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0025\n",
      "Epoch 79/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0025 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0055 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8733e-04 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0026 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7574e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4154e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5003e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3783e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6946e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8308e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5556e-04 - val_loss: 0.0017 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5251e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6506e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8506e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Early Stopping\n",
      "15\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1944e-05 - val_loss: 3.1300e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5975e-06 - val_loss: 8.8809e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4369e-07 - val_loss: 7.7263e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7076e-07 - val_loss: 3.6993e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2807e-07 - val_loss: 3.0177e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2832e-07 - val_loss: 2.1877e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0226e-07 - val_loss: 1.9593e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3028e-07 - val_loss: 2.0059e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6821e-07 - val_loss: 1.4605e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5310e-07 - val_loss: 2.0995e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2075e-07 - val_loss: 1.2316e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5407e-07 - val_loss: 2.2532e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.3140e-07 - val_loss: 9.1301e-08 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0015e-07 - val_loss: 2.0051e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1590e-07 - val_loss: 8.0953e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2583e-08 - val_loss: 1.0553e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2458e-07 - val_loss: 2.1275e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2437e-07 - val_loss: 8.5388e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8210e-08 - val_loss: 7.1939e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6738e-08 - val_loss: 6.3557e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0718e-07 - val_loss: 6.1586e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8708e-08 - val_loss: 8.7947e-08 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2418e-08 - val_loss: 6.1127e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7578e-08 - val_loss: 8.4420e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8899e-08 - val_loss: 6.4785e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2117e-08 - val_loss: 4.3840e-08 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3580e-08 - val_loss: 4.5407e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9675e-08 - val_loss: 4.2946e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1807e-08 - val_loss: 3.9448e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9760e-08 - val_loss: 4.2474e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1328e-08 - val_loss: 3.8040e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4140e-08 - val_loss: 4.8816e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2594e-08 - val_loss: 4.6432e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4313e-08 - val_loss: 3.6195e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6771e-08 - val_loss: 3.7239e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6813e-07 - val_loss: 1.5762e-07 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0731e-08 - val_loss: 3.2434e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.1856e-08 - val_loss: 3.1776e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.1656e-08 - val_loss: 3.1741e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1018e-08 - val_loss: 3.7677e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1189e-08 - val_loss: 3.0257e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9592e-08 - val_loss: 3.0736e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8359e-08 - val_loss: 3.1139e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8760e-08 - val_loss: 2.7293e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7019e-08 - val_loss: 2.7187e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6399e-08 - val_loss: 2.6147e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6105e-08 - val_loss: 2.5806e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5931e-08 - val_loss: 2.5213e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5393e-08 - val_loss: 2.5566e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4766e-08 - val_loss: 2.4233e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4400e-08 - val_loss: 2.4446e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3814e-08 - val_loss: 2.4139e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3877e-08 - val_loss: 2.4539e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3689e-08 - val_loss: 2.2914e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3025e-08 - val_loss: 2.3298e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2494e-08 - val_loss: 2.3071e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2264e-08 - val_loss: 2.3116e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2111e-08 - val_loss: 2.3915e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2929e-08 - val_loss: 2.2032e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1699e-08 - val_loss: 2.1998e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1858e-08 - val_loss: 2.1172e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1564e-08 - val_loss: 2.1235e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1170e-08 - val_loss: 2.1014e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0963e-08 - val_loss: 2.0651e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0388e-08 - val_loss: 2.0515e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0400e-08 - val_loss: 2.0063e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9923e-08 - val_loss: 2.0304e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0087e-08 - val_loss: 1.9861e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9830e-08 - val_loss: 2.0429e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9449e-08 - val_loss: 1.9679e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9283e-08 - val_loss: 1.9514e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9071e-08 - val_loss: 1.9347e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9164e-08 - val_loss: 1.9272e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8936e-08 - val_loss: 1.9077e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8784e-08 - val_loss: 1.9148e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8578e-08 - val_loss: 1.8619e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8411e-08 - val_loss: 1.8594e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8327e-08 - val_loss: 1.8723e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8222e-08 - val_loss: 1.8415e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8043e-08 - val_loss: 1.8217e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7903e-08 - val_loss: 1.7972e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7782e-08 - val_loss: 1.7891e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7774e-08 - val_loss: 1.8109e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7638e-08 - val_loss: 1.7855e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7497e-08 - val_loss: 1.7478e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7358e-08 - val_loss: 1.7614e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7376e-08 - val_loss: 1.7509e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7218e-08 - val_loss: 1.7457e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7177e-08 - val_loss: 1.7355e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7092e-08 - val_loss: 1.7066e-08 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7081e-08 - val_loss: 1.7129e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6907e-08 - val_loss: 1.7109e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6824e-08 - val_loss: 1.7025e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6809e-08 - val_loss: 1.6872e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6725e-08 - val_loss: 1.7048e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6706e-08 - val_loss: 1.6908e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6641e-08 - val_loss: 1.6706e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6553e-08 - val_loss: 1.6686e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6397e-08 - val_loss: 1.6483e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6360e-08 - val_loss: 1.6678e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6333e-08 - val_loss: 1.6576e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6264e-08 - val_loss: 1.6388e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6200e-08 - val_loss: 1.6414e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6154e-08 - val_loss: 1.6201e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6051e-08 - val_loss: 1.6193e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6033e-08 - val_loss: 1.6196e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5989e-08 - val_loss: 1.6192e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5935e-08 - val_loss: 1.6161e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5855e-08 - val_loss: 1.6128e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5843e-08 - val_loss: 1.6282e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5843e-08 - val_loss: 1.5993e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5748e-08 - val_loss: 1.5932e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5700e-08 - val_loss: 1.6073e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5622e-08 - val_loss: 1.5753e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5587e-08 - val_loss: 1.5796e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5554e-08 - val_loss: 1.5797e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5524e-08 - val_loss: 1.5669e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5459e-08 - val_loss: 1.5631e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5440e-08 - val_loss: 1.5594e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5434e-08 - val_loss: 1.5864e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5381e-08 - val_loss: 1.5520e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5340e-08 - val_loss: 1.5456e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5308e-08 - val_loss: 1.5467e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5263e-08 - val_loss: 1.5418e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5246e-08 - val_loss: 1.5408e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5209e-08 - val_loss: 1.5368e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5180e-08 - val_loss: 1.5466e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5165e-08 - val_loss: 1.5390e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5133e-08 - val_loss: 1.5292e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5095e-08 - val_loss: 1.5295e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5065e-08 - val_loss: 1.5357e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5053e-08 - val_loss: 1.5202e-08 - lr: 0.0015\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1988 - val_loss: 0.2496 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1170 - val_loss: 0.1025 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0601 - val_loss: 0.0647 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0421 - val_loss: 0.0319 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0680 - val_loss: 0.0411 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0245 - val_loss: 0.0237 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0197 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0197 - val_loss: 0.0182 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0229 - val_loss: 0.0247 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0239 - val_loss: 0.0257 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0242 - val_loss: 0.0158 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0301 - val_loss: 0.0111 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0103 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0224 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0288 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0195 - val_loss: 0.0178 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0213 - val_loss: 0.0139 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0095 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0092 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0086 - val_loss: 0.0089 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0101 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0116 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0071 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0134 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0184 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0118 - val_loss: 0.0233 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0132 - lr: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0056 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0074 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0138 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0110 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0095 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0100 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0069 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0055 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0076 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0096 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0065 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0044 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0060 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0085 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0031 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0035 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0032 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0060 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0031 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0054 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0061 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0039 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0033 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0027 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0053 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0063 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0050 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0023 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0023 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0039 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0032 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0028 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0024 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 100/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4742e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1788e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3780e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4872e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4730e-04 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1659e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6702e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Early Stopping\n",
      "16\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4988e-05 - val_loss: 3.2810e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6135e-06 - val_loss: 8.4785e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6390e-07 - val_loss: 5.0483e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5935e-07 - val_loss: 3.8256e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3246e-07 - val_loss: 3.4988e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2754e-07 - val_loss: 2.5891e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2958e-07 - val_loss: 1.9913e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9690e-07 - val_loss: 1.7808e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3655e-07 - val_loss: 2.0309e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6898e-07 - val_loss: 1.3902e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0956e-07 - val_loss: 1.3830e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1894e-07 - val_loss: 1.1092e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1401e-07 - val_loss: 2.4969e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2730e-07 - val_loss: 9.8940e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0000e-07 - val_loss: 9.8797e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6122e-07 - val_loss: 3.5501e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3724e-07 - val_loss: 1.2845e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4192e-08 - val_loss: 7.9086e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4185e-08 - val_loss: 1.4302e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3284e-08 - val_loss: 7.3603e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4648e-08 - val_loss: 7.7493e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7776e-08 - val_loss: 9.2288e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4744e-07 - val_loss: 9.3612e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0230e-07 - val_loss: 6.8454e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7405e-08 - val_loss: 5.6545e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6300e-08 - val_loss: 7.3139e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3862e-08 - val_loss: 7.3894e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9172e-08 - val_loss: 5.6760e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2943e-08 - val_loss: 5.5441e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7519e-08 - val_loss: 5.1436e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4218e-08 - val_loss: 4.7682e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0218e-08 - val_loss: 1.5244e-07 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3524e-08 - val_loss: 6.8167e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5739e-08 - val_loss: 7.7203e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6377e-08 - val_loss: 5.5981e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2549e-08 - val_loss: 4.1013e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8220e-08 - val_loss: 3.8109e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7153e-08 - val_loss: 3.8861e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7900e-08 - val_loss: 3.8118e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.5559e-08 - val_loss: 3.5666e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7811e-08 - val_loss: 4.2823e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6196e-08 - val_loss: 6.4463e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2492e-08 - val_loss: 3.4783e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5205e-08 - val_loss: 3.3653e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6187e-08 - val_loss: 4.3209e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5451e-08 - val_loss: 3.0402e-08 - lr: 0.0081\n",
      "Epoch 47/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1145e-08 - val_loss: 3.2696e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0753e-08 - val_loss: 3.0132e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0531e-08 - val_loss: 2.9406e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9699e-08 - val_loss: 4.3051e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8614e-08 - val_loss: 3.3415e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8332e-08 - val_loss: 2.8490e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7989e-08 - val_loss: 2.8662e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8565e-08 - val_loss: 3.0175e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7666e-08 - val_loss: 2.7214e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6944e-08 - val_loss: 2.9920e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6566e-08 - val_loss: 2.6297e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5840e-08 - val_loss: 2.6780e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5550e-08 - val_loss: 2.6251e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6123e-08 - val_loss: 2.5750e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6397e-08 - val_loss: 2.6739e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5190e-08 - val_loss: 2.4973e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4361e-08 - val_loss: 2.4678e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4444e-08 - val_loss: 2.4512e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4112e-08 - val_loss: 2.4048e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3900e-08 - val_loss: 2.3750e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3764e-08 - val_loss: 2.3976e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3196e-08 - val_loss: 2.4056e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3650e-08 - val_loss: 2.5602e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3174e-08 - val_loss: 2.3096e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2892e-08 - val_loss: 2.3141e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2708e-08 - val_loss: 2.2959e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2483e-08 - val_loss: 2.2242e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2251e-08 - val_loss: 2.2199e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2084e-08 - val_loss: 2.2142e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1806e-08 - val_loss: 2.2023e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1861e-08 - val_loss: 2.2070e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1534e-08 - val_loss: 2.1535e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1303e-08 - val_loss: 2.1595e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1286e-08 - val_loss: 2.1371e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1333e-08 - val_loss: 2.1163e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1112e-08 - val_loss: 2.1135e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0850e-08 - val_loss: 2.1056e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0789e-08 - val_loss: 2.0925e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0751e-08 - val_loss: 2.0680e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0553e-08 - val_loss: 2.0763e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0493e-08 - val_loss: 2.0750e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0337e-08 - val_loss: 2.0427e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0300e-08 - val_loss: 2.0350e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0086e-08 - val_loss: 2.0317e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0064e-08 - val_loss: 2.0023e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0009e-08 - val_loss: 1.9988e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9869e-08 - val_loss: 1.9946e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9864e-08 - val_loss: 1.9975e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9708e-08 - val_loss: 1.9844e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9645e-08 - val_loss: 1.9878e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9608e-08 - val_loss: 1.9731e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9530e-08 - val_loss: 1.9540e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9388e-08 - val_loss: 1.9531e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9321e-08 - val_loss: 1.9477e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9267e-08 - val_loss: 1.9343e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9223e-08 - val_loss: 1.9279e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9189e-08 - val_loss: 1.9168e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9043e-08 - val_loss: 1.9116e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8978e-08 - val_loss: 1.9104e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8970e-08 - val_loss: 1.8990e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8908e-08 - val_loss: 1.9125e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8873e-08 - val_loss: 1.8910e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8797e-08 - val_loss: 1.8973e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8726e-08 - val_loss: 1.8812e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8699e-08 - val_loss: 1.8811e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8642e-08 - val_loss: 1.8668e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8592e-08 - val_loss: 1.8620e-08 - lr: 0.0023\n",
      "Epoch 114/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8530e-08 - val_loss: 1.8688e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8475e-08 - val_loss: 1.8514e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8457e-08 - val_loss: 1.8512e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8389e-08 - val_loss: 1.8458e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8369e-08 - val_loss: 1.8386e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8310e-08 - val_loss: 1.8445e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8252e-08 - val_loss: 1.8337e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8220e-08 - val_loss: 1.8383e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8197e-08 - val_loss: 1.8339e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8224e-08 - val_loss: 1.8244e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8089e-08 - val_loss: 1.8246e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8041e-08 - val_loss: 1.8133e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8068e-08 - val_loss: 1.8146e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8016e-08 - val_loss: 1.8111e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7991e-08 - val_loss: 1.8115e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7944e-08 - val_loss: 1.8026e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7901e-08 - val_loss: 1.7935e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7861e-08 - val_loss: 1.7943e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7852e-08 - val_loss: 1.7980e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7825e-08 - val_loss: 1.7899e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7809e-08 - val_loss: 1.7864e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7764e-08 - val_loss: 1.7859e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7737e-08 - val_loss: 1.7815e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7720e-08 - val_loss: 1.7792e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7706e-08 - val_loss: 1.7780e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5461 - val_loss: 0.2213 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1508 - val_loss: 0.0988 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0854 - val_loss: 0.0641 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0703 - val_loss: 0.0633 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0347 - val_loss: 0.0293 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0404 - val_loss: 0.0246 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0414 - val_loss: 0.0685 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0482 - val_loss: 0.0314 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0247 - val_loss: 0.0173 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0252 - val_loss: 0.0311 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0369 - val_loss: 0.0420 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0235 - val_loss: 0.0358 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0174 - val_loss: 0.0182 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0860 - val_loss: 0.0565 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0101 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0082 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0107 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0097 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0233 - val_loss: 0.0230 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0283 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0088 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0079 - val_loss: 0.0071 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0068 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0134 - val_loss: 0.0413 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0208 - val_loss: 0.0078 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0046 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0082 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0110 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0273 - val_loss: 0.0219 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0091 - val_loss: 0.0174 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0209 - val_loss: 0.0172 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0084 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0083 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0094 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0058 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0079 - val_loss: 0.0062 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0059 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0086 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0083 - val_loss: 0.0059 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0070 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0053 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0055 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0044 - lr: 0.0053\n",
      "Epoch 46/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0115 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0053 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0056 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0094 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0095 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0062 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0040 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0036 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0062 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0103 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0039 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0063 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0037 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0033 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0036 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0040 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0036 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0052 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0033 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0042 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0037 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0023 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0030 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0157 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0027 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0026 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0026 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0026 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0011\n",
      "Epoch 118/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0278e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5798e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7727e-04 - val_loss: 0.0015 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7991e-04 - val_loss: 0.0015 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 9.3442e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6141e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0452e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4966e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.5717e-04 - val_loss: 0.0016 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7674e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4032e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0568e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4980e-04 - val_loss: 0.0014 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2176e-04 - val_loss: 0.0015 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2320e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2888e-04 - val_loss: 0.0013 - lr: 7.1790e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1232e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2412e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0766e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5723e-04 - val_loss: 0.0013 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0588e-04 - val_loss: 0.0013 - lr: 6.4611e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7802e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8593e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1302e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2512e-04 - val_loss: 0.0013 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8576e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7247e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7041e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9778e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6996e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0097e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3753e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5832e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3727e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7859e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9067e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0431e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9661e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1944e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0713e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9257e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8156e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8773e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8333e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9528e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5010e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4076e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6549e-04 - val_loss: 0.0011 - lr: 3.8152e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7228e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5439e-04 - val_loss: 0.0011 - lr: 3.8152e-04\n",
      "Early Stopping\n",
      "17\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5138e-05 - val_loss: 3.0592e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5561e-06 - val_loss: 8.9324e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0716e-07 - val_loss: 5.4017e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5618e-07 - val_loss: 4.4159e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0776e-07 - val_loss: 2.9540e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6471e-07 - val_loss: 2.4119e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2593e-07 - val_loss: 1.9863e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2099e-07 - val_loss: 2.0727e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0324e-07 - val_loss: 1.9161e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5679e-07 - val_loss: 1.4063e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0878e-07 - val_loss: 1.3743e-07 - lr: 0.0100\n",
      "Epoch 12/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1826e-07 - val_loss: 1.0724e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0933e-07 - val_loss: 1.0441e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0251e-07 - val_loss: 1.0002e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4183e-08 - val_loss: 9.4564e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.6681e-08 - val_loss: 1.0148e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.1522e-07 - val_loss: 9.4148e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0124e-07 - val_loss: 1.0296e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3342e-08 - val_loss: 7.5501e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3851e-08 - val_loss: 7.0859e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2468e-07 - val_loss: 8.5981e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6292e-08 - val_loss: 6.3653e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3844e-08 - val_loss: 1.4307e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9934e-08 - val_loss: 7.3814e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.0821e-08 - val_loss: 5.1933e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.2980e-08 - val_loss: 6.3855e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3282e-08 - val_loss: 7.1447e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1963e-08 - val_loss: 5.8125e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.7505e-08 - val_loss: 1.0389e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2579e-07 - val_loss: 7.9869e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6423e-08 - val_loss: 4.1744e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0082e-08 - val_loss: 3.8336e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9312e-08 - val_loss: 4.0679e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8207e-08 - val_loss: 4.0850e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7429e-08 - val_loss: 3.9544e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6853e-08 - val_loss: 3.6233e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7812e-08 - val_loss: 3.4812e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8278e-08 - val_loss: 4.3523e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.7478e-08 - val_loss: 4.0224e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8565e-08 - val_loss: 3.8593e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4872e-08 - val_loss: 3.0867e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4284e-08 - val_loss: 4.2199e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.1703e-08 - val_loss: 3.1344e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2666e-08 - val_loss: 3.2791e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1471e-08 - val_loss: 2.9553e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0948e-08 - val_loss: 8.5593e-08 - lr: 0.0090\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1304e-08 - val_loss: 2.9266e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9030e-08 - val_loss: 3.4404e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7251e-08 - val_loss: 2.5757e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6827e-08 - val_loss: 3.5761e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7929e-08 - val_loss: 2.9546e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0278e-08 - val_loss: 3.0446e-08 - lr: 0.0081\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5160e-08 - val_loss: 3.3297e-08 - lr: 0.0081\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7296e-08 - val_loss: 2.4493e-08 - lr: 0.0081\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4419e-08 - val_loss: 2.4185e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4303e-08 - val_loss: 2.3746e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4383e-08 - val_loss: 2.5050e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3399e-08 - val_loss: 2.3165e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3247e-08 - val_loss: 2.3029e-08 - lr: 0.0073\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2582e-08 - val_loss: 2.1954e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2567e-08 - val_loss: 2.4786e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2105e-08 - val_loss: 2.1687e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2335e-08 - val_loss: 2.2807e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2079e-08 - val_loss: 2.1216e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1443e-08 - val_loss: 2.1399e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0742e-08 - val_loss: 2.0360e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0726e-08 - val_loss: 2.0260e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0713e-08 - val_loss: 2.0564e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0518e-08 - val_loss: 2.0346e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0358e-08 - val_loss: 2.0895e-08 - lr: 0.0059\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0297e-08 - val_loss: 1.9973e-08 - lr: 0.0059\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9945e-08 - val_loss: 1.9726e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9748e-08 - val_loss: 1.9636e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9489e-08 - val_loss: 1.9331e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9432e-08 - val_loss: 2.0161e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9309e-08 - val_loss: 1.9021e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8956e-08 - val_loss: 1.9888e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8904e-08 - val_loss: 1.8697e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8611e-08 - val_loss: 1.8556e-08 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8655e-08 - val_loss: 1.8592e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8538e-08 - val_loss: 1.8177e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8208e-08 - val_loss: 1.8176e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8054e-08 - val_loss: 1.7900e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7949e-08 - val_loss: 1.7841e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7992e-08 - val_loss: 1.7914e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7806e-08 - val_loss: 1.7732e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7635e-08 - val_loss: 1.7687e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7635e-08 - val_loss: 1.7509e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7468e-08 - val_loss: 1.7574e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7531e-08 - val_loss: 1.7370e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7356e-08 - val_loss: 1.7184e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7161e-08 - val_loss: 1.7162e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7167e-08 - val_loss: 1.7102e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7082e-08 - val_loss: 1.7128e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7028e-08 - val_loss: 1.6920e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6934e-08 - val_loss: 1.7090e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6833e-08 - val_loss: 1.6645e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6758e-08 - val_loss: 1.6704e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6746e-08 - val_loss: 1.6742e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6660e-08 - val_loss: 1.6558e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6594e-08 - val_loss: 1.6637e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6488e-08 - val_loss: 1.6597e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6436e-08 - val_loss: 1.6371e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6371e-08 - val_loss: 1.6462e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6367e-08 - val_loss: 1.6222e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6278e-08 - val_loss: 1.6245e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6215e-08 - val_loss: 1.6192e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6158e-08 - val_loss: 1.6141e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6123e-08 - val_loss: 1.6048e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6105e-08 - val_loss: 1.5970e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6040e-08 - val_loss: 1.6066e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6005e-08 - val_loss: 1.6092e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5958e-08 - val_loss: 1.5893e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5877e-08 - val_loss: 1.5741e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5859e-08 - val_loss: 1.5763e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5796e-08 - val_loss: 1.5775e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5765e-08 - val_loss: 1.5665e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5720e-08 - val_loss: 1.5601e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5686e-08 - val_loss: 1.5584e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5659e-08 - val_loss: 1.5582e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5651e-08 - val_loss: 1.5569e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5563e-08 - val_loss: 1.5492e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5542e-08 - val_loss: 1.5488e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5538e-08 - val_loss: 1.5395e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5476e-08 - val_loss: 1.5375e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5457e-08 - val_loss: 1.5396e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5422e-08 - val_loss: 1.5329e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5389e-08 - val_loss: 1.5388e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5372e-08 - val_loss: 1.5323e-08 - lr: 0.0017\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2058 - val_loss: 0.1698 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1245 - val_loss: 0.1006 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0777 - val_loss: 0.0488 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0400 - val_loss: 0.0417 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0476 - val_loss: 0.0561 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0423 - val_loss: 0.0667 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0315 - val_loss: 0.0255 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0203 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0274 - val_loss: 0.0373 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0378 - val_loss: 0.0348 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0310 - val_loss: 0.0137 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0098 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0291 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0273 - val_loss: 0.0265 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.0183 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0393 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0105 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0109 - val_loss: 0.0135 - lr: 0.0090\n",
      "Epoch 19/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0116 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0083 - val_loss: 0.0147 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0282 - val_loss: 0.0294 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0076 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0119 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0075 - val_loss: 0.0080 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0068 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0246 - val_loss: 0.0202 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0107 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0062 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0083 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0058 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0124 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0224 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0056 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0045 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0123 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0048 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0056 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0054 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0066 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0099 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.0138 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0201 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0043 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0062 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0024 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0028 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0074 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0121 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0138 - val_loss: 0.0068 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0082 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0026 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0021 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0039 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0047 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0058 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0032 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0032 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0050 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0020 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0050 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0033 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0016 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 91/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2718e-04 - val_loss: 0.0013 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1007e-04 - val_loss: 0.0011 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6484e-04 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9063e-04 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1957e-04 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6995e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4292e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9408e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.5316e-04 - val_loss: 0.0010 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5450e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1074e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7012e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4173e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0095e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8842e-04 - val_loss: 9.5570e-04 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9706e-04 - val_loss: 9.8510e-04 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4122e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0456e-04 - val_loss: 0.0010 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5996e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8436e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8833e-04 - val_loss: 9.4778e-04 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1318e-04 - val_loss: 9.6898e-04 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1908e-04 - val_loss: 0.0010 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4425e-04 - val_loss: 9.9823e-04 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2516e-04 - val_loss: 9.9130e-04 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2456e-04 - val_loss: 9.6553e-04 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2994e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9818e-04 - val_loss: 8.7826e-04 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4150e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9802e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4812e-04 - val_loss: 9.9112e-04 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9423e-04 - val_loss: 9.8419e-04 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4864e-04 - val_loss: 8.5934e-04 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9064e-04 - val_loss: 8.7391e-04 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2257e-04 - val_loss: 8.6837e-04 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3374e-04 - val_loss: 8.7347e-04 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2507e-04 - val_loss: 8.5172e-04 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5426e-04 - val_loss: 8.7686e-04 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5578e-04 - val_loss: 8.7592e-04 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0324e-04 - val_loss: 8.1849e-04 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2452e-04 - val_loss: 8.2955e-04 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1681e-04 - val_loss: 8.2830e-04 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2990e-04 - val_loss: 8.1955e-04 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1961e-04 - val_loss: 8.4693e-04 - lr: 6.4611e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8489e-04 - val_loss: 8.2694e-04 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8878e-04 - val_loss: 7.9273e-04 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8922e-04 - val_loss: 7.6656e-04 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1352e-04 - val_loss: 9.1599e-04 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0716e-04 - val_loss: 8.5287e-04 - lr: 5.8150e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6786e-04 - val_loss: 8.0662e-04 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.4553e-04 - val_loss: 7.6404e-04 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4001e-04 - val_loss: 7.6287e-04 - lr: 5.2335e-04\n",
      "Epoch 159/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 4.6089e-04 - val_loss: 8.2479e-04 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8042e-04 - val_loss: 7.8921e-04 - lr: 5.2335e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.3549e-04 - val_loss: 7.3241e-04 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5584e-04 - val_loss: 7.8946e-04 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.3794e-04 - val_loss: 7.3732e-04 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3422e-04 - val_loss: 7.9251e-04 - lr: 4.7101e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9301e-04 - val_loss: 7.5345e-04 - lr: 4.7101e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0148e-04 - val_loss: 7.2105e-04 - lr: 4.2391e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.0493e-04 - val_loss: 7.5967e-04 - lr: 4.2391e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.3289e-04 - val_loss: 7.6161e-04 - lr: 4.2391e-04\n",
      "Early Stopping\n",
      "18\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2573e-05 - val_loss: 2.6553e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4312e-06 - val_loss: 8.7833e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4372e-07 - val_loss: 6.0291e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8773e-07 - val_loss: 4.3398e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.7479e-07 - val_loss: 3.6420e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9583e-07 - val_loss: 2.6688e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5513e-07 - val_loss: 2.2551e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3488e-07 - val_loss: 2.4340e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9804e-07 - val_loss: 2.1312e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8263e-07 - val_loss: 2.2895e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5465e-07 - val_loss: 1.4232e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3830e-07 - val_loss: 1.2473e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3247e-07 - val_loss: 1.2047e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9292e-07 - val_loss: 3.2062e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5954e-07 - val_loss: 1.0493e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7977e-08 - val_loss: 9.1385e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2116e-08 - val_loss: 8.9567e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0525e-07 - val_loss: 8.6983e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8797e-08 - val_loss: 9.2543e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9282e-08 - val_loss: 9.7192e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0130e-07 - val_loss: 7.1728e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0409e-07 - val_loss: 6.8497e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5771e-08 - val_loss: 2.0178e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2509e-08 - val_loss: 1.1123e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3927e-07 - val_loss: 7.5454e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2959e-08 - val_loss: 6.6018e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2583e-08 - val_loss: 7.2160e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7253e-08 - val_loss: 6.2599e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8380e-08 - val_loss: 5.1878e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7161e-08 - val_loss: 5.7490e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2466e-07 - val_loss: 1.0246e-07 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1580e-08 - val_loss: 4.6025e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9177e-08 - val_loss: 4.4725e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.6468e-08 - val_loss: 4.2846e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8476e-08 - val_loss: 5.7262e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3616e-08 - val_loss: 4.9655e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1135e-08 - val_loss: 1.1206e-07 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8207e-08 - val_loss: 4.0101e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8649e-08 - val_loss: 3.7959e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.7998e-08 - val_loss: 3.7447e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9740e-08 - val_loss: 4.2493e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5643e-08 - val_loss: 3.3976e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5986e-08 - val_loss: 3.9823e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5232e-08 - val_loss: 3.3574e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8695e-08 - val_loss: 3.9769e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7832e-08 - val_loss: 3.6875e-08 - lr: 0.0090\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5162e-08 - val_loss: 3.5324e-08 - lr: 0.0090\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0346e-08 - val_loss: 3.0897e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0895e-08 - val_loss: 3.0498e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0436e-08 - val_loss: 2.8867e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9078e-08 - val_loss: 2.8641e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.3227e-08 - val_loss: 9.9224e-08 - lr: 0.0081\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6653e-08 - val_loss: 2.8294e-08 - lr: 0.0081\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7076e-08 - val_loss: 2.7028e-08 - lr: 0.0081\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7226e-08 - val_loss: 2.8710e-08 - lr: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6399e-08 - val_loss: 2.6955e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5866e-08 - val_loss: 2.6758e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5850e-08 - val_loss: 2.7579e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5699e-08 - val_loss: 2.5103e-08 - lr: 0.0073\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5909e-08 - val_loss: 2.5566e-08 - lr: 0.0073\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3861e-08 - val_loss: 2.3921e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3622e-08 - val_loss: 2.3975e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3670e-08 - val_loss: 2.3701e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3297e-08 - val_loss: 2.3387e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3620e-08 - val_loss: 2.3010e-08 - lr: 0.0066\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3913e-08 - val_loss: 2.2801e-08 - lr: 0.0066\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2640e-08 - val_loss: 2.3032e-08 - lr: 0.0066\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2623e-08 - val_loss: 2.2825e-08 - lr: 0.0066\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2364e-08 - val_loss: 2.3297e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2259e-08 - val_loss: 2.2127e-08 - lr: 0.0059\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1639e-08 - val_loss: 2.1807e-08 - lr: 0.0059\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1550e-08 - val_loss: 2.1992e-08 - lr: 0.0059\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1283e-08 - val_loss: 2.1215e-08 - lr: 0.0059\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1051e-08 - val_loss: 2.1214e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0880e-08 - val_loss: 2.1210e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0575e-08 - val_loss: 2.1628e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0466e-08 - val_loss: 2.0515e-08 - lr: 0.0053\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0174e-08 - val_loss: 2.0655e-08 - lr: 0.0053\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0107e-08 - val_loss: 2.0166e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9801e-08 - val_loss: 2.0175e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0244e-08 - val_loss: 2.0714e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9587e-08 - val_loss: 1.9867e-08 - lr: 0.0048\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9488e-08 - val_loss: 2.0464e-08 - lr: 0.0048\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9317e-08 - val_loss: 1.9454e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9119e-08 - val_loss: 1.9299e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9018e-08 - val_loss: 1.9132e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8953e-08 - val_loss: 1.9064e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8834e-08 - val_loss: 1.9068e-08 - lr: 0.0043\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8612e-08 - val_loss: 1.8830e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8521e-08 - val_loss: 1.8640e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8432e-08 - val_loss: 1.8525e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8331e-08 - val_loss: 1.8417e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8332e-08 - val_loss: 1.8519e-08 - lr: 0.0039\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8163e-08 - val_loss: 1.8260e-08 - lr: 0.0039\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8066e-08 - val_loss: 1.8879e-08 - lr: 0.0039\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8069e-08 - val_loss: 1.7994e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7920e-08 - val_loss: 1.8224e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7761e-08 - val_loss: 1.8023e-08 - lr: 0.0035\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7756e-08 - val_loss: 1.7911e-08 - lr: 0.0035\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7639e-08 - val_loss: 1.7791e-08 - lr: 0.0035\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7537e-08 - val_loss: 1.7720e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7455e-08 - val_loss: 1.7688e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7430e-08 - val_loss: 1.7909e-08 - lr: 0.0031\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7431e-08 - val_loss: 1.7498e-08 - lr: 0.0031\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7248e-08 - val_loss: 1.7494e-08 - lr: 0.0031\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7141e-08 - val_loss: 1.7479e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7091e-08 - val_loss: 1.7299e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7025e-08 - val_loss: 1.7186e-08 - lr: 0.0028\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7021e-08 - val_loss: 1.7251e-08 - lr: 0.0028\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6984e-08 - val_loss: 1.7158e-08 - lr: 0.0028\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6857e-08 - val_loss: 1.7027e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6784e-08 - val_loss: 1.7019e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6731e-08 - val_loss: 1.7221e-08 - lr: 0.0025\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6720e-08 - val_loss: 1.6899e-08 - lr: 0.0025\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6688e-08 - val_loss: 1.6796e-08 - lr: 0.0025\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6603e-08 - val_loss: 1.6729e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6565e-08 - val_loss: 1.6727e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6507e-08 - val_loss: 1.6711e-08 - lr: 0.0023\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6459e-08 - val_loss: 1.6628e-08 - lr: 0.0023\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6414e-08 - val_loss: 1.6540e-08 - lr: 0.0023\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6350e-08 - val_loss: 1.6509e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6321e-08 - val_loss: 1.6521e-08 - lr: 0.0021\n",
      "Epoch 123/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6291e-08 - val_loss: 1.6508e-08 - lr: 0.0021\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6275e-08 - val_loss: 1.6442e-08 - lr: 0.0021\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6233e-08 - val_loss: 1.6415e-08 - lr: 0.0021\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6175e-08 - val_loss: 1.6388e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6153e-08 - val_loss: 1.6426e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6108e-08 - val_loss: 1.6310e-08 - lr: 0.0019\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6053e-08 - val_loss: 1.6293e-08 - lr: 0.0019\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6067e-08 - val_loss: 1.6208e-08 - lr: 0.0019\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5993e-08 - val_loss: 1.6232e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5999e-08 - val_loss: 1.6172e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5951e-08 - val_loss: 1.6107e-08 - lr: 0.0017\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5959e-08 - val_loss: 1.6053e-08 - lr: 0.0017\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5872e-08 - val_loss: 1.6048e-08 - lr: 0.0017\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5850e-08 - val_loss: 1.5995e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5843e-08 - val_loss: 1.5998e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5787e-08 - val_loss: 1.5974e-08 - lr: 0.0015\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5767e-08 - val_loss: 1.5932e-08 - lr: 0.0015\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5733e-08 - val_loss: 1.5952e-08 - lr: 0.0015\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5717e-08 - val_loss: 1.5914e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1975 - val_loss: 0.1961 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1124 - val_loss: 0.0888 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0569 - val_loss: 0.0450 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0501 - val_loss: 0.0535 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0431 - val_loss: 0.0435 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0317 - val_loss: 0.0324 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0307 - val_loss: 0.0279 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0317 - val_loss: 0.0262 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0235 - val_loss: 0.0339 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0228 - val_loss: 0.0247 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0224 - val_loss: 0.0243 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0310 - val_loss: 0.0249 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0231 - val_loss: 0.0113 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0199 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0230 - val_loss: 0.0629 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0483 - val_loss: 0.0143 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0123 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0151 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0109 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0076 - val_loss: 0.0102 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0173 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0084 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0319 - val_loss: 0.0357 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0138 - val_loss: 0.0072 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0053 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0053 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0102 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0203 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0215 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0121 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0071 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0053 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0063 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0066 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0274 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0065 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0033 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0053 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0049 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0066 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0068 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0046 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0060 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0046 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0124 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0069 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0157 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0072 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0027 - lr: 0.0048\n",
      "Epoch 52/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0025 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0031 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0055 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0070 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0028 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0049 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0046 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0031 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0043 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0042 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0024 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0045 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0045 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0042 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0019 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0107 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0026 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9315e-04 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2325e-04 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8542e-04 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5781e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1761e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2824e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2623e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4745e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8066e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7512e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2083e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3603e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8719e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1122e-04 - val_loss: 0.0011 - lr: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5849e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6577e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3271e-04 - val_loss: 0.0010 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0981e-04 - val_loss: 0.0010 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5173e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9550e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4091e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6572e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2912e-04 - val_loss: 9.8260e-04 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2133e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 6.7161e-04 - val_loss: 9.8946e-04 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3686e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5956e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1600e-04 - val_loss: 9.7148e-04 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2921e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5410e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2904e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0181e-04 - val_loss: 9.2073e-04 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6349e-04 - val_loss: 9.8980e-04 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8585e-04 - val_loss: 9.5157e-04 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8302e-04 - val_loss: 9.4701e-04 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0379e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6697e-04 - val_loss: 9.0574e-04 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2997e-04 - val_loss: 9.1296e-04 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1305e-04 - val_loss: 9.5324e-04 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6657e-04 - val_loss: 9.8802e-04 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3608e-04 - val_loss: 8.4578e-04 - lr: 6.4611e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9433e-04 - val_loss: 8.8336e-04 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1907e-04 - val_loss: 9.2991e-04 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1223e-04 - val_loss: 8.5622e-04 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5087e-04 - val_loss: 8.6986e-04 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9233e-04 - val_loss: 8.7252e-04 - lr: 5.8150e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0162e-04 - val_loss: 8.4776e-04 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7912e-04 - val_loss: 9.0075e-04 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0333e-04 - val_loss: 8.0764e-04 - lr: 5.2335e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7060e-04 - val_loss: 8.2504e-04 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0346e-04 - val_loss: 8.6671e-04 - lr: 5.2335e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.6540e-04 - val_loss: 8.2572e-04 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8428e-04 - val_loss: 8.9367e-04 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8097e-04 - val_loss: 8.5050e-04 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9478e-04 - val_loss: 8.6479e-04 - lr: 4.7101e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6522e-04 - val_loss: 8.8601e-04 - lr: 4.7101e-04\n",
      "Early Stopping\n",
      "19\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4064e-05 - val_loss: 3.0176e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4721e-06 - val_loss: 7.7432e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7623e-07 - val_loss: 5.9718e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2292e-07 - val_loss: 3.5749e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8227e-07 - val_loss: 4.3744e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7627e-07 - val_loss: 2.1217e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9431e-07 - val_loss: 1.8278e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8614e-07 - val_loss: 1.5705e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0050e-07 - val_loss: 1.4144e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6466e-07 - val_loss: 1.8076e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2777e-07 - val_loss: 1.4506e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4472e-07 - val_loss: 1.0089e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3543e-07 - val_loss: 1.2580e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7460e-07 - val_loss: 4.0416e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5283e-07 - val_loss: 9.5848e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4747e-07 - val_loss: 8.2876e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8860e-08 - val_loss: 1.4720e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7242e-08 - val_loss: 7.2200e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6546e-08 - val_loss: 6.6498e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4459e-08 - val_loss: 6.4398e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4364e-08 - val_loss: 1.8914e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2625e-07 - val_loss: 2.0185e-07 - lr: 0.0100\n",
      "Epoch 23/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1032e-08 - val_loss: 6.3242e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7013e-08 - val_loss: 6.0245e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6356e-08 - val_loss: 5.9248e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2534e-08 - val_loss: 6.2376e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7662e-08 - val_loss: 6.1275e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7749e-08 - val_loss: 5.9215e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0608e-07 - val_loss: 6.2113e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6849e-08 - val_loss: 4.1722e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4076e-08 - val_loss: 4.3685e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1007e-08 - val_loss: 4.0031e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8990e-08 - val_loss: 4.0387e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1701e-08 - val_loss: 4.2124e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7004e-08 - val_loss: 6.7946e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5399e-08 - val_loss: 3.5654e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4865e-08 - val_loss: 3.4183e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5144e-08 - val_loss: 3.2936e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6277e-08 - val_loss: 3.8200e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.3879e-08 - val_loss: 3.2989e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3455e-08 - val_loss: 3.5628e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1258e-08 - val_loss: 3.1155e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1162e-08 - val_loss: 3.0738e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0332e-08 - val_loss: 3.0441e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0046e-08 - val_loss: 2.9465e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7137e-08 - val_loss: 2.8870e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0859e-08 - val_loss: 3.5968e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9643e-08 - val_loss: 2.8815e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5097e-08 - val_loss: 3.6147e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7916e-08 - val_loss: 2.6977e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6542e-08 - val_loss: 2.6514e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7044e-08 - val_loss: 2.8158e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6559e-08 - val_loss: 2.6491e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6224e-08 - val_loss: 2.5661e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4992e-08 - val_loss: 2.5207e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5117e-08 - val_loss: 2.5098e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4740e-08 - val_loss: 2.5124e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4753e-08 - val_loss: 2.4913e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4405e-08 - val_loss: 2.4202e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4002e-08 - val_loss: 2.4478e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3513e-08 - val_loss: 2.3835e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3176e-08 - val_loss: 2.3402e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3299e-08 - val_loss: 2.3349e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2738e-08 - val_loss: 2.2783e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2320e-08 - val_loss: 2.2729e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1949e-08 - val_loss: 2.2036e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1930e-08 - val_loss: 2.2537e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1930e-08 - val_loss: 2.2674e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1845e-08 - val_loss: 2.2269e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1590e-08 - val_loss: 2.2401e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1227e-08 - val_loss: 2.1156e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0895e-08 - val_loss: 2.1102e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0821e-08 - val_loss: 2.1856e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0969e-08 - val_loss: 2.1015e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0650e-08 - val_loss: 2.1064e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0440e-08 - val_loss: 2.0539e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0223e-08 - val_loss: 2.0459e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0143e-08 - val_loss: 2.0191e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9984e-08 - val_loss: 2.0388e-08 - lr: 0.0039\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0019e-08 - val_loss: 2.0138e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9915e-08 - val_loss: 1.9948e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9657e-08 - val_loss: 1.9871e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9686e-08 - val_loss: 1.9814e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9414e-08 - val_loss: 1.9570e-08 - lr: 0.0035\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9263e-08 - val_loss: 1.9885e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9361e-08 - val_loss: 1.9428e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9211e-08 - val_loss: 1.9976e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9030e-08 - val_loss: 1.9281e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8826e-08 - val_loss: 1.8932e-08 - lr: 0.0031\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8763e-08 - val_loss: 1.8923e-08 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8805e-08 - val_loss: 1.8783e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8622e-08 - val_loss: 1.8846e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8538e-08 - val_loss: 1.8712e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8420e-08 - val_loss: 1.8458e-08 - lr: 0.0028\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8441e-08 - val_loss: 1.8479e-08 - lr: 0.0028\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8336e-08 - val_loss: 1.8545e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8261e-08 - val_loss: 1.8667e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8135e-08 - val_loss: 1.8271e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8015e-08 - val_loss: 1.8101e-08 - lr: 0.0025\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7959e-08 - val_loss: 1.8143e-08 - lr: 0.0025\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7906e-08 - val_loss: 1.8186e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7852e-08 - val_loss: 1.7988e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7838e-08 - val_loss: 1.7866e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7717e-08 - val_loss: 1.7824e-08 - lr: 0.0023\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7694e-08 - val_loss: 1.7901e-08 - lr: 0.0023\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7634e-08 - val_loss: 1.7768e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7590e-08 - val_loss: 1.7755e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7555e-08 - val_loss: 1.7825e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7441e-08 - val_loss: 1.7588e-08 - lr: 0.0021\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7393e-08 - val_loss: 1.7623e-08 - lr: 0.0021\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7365e-08 - val_loss: 1.7559e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7329e-08 - val_loss: 1.7464e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7270e-08 - val_loss: 1.7431e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7207e-08 - val_loss: 1.7539e-08 - lr: 0.0019\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7188e-08 - val_loss: 1.7268e-08 - lr: 0.0019\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7128e-08 - val_loss: 1.7391e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7092e-08 - val_loss: 1.7298e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7052e-08 - val_loss: 1.7126e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7007e-08 - val_loss: 1.7134e-08 - lr: 0.0017\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6987e-08 - val_loss: 1.7147e-08 - lr: 0.0017\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6934e-08 - val_loss: 1.7157e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6895e-08 - val_loss: 1.7038e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6859e-08 - val_loss: 1.7082e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6826e-08 - val_loss: 1.7017e-08 - lr: 0.0015\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6795e-08 - val_loss: 1.6934e-08 - lr: 0.0015\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6783e-08 - val_loss: 1.7015e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6747e-08 - val_loss: 1.6863e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6708e-08 - val_loss: 1.6976e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6669e-08 - val_loss: 1.6841e-08 - lr: 0.0014\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6619e-08 - val_loss: 1.6801e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3453 - val_loss: 0.1999 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1246 - val_loss: 0.1035 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0616 - val_loss: 0.0595 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0530 - val_loss: 0.0957 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0478 - val_loss: 0.0325 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0351 - val_loss: 0.0210 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0291 - val_loss: 0.0173 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0382 - val_loss: 0.0653 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0284 - val_loss: 0.0580 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0312 - val_loss: 0.0238 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0265 - val_loss: 0.0195 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0119 - lr: 0.0090\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0151 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0135 - val_loss: 0.0071 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0138 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0077 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0173 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0104 - lr: 0.0081\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0114 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0130 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0330 - val_loss: 0.0503 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0064 - lr: 0.0073\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0048 - lr: 0.0073\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0071 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0154 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0065 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0119 - val_loss: 0.0165 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0048 - lr: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0069 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0060 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0099 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0073 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0069 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0118 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0067 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0084 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0035 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0039 - lr: 0.0048\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0045 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0101 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0057 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0028 - lr: 0.0043\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0050 - lr: 0.0043\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0026 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0117 - val_loss: 0.0059 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0027 - lr: 0.0039\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0024 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0036 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0044 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0079 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0036 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0047 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0043 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0023 - lr: 0.0019\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0017\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0026 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 102/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0020 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5262e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9025e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7552e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8174e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9536e-04 - val_loss: 0.0015 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2995e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3544e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7372e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4825e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9007e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1011e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.8272e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6794e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7573e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7740e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5116e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4141e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8532e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3634e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9504e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2317e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0281e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0093e-04 - val_loss: 0.0013 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2884e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7378e-04 - val_loss: 0.0015 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6775e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8125e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7305e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6841e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2097e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 6.8591e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7697e-04 - val_loss: 0.0010 - lr: 5.8150e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3954e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6502e-04 - val_loss: 9.9451e-04 - lr: 5.8150e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9660e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7896e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0979e-04 - val_loss: 9.8946e-04 - lr: 5.2335e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3442e-04 - val_loss: 9.8369e-04 - lr: 5.2335e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3094e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4346e-04 - val_loss: 9.9145e-04 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9346e-04 - val_loss: 9.5497e-04 - lr: 4.7101e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1421e-04 - val_loss: 9.9206e-04 - lr: 4.7101e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9856e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1218e-04 - val_loss: 9.3967e-04 - lr: 4.7101e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0334e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 6.0613e-04 - val_loss: 9.3290e-04 - lr: 4.2391e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7174e-04 - val_loss: 9.5464e-04 - lr: 4.2391e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8411e-04 - val_loss: 9.4636e-04 - lr: 4.2391e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7611e-04 - val_loss: 9.2399e-04 - lr: 4.2391e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8351e-04 - val_loss: 9.6150e-04 - lr: 4.2391e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7063e-04 - val_loss: 9.4868e-04 - lr: 3.8152e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5704e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8685e-04 - val_loss: 9.7285e-04 - lr: 3.8152e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6548e-04 - val_loss: 9.2028e-04 - lr: 3.8152e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6824e-04 - val_loss: 9.2915e-04 - lr: 3.8152e-04\n",
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4688e-04 - val_loss: 9.1658e-04 - lr: 3.4337e-04\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "errs = np.empty((20, 1704))\n",
    "ae_errs = np.empty((20, 1704))\n",
    "BEST_RES = 1000\n",
    "BEST_IDX = 0\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    ae_emulator = VAE.AutoEncoderEmulator()\n",
    "    ae_emulator.train()\n",
    "    rmse = ae_emulator.compute_rms_error()\n",
    "    errs[i] = rmse\n",
    "    rmse_auto = ae_emulator.compute_rms_error(use_autoencoder=False)\n",
    "    ae_errs[i] = rmse_auto\n",
    "    if i == 0:\n",
    "        BEST_RES = rmse.mean()\n",
    "        ae_emulator.emulator.save('ae_res_nov9/em0.h5')\n",
    "        ae_emulator.encoder.save('ae_res_nov9/en0.h5')\n",
    "        ae_emulator.decoder.save('ae_res_nov9/de0.h5')\n",
    "        ae_emulator.autoencoder.save('ae_res_nov9/ae0.h5')\n",
    "    elif rmse.mean() < BEST_RES:\n",
    "        print('Old Best was = ')\n",
    "        print(BEST_RES)\n",
    "        BEST_RES = rmse.mean()\n",
    "        print('NEW BEST is')\n",
    "        print(BEST_RES)\n",
    "        print('Old Best idx was = ')\n",
    "        print(BEST_IDX)\n",
    "        BEST_IDX = i\n",
    "        print('NEW BEST idx is')\n",
    "        print(BEST_IDX)\n",
    "        ae_emulator.emulator.save('ae_res_nov9/em'+str(i)+'.h5')\n",
    "        ae_emulator.encoder.save('ae_res_nov9/en'+str(i)+'.h5')\n",
    "        ae_emulator.decoder.save('ae_res_nov9/de'+str(i)+'.h5')\n",
    "        ae_emulator.autoencoder.save('ae_res_nov9/ae'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038255493\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(BEST_RES)\n",
    "print(BEST_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('emerr.npy', errs)\n",
    "np.save('aeerr.npy', ae_errs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator_env",
   "language": "python",
   "name": "emulator_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
