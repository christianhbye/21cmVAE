{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 20:55:57.174150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s/sievers/cbye/lib:/home/s/sievers/cbye/lib:/opt/slurm/lib64:/scinet/niagara/software/2019b/core/lib64\n",
      "2021-11-07 20:55:57.174231: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import VeryAccurateEmulator as VAE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Emulator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " em_input (InputLayer)       [(None, 7)]               0         \n",
      "                                                                 \n",
      " em_hidden_layer_0 (Dense)   (None, 288)               2304      \n",
      "                                                                 \n",
      " em_hidden_layer_1 (Dense)   (None, 352)               101728    \n",
      "                                                                 \n",
      " em_hidden_layer_2 (Dense)   (None, 288)               101664    \n",
      "                                                                 \n",
      " em_hidden_layer_3 (Dense)   (None, 224)               64736     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 451)               101475    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 371,907\n",
      "Trainable params: 371,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emulator = VAE.VeryAccurateEmulator()\n",
    "emulator.emulator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compiled: Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.6461e-05 - val_loss: 1.7635e-05 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.1039e-06 - val_loss: 4.7002e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.4496e-06 - val_loss: 2.5664e-06 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9831e-06 - val_loss: 1.9821e-06 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4884e-06 - val_loss: 1.4388e-06 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0826e-06 - val_loss: 9.9930e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.4730e-07 - val_loss: 7.6172e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.9580e-07 - val_loss: 6.5913e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.8622e-07 - val_loss: 6.2114e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5520e-07 - val_loss: 3.9665e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2373e-07 - val_loss: 4.7027e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6772e-07 - val_loss: 3.9454e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5492e-07 - val_loss: 4.3087e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6443e-07 - val_loss: 2.5956e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 3.3093e-07 - val_loss: 2.6925e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.6146e-07 - val_loss: 2.1674e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 3.0060e-07 - val_loss: 2.2214e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.7487e-07 - val_loss: 3.1346e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4442e-07 - val_loss: 2.3693e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 2s 18ms/step - loss: 2.1711e-07 - val_loss: 2.0428e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 1.7497e-07 - val_loss: 1.9575e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4459e-07 - val_loss: 2.2633e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 1.6729e-07 - val_loss: 1.5152e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 2.3659e-07 - val_loss: 1.6946e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 1.6545e-07 - val_loss: 1.5480e-07 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.6179e-07 - val_loss: 1.7813e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.6012e-07 - val_loss: 2.3478e-07 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.4018e-07 - val_loss: 1.2292e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 1.4166e-07 - val_loss: 1.6947e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.0150e-07 - val_loss: 1.2106e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 1.5060e-07 - val_loss: 1.5339e-07 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 1.4798e-07 - val_loss: 1.1154e-07 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.3995e-07 - val_loss: 1.1122e-07 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.0438e-07 - val_loss: 1.2697e-07 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 1.2227e-07 - val_loss: 9.3810e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.2081e-07 - val_loss: 1.1953e-07 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 1.3965e-07 - val_loss: 1.3603e-07 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.2784e-07 - val_loss: 1.9685e-07 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 9.3060e-08 - val_loss: 8.2469e-08 - lr: 0.0100\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 8.6871e-08 - val_loss: 1.0735e-07 - lr: 0.0100\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 1.1535e-07 - val_loss: 1.1243e-07 - lr: 0.0100\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 1.0947e-07 - val_loss: 1.0554e-07 - lr: 0.0100\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 1.2265e-07 - val_loss: 1.6316e-07 - lr: 0.0100\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 9.9702e-08 - val_loss: 7.2472e-08 - lr: 0.0100\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 6.4409e-08 - val_loss: 6.9811e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 6.5574e-08 - val_loss: 9.3335e-08 - lr: 0.0090\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 6.6989e-08 - val_loss: 7.0522e-08 - lr: 0.0090\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 6.6087e-08 - val_loss: 5.8402e-08 - lr: 0.0090\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 6.9681e-08 - val_loss: 9.0637e-08 - lr: 0.0090\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 8.4494e-08 - val_loss: 5.5568e-08 - lr: 0.0090\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 7.1665e-08 - val_loss: 8.7661e-08 - lr: 0.0090\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 7.8064e-08 - val_loss: 6.4006e-08 - lr: 0.0090\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 2s 18ms/step - loss: 7.4131e-08 - val_loss: 9.5841e-08 - lr: 0.0090\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 5.7355e-08 - val_loss: 5.0161e-08 - lr: 0.0081\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 5.1218e-08 - val_loss: 5.1691e-08 - lr: 0.0081\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 5.1309e-08 - val_loss: 5.6496e-08 - lr: 0.0081\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 5.2587e-08 - val_loss: 5.1922e-08 - lr: 0.0081\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 5.2713e-08 - val_loss: 8.4553e-08 - lr: 0.0081\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 4.9786e-08 - val_loss: 4.7996e-08 - lr: 0.0073\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 4.5867e-08 - val_loss: 4.4044e-08 - lr: 0.0073\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 4.4181e-08 - val_loss: 4.6573e-08 - lr: 0.0073\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 4.6491e-08 - val_loss: 4.8081e-08 - lr: 0.0073\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 4.5375e-08 - val_loss: 5.2576e-08 - lr: 0.0073\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 4.3812e-08 - val_loss: 4.5362e-08 - lr: 0.0073\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 4.4046e-08 - val_loss: 4.1149e-08 - lr: 0.0066\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 4.0005e-08 - val_loss: 4.0002e-08 - lr: 0.0066\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.9517e-08 - val_loss: 4.0785e-08 - lr: 0.0066\n",
      "Epoch 68/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 15ms/step - loss: 4.1468e-08 - val_loss: 4.9136e-08 - lr: 0.0066\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 3.9513e-08 - val_loss: 4.1903e-08 - lr: 0.0066\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.7363e-08 - val_loss: 3.7930e-08 - lr: 0.0059\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.6429e-08 - val_loss: 3.9799e-08 - lr: 0.0059\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 3.7515e-08 - val_loss: 4.2115e-08 - lr: 0.0059\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.7119e-08 - val_loss: 4.0960e-08 - lr: 0.0059\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.6341e-08 - val_loss: 3.7188e-08 - lr: 0.0059\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.6564e-08 - val_loss: 3.8841e-08 - lr: 0.0059\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.5011e-08 - val_loss: 3.6855e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.5524e-08 - val_loss: 3.7663e-08 - lr: 0.0053\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.5186e-08 - val_loss: 3.7238e-08 - lr: 0.0053\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.3893e-08 - val_loss: 3.5288e-08 - lr: 0.0053\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.4669e-08 - val_loss: 3.4987e-08 - lr: 0.0053\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.3025e-08 - val_loss: 3.4967e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.2758e-08 - val_loss: 3.5690e-08 - lr: 0.0048\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.3388e-08 - val_loss: 3.4156e-08 - lr: 0.0048\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 3.2818e-08 - val_loss: 3.5092e-08 - lr: 0.0048\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.3111e-08 - val_loss: 3.7717e-08 - lr: 0.0048\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.3117e-08 - val_loss: 3.6108e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.1926e-08 - val_loss: 3.3428e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 3.1047e-08 - val_loss: 3.3499e-08 - lr: 0.0043\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 3.1069e-08 - val_loss: 3.2854e-08 - lr: 0.0043\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.0865e-08 - val_loss: 3.2720e-08 - lr: 0.0043\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 3.0556e-08 - val_loss: 3.2407e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.0267e-08 - val_loss: 3.2980e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 3.1170e-08 - val_loss: 3.2113e-08 - lr: 0.0039\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.9900e-08 - val_loss: 3.3459e-08 - lr: 0.0039\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.9920e-08 - val_loss: 3.1472e-08 - lr: 0.0039\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.9445e-08 - val_loss: 3.1655e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.9244e-08 - val_loss: 3.1309e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 2.9093e-08 - val_loss: 3.1202e-08 - lr: 0.0035\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.9237e-08 - val_loss: 3.1882e-08 - lr: 0.0035\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.9530e-08 - val_loss: 3.1660e-08 - lr: 0.0035\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.8570e-08 - val_loss: 3.1058e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 2.8270e-08 - val_loss: 3.0491e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.8572e-08 - val_loss: 3.0453e-08 - lr: 0.0031\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 2s 18ms/step - loss: 2.8116e-08 - val_loss: 3.0477e-08 - lr: 0.0031\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.8196e-08 - val_loss: 3.0783e-08 - lr: 0.0031\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.7874e-08 - val_loss: 2.9936e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 2.7656e-08 - val_loss: 2.9993e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.7954e-08 - val_loss: 2.9890e-08 - lr: 0.0028\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.7686e-08 - val_loss: 3.0333e-08 - lr: 0.0028\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.7485e-08 - val_loss: 2.9939e-08 - lr: 0.0028\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.7055e-08 - val_loss: 2.9214e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6969e-08 - val_loss: 2.9208e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.7169e-08 - val_loss: 2.9441e-08 - lr: 0.0025\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6935e-08 - val_loss: 2.9529e-08 - lr: 0.0025\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6944e-08 - val_loss: 2.9495e-08 - lr: 0.0025\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.6700e-08 - val_loss: 2.9087e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6587e-08 - val_loss: 2.9102e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.6643e-08 - val_loss: 2.8739e-08 - lr: 0.0023\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6505e-08 - val_loss: 2.8669e-08 - lr: 0.0023\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.6352e-08 - val_loss: 2.8719e-08 - lr: 0.0023\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6321e-08 - val_loss: 2.8996e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.6356e-08 - val_loss: 2.8641e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6093e-08 - val_loss: 2.8255e-08 - lr: 0.0021\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 2.6112e-08 - val_loss: 2.8321e-08 - lr: 0.0021\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.6001e-08 - val_loss: 2.8305e-08 - lr: 0.0021\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.6023e-08 - val_loss: 2.8066e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5843e-08 - val_loss: 2.8583e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.5935e-08 - val_loss: 2.8325e-08 - lr: 0.0019\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.5816e-08 - val_loss: 2.7973e-08 - lr: 0.0019\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 2.5710e-08 - val_loss: 2.7889e-08 - lr: 0.0019\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5531e-08 - val_loss: 2.8045e-08 - lr: 0.0019\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.5536e-08 - val_loss: 2.7846e-08 - lr: 0.0019\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.5470e-08 - val_loss: 2.7835e-08 - lr: 0.0019\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 2.5398e-08 - val_loss: 2.7823e-08 - lr: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5332e-08 - val_loss: 2.7572e-08 - lr: 0.0019\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5266e-08 - val_loss: 2.7614e-08 - lr: 0.0017\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5200e-08 - val_loss: 2.7758e-08 - lr: 0.0017\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 2.5198e-08 - val_loss: 2.7722e-08 - lr: 0.0017\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5147e-08 - val_loss: 2.7296e-08 - lr: 0.0017\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.5050e-08 - val_loss: 2.7497e-08 - lr: 0.0017\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4970e-08 - val_loss: 2.7308e-08 - lr: 0.0015\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4939e-08 - val_loss: 2.7242e-08 - lr: 0.0015\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4879e-08 - val_loss: 2.7297e-08 - lr: 0.0015\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4856e-08 - val_loss: 2.7089e-08 - lr: 0.0015\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4819e-08 - val_loss: 2.7153e-08 - lr: 0.0015\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4717e-08 - val_loss: 2.7029e-08 - lr: 0.0014\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 2.4693e-08 - val_loss: 2.7097e-08 - lr: 0.0014\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4620e-08 - val_loss: 2.7061e-08 - lr: 0.0014\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.4703e-08 - val_loss: 2.6890e-08 - lr: 0.0014\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.4618e-08 - val_loss: 2.6870e-08 - lr: 0.0014\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4557e-08 - val_loss: 2.6886e-08 - lr: 0.0012\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4521e-08 - val_loss: 2.7356e-08 - lr: 0.0012\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4541e-08 - val_loss: 2.6790e-08 - lr: 0.0012\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4392e-08 - val_loss: 2.6665e-08 - lr: 0.0012\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 2s 17ms/step - loss: 2.4402e-08 - val_loss: 2.6811e-08 - lr: 0.0012\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4371e-08 - val_loss: 2.6686e-08 - lr: 0.0011\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 2.4284e-08 - val_loss: 2.6783e-08 - lr: 0.0011\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4308e-08 - val_loss: 2.6784e-08 - lr: 0.0011\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 16ms/step - loss: 2.4244e-08 - val_loss: 2.6495e-08 - lr: 0.0011\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4182e-08 - val_loss: 2.6420e-08 - lr: 0.0011\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4147e-08 - val_loss: 2.6477e-08 - lr: 9.8477e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4148e-08 - val_loss: 2.6511e-08 - lr: 9.8477e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4154e-08 - val_loss: 2.6351e-08 - lr: 9.8477e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 2s 16ms/step - loss: 2.4054e-08 - val_loss: 2.6377e-08 - lr: 9.8477e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.4042e-08 - val_loss: 2.6321e-08 - lr: 9.8477e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.3979e-08 - val_loss: 2.6491e-08 - lr: 8.8629e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.3977e-08 - val_loss: 2.6364e-08 - lr: 8.8629e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.3948e-08 - val_loss: 2.6363e-08 - lr: 8.8629e-04\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "emulator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0., 0., 1., 1.])\n",
    "ax.plot(emulator.train_losses, label='Training')\n",
    "ax.plot(emulator.val_losses, label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42331116273999214\n"
     ]
    }
   ],
   "source": [
    "rmse = emulator.compute_rms_error()\n",
    "print(rmse.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "Model Compiled: Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.5068e-05 - val_loss: 1.4378e-05 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7972e-06 - val_loss: 4.3855e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3301e-06 - val_loss: 2.3909e-06 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9150e-06 - val_loss: 1.6131e-06 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3734e-06 - val_loss: 1.1019e-06 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0632e-06 - val_loss: 8.7190e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6662e-07 - val_loss: 6.8626e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6766e-07 - val_loss: 5.7097e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.9409e-07 - val_loss: 4.8639e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9678e-07 - val_loss: 6.0835e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7694e-07 - val_loss: 4.1887e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2118e-07 - val_loss: 3.2033e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3927e-07 - val_loss: 3.2807e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0195e-07 - val_loss: 3.5966e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3865e-07 - val_loss: 2.7198e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7498e-07 - val_loss: 2.6876e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6872e-07 - val_loss: 2.7163e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9478e-07 - val_loss: 3.5461e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1257e-07 - val_loss: 1.8076e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4450e-07 - val_loss: 2.7803e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2721e-07 - val_loss: 1.6312e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8010e-07 - val_loss: 1.7811e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5259e-07 - val_loss: 4.3887e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2418e-07 - val_loss: 1.9759e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8058e-07 - val_loss: 1.5927e-07 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4460e-07 - val_loss: 1.2563e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9836e-07 - val_loss: 1.2448e-07 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2901e-07 - val_loss: 1.1899e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3913e-07 - val_loss: 1.4514e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.6340e-07 - val_loss: 1.3327e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7623e-07 - val_loss: 1.1640e-07 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0041e-07 - val_loss: 9.1690e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.6844e-08 - val_loss: 8.7386e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.0256e-08 - val_loss: 8.1264e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.6427e-08 - val_loss: 9.2345e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0637e-07 - val_loss: 1.6854e-07 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0281e-07 - val_loss: 1.0292e-07 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0989e-07 - val_loss: 1.0273e-07 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.0556e-08 - val_loss: 1.0723e-07 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.4472e-08 - val_loss: 7.2811e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.0797e-08 - val_loss: 6.5897e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0744e-08 - val_loss: 8.3392e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4543e-08 - val_loss: 1.1876e-07 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7530e-08 - val_loss: 6.1083e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1442e-08 - val_loss: 6.7255e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3941e-08 - val_loss: 9.7987e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.6084e-08 - val_loss: 5.9769e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.8911e-08 - val_loss: 6.9011e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8845e-08 - val_loss: 6.7420e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.6101e-08 - val_loss: 6.3185e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.4715e-08 - val_loss: 5.5672e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3292e-08 - val_loss: 7.6867e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.4447e-08 - val_loss: 5.1397e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3163e-08 - val_loss: 5.8020e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6957e-08 - val_loss: 1.0793e-07 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.1274e-08 - val_loss: 5.8909e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.9800e-08 - val_loss: 4.9663e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.9451e-08 - val_loss: 4.9380e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6221e-08 - val_loss: 4.6838e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.5368e-08 - val_loss: 5.0861e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.5991e-08 - val_loss: 4.4495e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4486e-08 - val_loss: 4.7541e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3067e-08 - val_loss: 5.1209e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.7776e-08 - val_loss: 5.2940e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.5969e-08 - val_loss: 4.4232e-08 - lr: 0.0066\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.6181e-08 - val_loss: 5.2424e-08 - lr: 0.0066\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.2273e-08 - val_loss: 4.4855e-08 - lr: 0.0059\n",
      "Epoch 68/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 10ms/step - loss: 4.2539e-08 - val_loss: 4.4523e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0068e-08 - val_loss: 4.1856e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9683e-08 - val_loss: 3.9347e-08 - lr: 0.0059\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9079e-08 - val_loss: 4.1489e-08 - lr: 0.0059\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8292e-08 - val_loss: 3.9121e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7420e-08 - val_loss: 4.1680e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.8985e-08 - val_loss: 4.4715e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3646e-08 - val_loss: 5.2198e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8052e-08 - val_loss: 3.8732e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7957e-08 - val_loss: 3.9966e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.6853e-08 - val_loss: 3.7737e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.6168e-08 - val_loss: 3.8640e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.6134e-08 - val_loss: 3.6639e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5547e-08 - val_loss: 3.7682e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.4228e-08 - val_loss: 3.5727e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.4768e-08 - val_loss: 3.5158e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4464e-08 - val_loss: 3.5333e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3978e-08 - val_loss: 3.4850e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4387e-08 - val_loss: 3.4600e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2662e-08 - val_loss: 3.4525e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2659e-08 - val_loss: 3.3857e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2410e-08 - val_loss: 3.4520e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2623e-08 - val_loss: 3.4329e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2160e-08 - val_loss: 3.4037e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2454e-08 - val_loss: 3.3419e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1874e-08 - val_loss: 3.3315e-08 - lr: 0.0039\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2317e-08 - val_loss: 3.6492e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1380e-08 - val_loss: 3.2483e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0931e-08 - val_loss: 3.2666e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1513e-08 - val_loss: 3.3181e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0862e-08 - val_loss: 3.2802e-08 - lr: 0.0035\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0563e-08 - val_loss: 3.3611e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0420e-08 - val_loss: 3.2335e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1064e-08 - val_loss: 3.3133e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0112e-08 - val_loss: 3.1774e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0165e-08 - val_loss: 3.1834e-08 - lr: 0.0031\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9655e-08 - val_loss: 3.2160e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9739e-08 - val_loss: 3.1627e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9419e-08 - val_loss: 3.1340e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9382e-08 - val_loss: 3.1464e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9659e-08 - val_loss: 3.3274e-08 - lr: 0.0028\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9152e-08 - val_loss: 3.1052e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8897e-08 - val_loss: 3.0473e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8981e-08 - val_loss: 3.2191e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8675e-08 - val_loss: 3.0443e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8505e-08 - val_loss: 3.0483e-08 - lr: 0.0025\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8531e-08 - val_loss: 3.0210e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8201e-08 - val_loss: 2.9829e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8140e-08 - val_loss: 3.0255e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8429e-08 - val_loss: 2.9951e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8468e-08 - val_loss: 2.9842e-08 - lr: 0.0023\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7930e-08 - val_loss: 3.0268e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7895e-08 - val_loss: 2.9892e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7736e-08 - val_loss: 2.9958e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7828e-08 - val_loss: 2.9858e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7760e-08 - val_loss: 2.9399e-08 - lr: 0.0021\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7396e-08 - val_loss: 2.9290e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7500e-08 - val_loss: 2.9352e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7315e-08 - val_loss: 2.9096e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7310e-08 - val_loss: 2.9493e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7214e-08 - val_loss: 2.9201e-08 - lr: 0.0019\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7137e-08 - val_loss: 2.8827e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7182e-08 - val_loss: 2.8784e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7043e-08 - val_loss: 2.8846e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6985e-08 - val_loss: 2.9055e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7002e-08 - val_loss: 2.8683e-08 - lr: 0.0017\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6776e-08 - val_loss: 2.9014e-08 - lr: 0.0015\n",
      "Epoch 135/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6779e-08 - val_loss: 2.8661e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6694e-08 - val_loss: 2.8580e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6647e-08 - val_loss: 2.8908e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6625e-08 - val_loss: 2.9445e-08 - lr: 0.0015\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6523e-08 - val_loss: 2.8444e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6493e-08 - val_loss: 2.8290e-08 - lr: 0.0014\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6393e-08 - val_loss: 2.8555e-08 - lr: 0.0014\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6388e-08 - val_loss: 2.8181e-08 - lr: 0.0014\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6332e-08 - val_loss: 2.8603e-08 - lr: 0.0014\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6215e-08 - val_loss: 2.8207e-08 - lr: 0.0012\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6112e-08 - val_loss: 2.8366e-08 - lr: 0.0012\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6143e-08 - val_loss: 2.8023e-08 - lr: 0.0012\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6130e-08 - val_loss: 2.8205e-08 - lr: 0.0012\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6073e-08 - val_loss: 2.7943e-08 - lr: 0.0012\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6004e-08 - val_loss: 2.8210e-08 - lr: 0.0011\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5968e-08 - val_loss: 2.7837e-08 - lr: 0.0011\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6052e-08 - val_loss: 2.7968e-08 - lr: 0.0011\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5924e-08 - val_loss: 2.7725e-08 - lr: 0.0011\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5827e-08 - val_loss: 2.7893e-08 - lr: 0.0011\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5774e-08 - val_loss: 2.7832e-08 - lr: 9.8477e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5775e-08 - val_loss: 2.7817e-08 - lr: 9.8477e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5695e-08 - val_loss: 2.7844e-08 - lr: 9.8477e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5728e-08 - val_loss: 2.7769e-08 - lr: 9.8477e-04\n",
      "Early Stopping\n",
      "Saving first emulator\n",
      "i =  1\n",
      "Model Compiled: Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.6243e-05 - val_loss: 1.5225e-05 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.2500e-06 - val_loss: 4.7878e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2170e-06 - val_loss: 2.2770e-06 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9991e-06 - val_loss: 1.4993e-06 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5121e-06 - val_loss: 1.5770e-06 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0801e-06 - val_loss: 9.3304e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5288e-07 - val_loss: 7.0997e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1694e-07 - val_loss: 7.4567e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9853e-07 - val_loss: 5.2670e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.6430e-07 - val_loss: 6.1084e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.1103e-07 - val_loss: 4.1376e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0256e-07 - val_loss: 3.1251e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.2813e-07 - val_loss: 3.1014e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4841e-07 - val_loss: 2.5637e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.3626e-07 - val_loss: 2.7016e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9702e-07 - val_loss: 2.7563e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7647e-07 - val_loss: 4.0202e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6145e-07 - val_loss: 4.8835e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6000e-07 - val_loss: 3.1843e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9706e-07 - val_loss: 1.9398e-07 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7449e-07 - val_loss: 1.5813e-07 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7518e-07 - val_loss: 1.8414e-07 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9496e-07 - val_loss: 1.8286e-07 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7033e-07 - val_loss: 1.3062e-07 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7477e-07 - val_loss: 1.1994e-07 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5672e-07 - val_loss: 1.3556e-07 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3210e-07 - val_loss: 1.6241e-07 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3629e-07 - val_loss: 1.1834e-07 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6192e-07 - val_loss: 1.1029e-07 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5517e-07 - val_loss: 1.2734e-07 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0795e-07 - val_loss: 9.2928e-08 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9886e-08 - val_loss: 9.9819e-08 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1244e-07 - val_loss: 1.6685e-07 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4882e-08 - val_loss: 8.7348e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0073e-07 - val_loss: 7.9808e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8287e-08 - val_loss: 9.2734e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0950e-07 - val_loss: 9.0283e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0048e-08 - val_loss: 9.3556e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3116e-07 - val_loss: 2.2580e-07 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1152e-07 - val_loss: 1.2255e-07 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0435e-08 - val_loss: 7.3824e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2637e-08 - val_loss: 7.4856e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6940e-08 - val_loss: 1.0378e-07 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.3113e-08 - val_loss: 7.2633e-08 - lr: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6271e-08 - val_loss: 6.4266e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2407e-08 - val_loss: 1.2491e-07 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1504e-07 - val_loss: 7.0329e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9656e-08 - val_loss: 6.6412e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1338e-08 - val_loss: 7.2436e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.5602e-08 - val_loss: 6.3340e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5049e-08 - val_loss: 6.7882e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5014e-08 - val_loss: 5.8439e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8780e-08 - val_loss: 7.3019e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.8152e-08 - val_loss: 5.3204e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1670e-08 - val_loss: 5.6155e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.3476e-08 - val_loss: 5.3983e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.3704e-08 - val_loss: 5.1933e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.2774e-08 - val_loss: 6.1249e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5315e-08 - val_loss: 6.0775e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9706e-08 - val_loss: 5.0191e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.1000e-08 - val_loss: 5.3676e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5863e-08 - val_loss: 5.4699e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8271e-08 - val_loss: 4.6691e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4856e-08 - val_loss: 4.6132e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.4848e-08 - val_loss: 4.6495e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.4276e-08 - val_loss: 4.4166e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3419e-08 - val_loss: 5.3402e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.2717e-08 - val_loss: 4.3491e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2257e-08 - val_loss: 5.0181e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1243e-08 - val_loss: 4.3441e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.2009e-08 - val_loss: 4.4068e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.1202e-08 - val_loss: 4.4921e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1574e-08 - val_loss: 4.1906e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.1018e-08 - val_loss: 4.2791e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.0160e-08 - val_loss: 4.3131e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0916e-08 - val_loss: 4.0287e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.9836e-08 - val_loss: 4.2212e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.9853e-08 - val_loss: 4.4926e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.8122e-08 - val_loss: 3.8916e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.7842e-08 - val_loss: 4.0639e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.7529e-08 - val_loss: 3.8784e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7130e-08 - val_loss: 3.9854e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.0983e-08 - val_loss: 3.8254e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6124e-08 - val_loss: 3.9514e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6138e-08 - val_loss: 3.7448e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6326e-08 - val_loss: 4.0754e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6339e-08 - val_loss: 3.7948e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.5066e-08 - val_loss: 3.8423e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4373e-08 - val_loss: 3.6287e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5758e-08 - val_loss: 3.7482e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.4199e-08 - val_loss: 3.6327e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.4313e-08 - val_loss: 3.5965e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.3606e-08 - val_loss: 3.5624e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.3263e-08 - val_loss: 3.6172e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3262e-08 - val_loss: 3.9213e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3057e-08 - val_loss: 3.5572e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3190e-08 - val_loss: 3.4842e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2310e-08 - val_loss: 3.5040e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2349e-08 - val_loss: 3.4671e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2220e-08 - val_loss: 3.5251e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1900e-08 - val_loss: 3.4370e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1681e-08 - val_loss: 3.4566e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2220e-08 - val_loss: 3.4325e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1452e-08 - val_loss: 3.5179e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1148e-08 - val_loss: 3.3694e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1376e-08 - val_loss: 3.3745e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0977e-08 - val_loss: 3.3936e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0939e-08 - val_loss: 3.4580e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0842e-08 - val_loss: 3.3565e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0534e-08 - val_loss: 3.2746e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0285e-08 - val_loss: 3.3038e-08 - lr: 0.0023\n",
      "Epoch 112/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0503e-08 - val_loss: 3.3060e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0315e-08 - val_loss: 3.2678e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0005e-08 - val_loss: 3.2669e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0047e-08 - val_loss: 3.3130e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0107e-08 - val_loss: 3.2142e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9787e-08 - val_loss: 3.1938e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9796e-08 - val_loss: 3.1938e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9433e-08 - val_loss: 3.1944e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9576e-08 - val_loss: 3.1776e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9519e-08 - val_loss: 3.1744e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9424e-08 - val_loss: 3.1992e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9135e-08 - val_loss: 3.1564e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9172e-08 - val_loss: 3.1823e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9126e-08 - val_loss: 3.1291e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8988e-08 - val_loss: 3.1327e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8926e-08 - val_loss: 3.1371e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8844e-08 - val_loss: 3.1337e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8712e-08 - val_loss: 3.1164e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8837e-08 - val_loss: 3.1504e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8533e-08 - val_loss: 3.1091e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8694e-08 - val_loss: 3.1359e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8536e-08 - val_loss: 3.0797e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8354e-08 - val_loss: 3.0862e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8327e-08 - val_loss: 3.0752e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8232e-08 - val_loss: 3.0501e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8109e-08 - val_loss: 3.0843e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8143e-08 - val_loss: 3.0526e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8034e-08 - val_loss: 3.0666e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8151e-08 - val_loss: 3.0790e-08 - lr: 0.0014\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7992e-08 - val_loss: 3.0605e-08 - lr: 0.0012\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7952e-08 - val_loss: 3.0501e-08 - lr: 0.0012\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7789e-08 - val_loss: 3.0809e-08 - lr: 0.0012\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7792e-08 - val_loss: 3.0297e-08 - lr: 0.0012\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7713e-08 - val_loss: 3.0460e-08 - lr: 0.0012\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7694e-08 - val_loss: 3.0069e-08 - lr: 0.0011\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7605e-08 - val_loss: 3.0365e-08 - lr: 0.0011\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7562e-08 - val_loss: 3.0364e-08 - lr: 0.0011\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7557e-08 - val_loss: 2.9983e-08 - lr: 0.0011\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7444e-08 - val_loss: 3.0041e-08 - lr: 0.0011\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7417e-08 - val_loss: 2.9892e-08 - lr: 9.8477e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7341e-08 - val_loss: 2.9888e-08 - lr: 9.8477e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7363e-08 - val_loss: 2.9831e-08 - lr: 9.8477e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7327e-08 - val_loss: 2.9769e-08 - lr: 9.8477e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7314e-08 - val_loss: 2.9848e-08 - lr: 9.8477e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7234e-08 - val_loss: 2.9859e-08 - lr: 8.8629e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7259e-08 - val_loss: 2.9689e-08 - lr: 8.8629e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7131e-08 - val_loss: 2.9649e-08 - lr: 8.8629e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7149e-08 - val_loss: 2.9725e-08 - lr: 8.8629e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7079e-08 - val_loss: 2.9642e-08 - lr: 8.8629e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7072e-08 - val_loss: 2.9538e-08 - lr: 7.9766e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6983e-08 - val_loss: 2.9531e-08 - lr: 7.9766e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7017e-08 - val_loss: 2.9467e-08 - lr: 7.9766e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6958e-08 - val_loss: 2.9481e-08 - lr: 7.9766e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6938e-08 - val_loss: 2.9457e-08 - lr: 7.9766e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6899e-08 - val_loss: 2.9486e-08 - lr: 7.1790e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6862e-08 - val_loss: 2.9441e-08 - lr: 7.1790e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6877e-08 - val_loss: 2.9240e-08 - lr: 7.1790e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6790e-08 - val_loss: 2.9264e-08 - lr: 7.1790e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6788e-08 - val_loss: 2.9241e-08 - lr: 7.1790e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6713e-08 - val_loss: 2.9178e-08 - lr: 6.4611e-04\n",
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6688e-08 - val_loss: 2.9251e-08 - lr: 6.4611e-04\n",
      "Epoch 173/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6690e-08 - val_loss: 2.9537e-08 - lr: 6.4611e-04\n",
      "Epoch 174/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6663e-08 - val_loss: 2.9165e-08 - lr: 6.4611e-04\n",
      "Epoch 175/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6659e-08 - val_loss: 2.9305e-08 - lr: 6.4611e-04\n",
      "Epoch 176/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6616e-08 - val_loss: 2.9155e-08 - lr: 5.8150e-04\n",
      "Early Stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_432818/3588482441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving first emulator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0memulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_em_nov7_0.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving new best emulator: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'best_em_nov7_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rms' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "errs = np.empty((20, 1704))\n",
    "for i in range(20):\n",
    "    print('i = ', i)\n",
    "    emulator = VAE.VeryAccurateEmulator()\n",
    "    emulator.train()\n",
    "    rmse = emulator.compute_rms_error()\n",
    "    errs[i] = rmse\n",
    "    if i == 0:\n",
    "        print('Saving first emulator')\n",
    "        emulator.emulator.save('best_em_nov7_0.h5')\n",
    "    elif np.mean(rmse) < np.mean(errs[:i], axis=1).min():\n",
    "        print('Saving new best emulator: ', i)\n",
    "        fname = 'best_em_nov7_' + str(i) +'.h5'\n",
    "        emulator.emulator.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nov7_manyems.npy', errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(errs, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator_env",
   "language": "python",
   "name": "emulator_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
