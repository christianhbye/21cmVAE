{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from VeryAccurateEmulator import emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Autoencoder-based Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 14:07:58.873808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s/sievers/cbye/lib:/home/s/sievers/cbye/lib:/opt/slurm/lib64:/scinet/niagara/software/2019b/core/lib64\n",
      "2021-11-09 14:07:58.873846: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-09 14:07:58.873869: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nia-jupyter.scinet.local): /proc/driver/nvidia/version does not exist\n",
      "2021-11-09 14:07:58.874135: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 2s 11ms/step - loss: 2.0924e-05 - val_loss: 2.2215e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3979e-06 - val_loss: 8.3257e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.9740e-07 - val_loss: 7.0352e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 4.6697e-07 - val_loss: 3.7079e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.0136e-07 - val_loss: 3.0858e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4743e-07 - val_loss: 2.0574e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9008e-07 - val_loss: 1.8753e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7050e-07 - val_loss: 1.5241e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4811e-07 - val_loss: 1.3979e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9175e-07 - val_loss: 1.4626e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3980e-07 - val_loss: 1.3441e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2195e-07 - val_loss: 1.0370e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.3621e-07 - val_loss: 1.3376e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.2098e-07 - val_loss: 9.4620e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1434e-07 - val_loss: 1.3328e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9717e-08 - val_loss: 7.9481e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0161e-07 - val_loss: 8.8034e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0963e-07 - val_loss: 7.0033e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.8200e-08 - val_loss: 8.0375e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.0229e-07 - val_loss: 1.1752e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 7.0498e-08 - val_loss: 6.2323e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.0530e-07 - val_loss: 6.5682e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.4382e-08 - val_loss: 5.5386e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.1267e-08 - val_loss: 5.2330e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.7899e-08 - val_loss: 7.7608e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0569e-07 - val_loss: 1.8321e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4188e-07 - val_loss: 5.4361e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1757e-08 - val_loss: 5.0085e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1577e-08 - val_loss: 4.9128e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.0434e-08 - val_loss: 5.2782e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.3866e-08 - val_loss: 5.5532e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3082e-08 - val_loss: 4.1921e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3692e-08 - val_loss: 3.7692e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 5.1261e-08 - val_loss: 5.6950e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.7867e-08 - val_loss: 7.2007e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6756e-08 - val_loss: 9.6637e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3272e-08 - val_loss: 8.8317e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.9866e-08 - val_loss: 3.1946e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.1111e-08 - val_loss: 3.4981e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.1945e-08 - val_loss: 2.9570e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.0485e-08 - val_loss: 4.1254e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.1017e-08 - val_loss: 2.8577e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.4890e-08 - val_loss: 3.0199e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9517e-08 - val_loss: 3.3215e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8242e-08 - val_loss: 2.9834e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7223e-08 - val_loss: 2.6463e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5933e-08 - val_loss: 2.7343e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1042e-08 - val_loss: 2.7432e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1157e-08 - val_loss: 2.7905e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7922e-08 - val_loss: 3.2616e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9987e-08 - val_loss: 2.6107e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4032e-08 - val_loss: 2.4062e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4061e-08 - val_loss: 2.4036e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3719e-08 - val_loss: 2.7341e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4106e-08 - val_loss: 2.3865e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5691e-08 - val_loss: 2.6485e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2856e-08 - val_loss: 2.2276e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1958e-08 - val_loss: 2.1925e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1742e-08 - val_loss: 2.2102e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2136e-08 - val_loss: 2.2968e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3343e-08 - val_loss: 2.3215e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1681e-08 - val_loss: 2.1333e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0793e-08 - val_loss: 2.1271e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0474e-08 - val_loss: 2.0961e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0267e-08 - val_loss: 2.0537e-08 - lr: 0.0059\n",
      "Epoch 66/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0216e-08 - val_loss: 2.0314e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9900e-08 - val_loss: 2.0169e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9572e-08 - val_loss: 2.0620e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9672e-08 - val_loss: 1.9837e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9446e-08 - val_loss: 1.9565e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9203e-08 - val_loss: 1.9324e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9263e-08 - val_loss: 1.9439e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8913e-08 - val_loss: 1.9031e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8766e-08 - val_loss: 1.8719e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8589e-08 - val_loss: 1.8677e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8473e-08 - val_loss: 1.8606e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8441e-08 - val_loss: 1.8263e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8065e-08 - val_loss: 1.8406e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8044e-08 - val_loss: 1.8358e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7958e-08 - val_loss: 1.8010e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7911e-08 - val_loss: 1.8302e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7760e-08 - val_loss: 1.8142e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7614e-08 - val_loss: 1.7776e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7503e-08 - val_loss: 1.7497e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7408e-08 - val_loss: 1.7480e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7277e-08 - val_loss: 1.7543e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7276e-08 - val_loss: 1.7756e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7149e-08 - val_loss: 1.7372e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7034e-08 - val_loss: 1.7262e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6969e-08 - val_loss: 1.7357e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6908e-08 - val_loss: 1.7167e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6895e-08 - val_loss: 1.6994e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6700e-08 - val_loss: 1.6806e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6605e-08 - val_loss: 1.6927e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6560e-08 - val_loss: 1.6677e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6524e-08 - val_loss: 1.6731e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6469e-08 - val_loss: 1.6622e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6346e-08 - val_loss: 1.6675e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6327e-08 - val_loss: 1.6502e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6255e-08 - val_loss: 1.6570e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6245e-08 - val_loss: 1.6446e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6115e-08 - val_loss: 1.6312e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6107e-08 - val_loss: 1.6241e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6085e-08 - val_loss: 1.6413e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6048e-08 - val_loss: 1.6292e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5960e-08 - val_loss: 1.6152e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5899e-08 - val_loss: 1.6100e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5794e-08 - val_loss: 1.6050e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5794e-08 - val_loss: 1.5960e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5757e-08 - val_loss: 1.5890e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5733e-08 - val_loss: 1.5862e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5656e-08 - val_loss: 1.5752e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5588e-08 - val_loss: 1.5751e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5524e-08 - val_loss: 1.5762e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5513e-08 - val_loss: 1.5676e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5479e-08 - val_loss: 1.5665e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5429e-08 - val_loss: 1.5725e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5382e-08 - val_loss: 1.5500e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5316e-08 - val_loss: 1.5428e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5298e-08 - val_loss: 1.5517e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5259e-08 - val_loss: 1.5443e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5211e-08 - val_loss: 1.5376e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5182e-08 - val_loss: 1.5393e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5155e-08 - val_loss: 1.5305e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5139e-08 - val_loss: 1.5262e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5105e-08 - val_loss: 1.5241e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5067e-08 - val_loss: 1.5255e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5040e-08 - val_loss: 1.5164e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5017e-08 - val_loss: 1.5124e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4974e-08 - val_loss: 1.5083e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4972e-08 - val_loss: 1.5119e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4930e-08 - val_loss: 1.5082e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4916e-08 - val_loss: 1.5018e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4877e-08 - val_loss: 1.5049e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4869e-08 - val_loss: 1.5023e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4816e-08 - val_loss: 1.4942e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4813e-08 - val_loss: 1.4953e-08 - lr: 0.0015\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2451 - val_loss: 0.2122 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1417 - val_loss: 0.0871 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0646 - val_loss: 0.0368 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0625 - val_loss: 0.0627 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0433 - val_loss: 0.0696 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0409 - val_loss: 0.0273 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0258 - val_loss: 0.0564 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0379 - val_loss: 0.0233 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0235 - val_loss: 0.0164 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0212 - val_loss: 0.0167 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0220 - val_loss: 0.0207 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0592 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0579 - val_loss: 0.0233 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0206 - val_loss: 0.0112 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0161 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0094 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.0131 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0242 - val_loss: 0.0523 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0258 - val_loss: 0.0312 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0106 - val_loss: 0.0080 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0066 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0051 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0097 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0124 - val_loss: 0.0189 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0232 - val_loss: 0.0172 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0071 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0354 - val_loss: 0.0321 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0067 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0045 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.0065 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0097 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0088 - val_loss: 0.0114 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0054 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0048 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0046 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0070 - lr: 0.0073\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0106 - lr: 0.0073\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0043 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0050 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0058 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0108 - lr: 0.0066\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0076 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0042 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0058 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0074 - lr: 0.0059\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0073 - lr: 0.0059\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0029 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0064 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0077 - val_loss: 0.0182 - lr: 0.0053\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0041 - lr: 0.0053\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0028 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0029 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0031 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0040 - lr: 0.0048\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0027 - lr: 0.0048\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0036 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0036 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0065 - lr: 0.0043\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0122 - lr: 0.0043\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0048 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0031 - lr: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0048 - lr: 0.0035\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0021 - lr: 0.0031\n",
      "Early Stopping\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3547e-05 - val_loss: 2.6273e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4785e-06 - val_loss: 9.5826e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.5716e-07 - val_loss: 5.1396e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2900e-07 - val_loss: 3.5861e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0041e-07 - val_loss: 3.5782e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6338e-07 - val_loss: 2.3599e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2099e-07 - val_loss: 1.8832e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9330e-07 - val_loss: 1.8224e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0765e-07 - val_loss: 1.7295e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5109e-07 - val_loss: 1.6520e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3518e-07 - val_loss: 1.6972e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2167e-07 - val_loss: 1.0220e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.6283e-08 - val_loss: 9.2040e-08 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.6032e-08 - val_loss: 1.1503e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2598e-07 - val_loss: 8.7255e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5076e-08 - val_loss: 7.7081e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4858e-08 - val_loss: 8.9164e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1812e-07 - val_loss: 8.7578e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1708e-08 - val_loss: 8.9829e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6077e-08 - val_loss: 1.1433e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1021e-07 - val_loss: 2.0983e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1906e-08 - val_loss: 5.3601e-08 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1557e-08 - val_loss: 5.3477e-08 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9620e-08 - val_loss: 5.0084e-08 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7665e-08 - val_loss: 9.4160e-08 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9454e-08 - val_loss: 4.5570e-08 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5216e-08 - val_loss: 5.1011e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8873e-08 - val_loss: 4.7226e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6020e-08 - val_loss: 5.3944e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5275e-08 - val_loss: 4.4175e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.1207e-08 - val_loss: 5.4356e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.9012e-08 - val_loss: 3.9683e-08 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7223e-08 - val_loss: 3.5590e-08 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3379e-08 - val_loss: 4.8215e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8185e-08 - val_loss: 3.6883e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6367e-08 - val_loss: 3.4230e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5890e-08 - val_loss: 3.8525e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1375e-08 - val_loss: 4.3327e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7736e-08 - val_loss: 7.3067e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9994e-08 - val_loss: 3.4030e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3244e-08 - val_loss: 3.3581e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9382e-08 - val_loss: 3.0068e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9428e-08 - val_loss: 3.4141e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.0718e-08 - val_loss: 2.9887e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9209e-08 - val_loss: 3.1264e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1536e-08 - val_loss: 3.0233e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6516e-08 - val_loss: 2.6460e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6165e-08 - val_loss: 2.6705e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6699e-08 - val_loss: 2.5813e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5847e-08 - val_loss: 2.8500e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6048e-08 - val_loss: 2.7841e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7246e-08 - val_loss: 2.5617e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4597e-08 - val_loss: 2.5034e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4093e-08 - val_loss: 2.4502e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3630e-08 - val_loss: 2.4072e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3470e-08 - val_loss: 2.3684e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3485e-08 - val_loss: 2.3758e-08 - lr: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2787e-08 - val_loss: 2.2973e-08 - lr: 0.0053\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2637e-08 - val_loss: 2.3431e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2329e-08 - val_loss: 2.2946e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2287e-08 - val_loss: 2.3001e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1899e-08 - val_loss: 2.2291e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1595e-08 - val_loss: 2.1870e-08 - lr: 0.0048\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1245e-08 - val_loss: 2.1711e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2179e-08 - val_loss: 2.2855e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1667e-08 - val_loss: 2.2035e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0836e-08 - val_loss: 2.1674e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0548e-08 - val_loss: 2.0813e-08 - lr: 0.0043\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0553e-08 - val_loss: 2.1055e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0358e-08 - val_loss: 2.0739e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0113e-08 - val_loss: 2.0769e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0127e-08 - val_loss: 2.0709e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9905e-08 - val_loss: 2.0591e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9895e-08 - val_loss: 2.0125e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9526e-08 - val_loss: 2.0122e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9408e-08 - val_loss: 2.0204e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9365e-08 - val_loss: 1.9865e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9268e-08 - val_loss: 1.9630e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8967e-08 - val_loss: 1.9358e-08 - lr: 0.0035\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8978e-08 - val_loss: 1.9427e-08 - lr: 0.0035\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8884e-08 - val_loss: 1.9969e-08 - lr: 0.0035\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8764e-08 - val_loss: 1.9442e-08 - lr: 0.0035\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8622e-08 - val_loss: 1.9077e-08 - lr: 0.0035\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8457e-08 - val_loss: 1.8942e-08 - lr: 0.0031\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8428e-08 - val_loss: 1.8789e-08 - lr: 0.0031\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8407e-08 - val_loss: 1.8756e-08 - lr: 0.0031\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8255e-08 - val_loss: 1.8790e-08 - lr: 0.0031\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8125e-08 - val_loss: 1.8517e-08 - lr: 0.0031\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8017e-08 - val_loss: 1.8671e-08 - lr: 0.0028\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7962e-08 - val_loss: 1.8449e-08 - lr: 0.0028\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7879e-08 - val_loss: 1.8419e-08 - lr: 0.0028\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7774e-08 - val_loss: 1.8305e-08 - lr: 0.0028\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7739e-08 - val_loss: 1.8374e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7574e-08 - val_loss: 1.8134e-08 - lr: 0.0025\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7573e-08 - val_loss: 1.8130e-08 - lr: 0.0025\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7525e-08 - val_loss: 1.8014e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7440e-08 - val_loss: 1.7889e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7452e-08 - val_loss: 1.7887e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7281e-08 - val_loss: 1.7674e-08 - lr: 0.0023\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7212e-08 - val_loss: 1.7841e-08 - lr: 0.0023\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7211e-08 - val_loss: 1.7790e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7126e-08 - val_loss: 1.7739e-08 - lr: 0.0023\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7080e-08 - val_loss: 1.7663e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6990e-08 - val_loss: 1.7435e-08 - lr: 0.0021\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6924e-08 - val_loss: 1.7512e-08 - lr: 0.0021\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6918e-08 - val_loss: 1.7505e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6844e-08 - val_loss: 1.7404e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6817e-08 - val_loss: 1.7255e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6763e-08 - val_loss: 1.7448e-08 - lr: 0.0019\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6684e-08 - val_loss: 1.7242e-08 - lr: 0.0019\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6666e-08 - val_loss: 1.7207e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6616e-08 - val_loss: 1.7187e-08 - lr: 0.0019\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6564e-08 - val_loss: 1.7039e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6515e-08 - val_loss: 1.7001e-08 - lr: 0.0017\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6459e-08 - val_loss: 1.6927e-08 - lr: 0.0017\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6421e-08 - val_loss: 1.6916e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6417e-08 - val_loss: 1.6896e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6389e-08 - val_loss: 1.6916e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6331e-08 - val_loss: 1.6868e-08 - lr: 0.0015\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6281e-08 - val_loss: 1.6746e-08 - lr: 0.0015\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6234e-08 - val_loss: 1.6785e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6217e-08 - val_loss: 1.6659e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6208e-08 - val_loss: 1.6799e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6137e-08 - val_loss: 1.6660e-08 - lr: 0.0014\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6107e-08 - val_loss: 1.6613e-08 - lr: 0.0014\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6089e-08 - val_loss: 1.6584e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6058e-08 - val_loss: 1.6537e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6044e-08 - val_loss: 1.6539e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5991e-08 - val_loss: 1.6484e-08 - lr: 0.0012\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5970e-08 - val_loss: 1.6458e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6180 - val_loss: 0.2000 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1326 - val_loss: 0.0841 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0632 - val_loss: 0.0734 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0509 - val_loss: 0.0314 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0350 - val_loss: 0.0331 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0359 - val_loss: 0.0422 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0307 - val_loss: 0.0190 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0319 - val_loss: 0.0176 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0248 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0138 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0241 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0267 - val_loss: 0.0111 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0146 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0228 - val_loss: 0.0346 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0212 - val_loss: 0.0236 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0143 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0064 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0180 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0152 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0154 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0111 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0255 - val_loss: 0.0180 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0079 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0119 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0088 - val_loss: 0.0060 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0140 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0072 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0038 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0043 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0048 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - val_loss: 0.0072 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0100 - val_loss: 0.0133 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0094 - val_loss: 0.0071 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0085 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0075 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0046 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0058 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0038 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0075 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0106 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0047 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0039 - lr: 0.0053\n",
      "Early Stopping\n",
      "2\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4640e-05 - val_loss: 2.5065e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4024e-06 - val_loss: 8.7070e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.8814e-07 - val_loss: 5.5428e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5858e-07 - val_loss: 3.7156e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6420e-07 - val_loss: 7.5884e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9984e-07 - val_loss: 2.3252e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1283e-07 - val_loss: 1.9630e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3770e-07 - val_loss: 2.2857e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7579e-07 - val_loss: 1.6037e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6673e-07 - val_loss: 5.4421e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7216e-07 - val_loss: 1.2179e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1749e-07 - val_loss: 1.2201e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6754e-07 - val_loss: 1.3482e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4697e-07 - val_loss: 1.3047e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1247e-07 - val_loss: 1.0538e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8985e-08 - val_loss: 8.6375e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0510e-07 - val_loss: 9.8004e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3893e-07 - val_loss: 1.9296e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2958e-07 - val_loss: 7.6382e-08 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0614e-08 - val_loss: 6.9191e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3101e-08 - val_loss: 6.4651e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.1241e-08 - val_loss: 1.0455e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4770e-07 - val_loss: 9.9372e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.1666e-08 - val_loss: 6.9604e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.0275e-08 - val_loss: 5.5535e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5678e-08 - val_loss: 5.7282e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4554e-08 - val_loss: 6.3580e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.3266e-08 - val_loss: 5.0020e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9349e-08 - val_loss: 4.8763e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3887e-08 - val_loss: 1.1330e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4063e-08 - val_loss: 5.6608e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0849e-08 - val_loss: 4.2433e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4267e-08 - val_loss: 6.0284e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5933e-08 - val_loss: 4.1116e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1898e-08 - val_loss: 4.8899e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.2837e-08 - val_loss: 4.3058e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8811e-08 - val_loss: 7.6571e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3538e-08 - val_loss: 3.5572e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6048e-08 - val_loss: 3.5832e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6193e-08 - val_loss: 3.9105e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7981e-08 - val_loss: 3.4053e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5221e-08 - val_loss: 3.4202e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3313e-08 - val_loss: 3.3074e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1942e-08 - val_loss: 3.1236e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0755e-08 - val_loss: 3.2278e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0125e-08 - val_loss: 3.1811e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9800e-08 - val_loss: 3.2061e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9806e-08 - val_loss: 3.0699e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1882e-08 - val_loss: 3.0338e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8194e-08 - val_loss: 2.7724e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7815e-08 - val_loss: 2.8964e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7754e-08 - val_loss: 2.7192e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9665e-08 - val_loss: 2.7013e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7878e-08 - val_loss: 2.6814e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6142e-08 - val_loss: 2.6208e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5972e-08 - val_loss: 2.6562e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5652e-08 - val_loss: 2.7332e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5807e-08 - val_loss: 2.5257e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5155e-08 - val_loss: 2.4539e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5166e-08 - val_loss: 2.4703e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5180e-08 - val_loss: 2.5487e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6435e-08 - val_loss: 2.4726e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5143e-08 - val_loss: 2.4302e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3854e-08 - val_loss: 2.3424e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3456e-08 - val_loss: 2.3412e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3089e-08 - val_loss: 2.3092e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3276e-08 - val_loss: 2.2995e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2752e-08 - val_loss: 2.4538e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2327e-08 - val_loss: 2.2480e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2148e-08 - val_loss: 2.2372e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2060e-08 - val_loss: 2.2113e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1689e-08 - val_loss: 2.1759e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1673e-08 - val_loss: 2.1682e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1227e-08 - val_loss: 2.1535e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1234e-08 - val_loss: 2.1448e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1169e-08 - val_loss: 2.1266e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0888e-08 - val_loss: 2.1197e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0691e-08 - val_loss: 2.0848e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0503e-08 - val_loss: 2.0579e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0471e-08 - val_loss: 2.0630e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0281e-08 - val_loss: 2.0449e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0229e-08 - val_loss: 2.0412e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0054e-08 - val_loss: 2.0232e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9946e-08 - val_loss: 2.0356e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9888e-08 - val_loss: 2.0142e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9683e-08 - val_loss: 1.9999e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9667e-08 - val_loss: 2.0360e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9563e-08 - val_loss: 1.9930e-08 - lr: 0.0043\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9316e-08 - val_loss: 2.0081e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9255e-08 - val_loss: 1.9434e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9224e-08 - val_loss: 1.9447e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9062e-08 - val_loss: 1.9122e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8990e-08 - val_loss: 1.9035e-08 - lr: 0.0039\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8820e-08 - val_loss: 1.9220e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8725e-08 - val_loss: 1.8989e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8644e-08 - val_loss: 1.9003e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8592e-08 - val_loss: 1.8666e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8579e-08 - val_loss: 1.8658e-08 - lr: 0.0035\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8375e-08 - val_loss: 1.8553e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8301e-08 - val_loss: 1.8502e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8265e-08 - val_loss: 1.8477e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8177e-08 - val_loss: 1.8380e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8151e-08 - val_loss: 1.8224e-08 - lr: 0.0031\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7990e-08 - val_loss: 1.8096e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7927e-08 - val_loss: 1.8234e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7929e-08 - val_loss: 1.8013e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7834e-08 - val_loss: 1.8043e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7752e-08 - val_loss: 1.7952e-08 - lr: 0.0028\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7707e-08 - val_loss: 1.7830e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7642e-08 - val_loss: 1.7840e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7637e-08 - val_loss: 1.7846e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7530e-08 - val_loss: 1.7703e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7516e-08 - val_loss: 1.7825e-08 - lr: 0.0025\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7444e-08 - val_loss: 1.7611e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7367e-08 - val_loss: 1.7578e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7346e-08 - val_loss: 1.7504e-08 - lr: 0.0023\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7282e-08 - val_loss: 1.7474e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7236e-08 - val_loss: 1.7466e-08 - lr: 0.0023\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7193e-08 - val_loss: 1.7414e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7147e-08 - val_loss: 1.7457e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7119e-08 - val_loss: 1.7296e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7077e-08 - val_loss: 1.7224e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6999e-08 - val_loss: 1.7255e-08 - lr: 0.0021\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6964e-08 - val_loss: 1.7141e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6917e-08 - val_loss: 1.7181e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6901e-08 - val_loss: 1.7118e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6867e-08 - val_loss: 1.7151e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6829e-08 - val_loss: 1.7014e-08 - lr: 0.0019\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6769e-08 - val_loss: 1.6975e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6746e-08 - val_loss: 1.6934e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6709e-08 - val_loss: 1.6899e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6698e-08 - val_loss: 1.6856e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6655e-08 - val_loss: 1.6853e-08 - lr: 0.0017\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6618e-08 - val_loss: 1.6778e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6595e-08 - val_loss: 1.6821e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6576e-08 - val_loss: 1.6810e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6561e-08 - val_loss: 1.6706e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6518e-08 - val_loss: 1.6679e-08 - lr: 0.0015\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6483e-08 - val_loss: 1.6691e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6461e-08 - val_loss: 1.6624e-08 - lr: 0.0014\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6418e-08 - val_loss: 1.6662e-08 - lr: 0.0014\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6420e-08 - val_loss: 1.6593e-08 - lr: 0.0014\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6369e-08 - val_loss: 1.6603e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1833 - val_loss: 0.1917 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1232 - val_loss: 0.0880 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0594 - val_loss: 0.0358 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0422 - val_loss: 0.0818 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0352 - val_loss: 0.0241 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0344 - val_loss: 0.0363 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0251 - val_loss: 0.0254 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0327 - val_loss: 0.0160 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0225 - val_loss: 0.0474 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0296 - val_loss: 0.0237 - lr: 0.0100\n",
      "Epoch 11/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0187 - val_loss: 0.0114 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0492 - val_loss: 0.0294 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0198 - val_loss: 0.0122 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0083 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0084 - val_loss: 0.0087 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0065 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0097 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0227 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0197 - val_loss: 0.0216 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0066 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0055 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0096 - val_loss: 0.0165 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0100 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0096 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0044 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0074 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0157 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0106 - val_loss: 0.0157 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0108 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0043 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0041 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0031 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - val_loss: 0.0056 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0104 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0053 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0051 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0077 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0030 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0040 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0077 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0059 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0037 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0035 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0054 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0048 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0055 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0042 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0024 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0041 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0036 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0024 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0039 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0027 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0030 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0072 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0037 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0043 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0016 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0046 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0048 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0027 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0022 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4537e-04 - val_loss: 0.0011 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.5943e-04 - val_loss: 0.0011 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2016e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Early Stopping\n",
      "Old Best was = \n",
      "0.004663747\n",
      "NEW BEST is\n",
      "0.004475533\n",
      "Old Best idx was = \n",
      "0\n",
      "NEW BEST idx is\n",
      "2\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "3\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2902e-05 - val_loss: 3.2024e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6825e-06 - val_loss: 9.5588e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4053e-07 - val_loss: 5.7288e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0701e-07 - val_loss: 4.0406e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7852e-07 - val_loss: 3.3391e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8177e-07 - val_loss: 2.4278e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3148e-07 - val_loss: 1.9925e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5720e-07 - val_loss: 2.1196e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6734e-07 - val_loss: 1.4660e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5486e-07 - val_loss: 1.5158e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8149e-07 - val_loss: 1.7708e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7956e-07 - val_loss: 1.3125e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1335e-07 - val_loss: 9.7294e-08 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1043e-07 - val_loss: 1.1572e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5964e-08 - val_loss: 9.5099e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4664e-07 - val_loss: 9.4042e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0572e-07 - val_loss: 7.4932e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0989e-08 - val_loss: 1.0682e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3044e-08 - val_loss: 7.8694e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7634e-08 - val_loss: 6.1352e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7952e-08 - val_loss: 1.0580e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6670e-07 - val_loss: 6.5525e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7584e-08 - val_loss: 5.5583e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6180e-08 - val_loss: 6.3176e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7107e-08 - val_loss: 5.5936e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1944e-08 - val_loss: 4.7205e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3113e-08 - val_loss: 5.5776e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0196e-08 - val_loss: 4.7077e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9523e-08 - val_loss: 1.5534e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1369e-08 - val_loss: 4.9961e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5906e-08 - val_loss: 6.4524e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1481e-08 - val_loss: 3.8512e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7168e-08 - val_loss: 3.7451e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.7875e-08 - val_loss: 3.8771e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9735e-08 - val_loss: 3.5619e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1508e-08 - val_loss: 7.2346e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5814e-08 - val_loss: 4.1348e-08 - lr: 0.0090\n",
      "Epoch 38/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4502e-08 - val_loss: 3.2059e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 3.1754e-08 - val_loss: 3.0816e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 3.1092e-08 - val_loss: 3.3183e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1525e-08 - val_loss: 3.1912e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5018e-08 - val_loss: 3.0256e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0003e-08 - val_loss: 2.8989e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8332e-08 - val_loss: 2.7972e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7679e-08 - val_loss: 2.9599e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7610e-08 - val_loss: 2.7369e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7432e-08 - val_loss: 3.1314e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7401e-08 - val_loss: 2.8148e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5949e-08 - val_loss: 2.5929e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5592e-08 - val_loss: 2.5446e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5530e-08 - val_loss: 2.6761e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5123e-08 - val_loss: 2.5199e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6810e-08 - val_loss: 3.1134e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7345e-08 - val_loss: 2.5017e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4049e-08 - val_loss: 2.3803e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3376e-08 - val_loss: 2.3339e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3237e-08 - val_loss: 2.3495e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3209e-08 - val_loss: 2.3931e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4016e-08 - val_loss: 2.3067e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2545e-08 - val_loss: 2.2461e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2146e-08 - val_loss: 2.1987e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1726e-08 - val_loss: 2.1683e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1731e-08 - val_loss: 2.1993e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1407e-08 - val_loss: 2.1655e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1166e-08 - val_loss: 2.1287e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1040e-08 - val_loss: 2.1276e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0884e-08 - val_loss: 2.0825e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0655e-08 - val_loss: 2.0806e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0522e-08 - val_loss: 2.0454e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0474e-08 - val_loss: 2.0232e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0140e-08 - val_loss: 2.0549e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0165e-08 - val_loss: 2.0396e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9943e-08 - val_loss: 1.9759e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9812e-08 - val_loss: 1.9609e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9533e-08 - val_loss: 1.9474e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9458e-08 - val_loss: 1.9595e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9462e-08 - val_loss: 1.9320e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9178e-08 - val_loss: 1.9231e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8979e-08 - val_loss: 1.9071e-08 - lr: 0.0039\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8894e-08 - val_loss: 1.8867e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8834e-08 - val_loss: 1.8809e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8811e-08 - val_loss: 1.8654e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8550e-08 - val_loss: 1.8466e-08 - lr: 0.0035\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8479e-08 - val_loss: 1.8425e-08 - lr: 0.0035\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8466e-08 - val_loss: 1.8401e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8381e-08 - val_loss: 1.8251e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8290e-08 - val_loss: 1.8467e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8098e-08 - val_loss: 1.8032e-08 - lr: 0.0031\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8067e-08 - val_loss: 1.8091e-08 - lr: 0.0031\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7989e-08 - val_loss: 1.7996e-08 - lr: 0.0031\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7870e-08 - val_loss: 1.8253e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7853e-08 - val_loss: 1.7942e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7754e-08 - val_loss: 1.7712e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7638e-08 - val_loss: 1.7566e-08 - lr: 0.0028\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7638e-08 - val_loss: 1.7536e-08 - lr: 0.0028\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7571e-08 - val_loss: 1.7478e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7473e-08 - val_loss: 1.7436e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7378e-08 - val_loss: 1.7387e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7308e-08 - val_loss: 1.7179e-08 - lr: 0.0025\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7267e-08 - val_loss: 1.7370e-08 - lr: 0.0025\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7221e-08 - val_loss: 1.7042e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7265e-08 - val_loss: 1.7012e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7042e-08 - val_loss: 1.7064e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7004e-08 - val_loss: 1.6957e-08 - lr: 0.0023\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6987e-08 - val_loss: 1.6885e-08 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/350\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.6951e-0 - 1s 8ms/step - loss: 1.6933e-08 - val_loss: 1.6880e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6925e-08 - val_loss: 1.6948e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6835e-08 - val_loss: 1.6730e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6776e-08 - val_loss: 1.6807e-08 - lr: 0.0021\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6741e-08 - val_loss: 1.6800e-08 - lr: 0.0021\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6714e-08 - val_loss: 1.6705e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6667e-08 - val_loss: 1.6591e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6593e-08 - val_loss: 1.6640e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6566e-08 - val_loss: 1.6517e-08 - lr: 0.0019\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6528e-08 - val_loss: 1.6503e-08 - lr: 0.0019\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6512e-08 - val_loss: 1.6373e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6472e-08 - val_loss: 1.6415e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6389e-08 - val_loss: 1.6351e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6361e-08 - val_loss: 1.6275e-08 - lr: 0.0017\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6337e-08 - val_loss: 1.6286e-08 - lr: 0.0017\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6328e-08 - val_loss: 1.6203e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6273e-08 - val_loss: 1.6250e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6234e-08 - val_loss: 1.6162e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6191e-08 - val_loss: 1.6170e-08 - lr: 0.0015\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6161e-08 - val_loss: 1.6113e-08 - lr: 0.0015\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6145e-08 - val_loss: 1.6067e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6112e-08 - val_loss: 1.6064e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6080e-08 - val_loss: 1.6020e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6035e-08 - val_loss: 1.5961e-08 - lr: 0.0014\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6021e-08 - val_loss: 1.5999e-08 - lr: 0.0014\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6014e-08 - val_loss: 1.5990e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5230 - val_loss: 0.2355 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1488 - val_loss: 0.0937 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0540 - val_loss: 0.0539 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0500 - val_loss: 0.0338 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0342 - val_loss: 0.0289 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0313 - val_loss: 0.0275 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0319 - val_loss: 0.0379 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0322 - val_loss: 0.0211 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0238 - val_loss: 0.0458 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0364 - val_loss: 0.0277 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0273 - val_loss: 0.0149 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0195 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0154 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0192 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0372 - val_loss: 0.0401 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0218 - val_loss: 0.0161 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0093 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0112 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0100 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0160 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0203 - val_loss: 0.0124 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0126 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0059 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0088 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0111 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0112 - val_loss: 0.0095 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0084 - val_loss: 0.0102 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0075 - val_loss: 0.0065 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0069 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0113 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0072 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0147 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0100 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0059 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - val_loss: 0.0039 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0075 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0148 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0119 - val_loss: 0.0069 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0084 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0061 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0146 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0083 - val_loss: 0.0070 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0067 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0083 - lr: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0047 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0042 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0060 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0072 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0047 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0049 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0048 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0030 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0081 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0031 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0037 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0071 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0039 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0028 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0045 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0037 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0051 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0046 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0031 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0033 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0055 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0034 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0029 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0030 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3813e-04 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8820e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9831e-04 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9141e-04 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2320e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0035e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4202e-04 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3980e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9018e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9839e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9235e-04 - val_loss: 0.0017 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1037e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1676e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7773e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9907e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9903e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5005e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9069e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1045e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4236e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6408e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6687e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9162e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1948e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8366e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9846e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9975e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5740e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2164e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4109e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2407e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3734e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4161e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3709e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7975e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5548e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1180e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2104e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1564e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4262e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1116e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9691e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9767e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1554e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1249e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9883e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9266e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5814e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6098e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6511e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4601e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4675e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4987e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4989e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6165e-04 - val_loss: 0.0012 - lr: 4.2391e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8248e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2448e-04 - val_loss: 9.9550e-04 - lr: 3.8152e-04\n",
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1525e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 173/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1344e-04 - val_loss: 0.0011 - lr: 3.8152e-04\n",
      "Epoch 174/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3594e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 175/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2156e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 176/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0312e-04 - val_loss: 0.0010 - lr: 3.4337e-04\n",
      "Epoch 177/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2717e-04 - val_loss: 0.0010 - lr: 3.4337e-04\n",
      "Epoch 178/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1855e-04 - val_loss: 0.0010 - lr: 3.4337e-04\n",
      "Epoch 179/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3621e-04 - val_loss: 0.0010 - lr: 3.4337e-04\n",
      "Early Stopping\n",
      "Old Best was = \n",
      "0.004475533\n",
      "NEW BEST is\n",
      "0.0040366896\n",
      "Old Best idx was = \n",
      "2\n",
      "NEW BEST idx is\n",
      "3\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "4\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3753e-05 - val_loss: 2.9192e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4978e-06 - val_loss: 8.6902e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7244e-07 - val_loss: 5.4745e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6414e-07 - val_loss: 3.7926e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7234e-07 - val_loss: 3.3147e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8453e-07 - val_loss: 2.8891e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3232e-07 - val_loss: 1.9293e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2912e-07 - val_loss: 1.8438e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6162e-07 - val_loss: 1.4200e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7414e-07 - val_loss: 1.4645e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3422e-07 - val_loss: 1.1526e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1568e-07 - val_loss: 1.1279e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6890e-07 - val_loss: 1.4880e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4479e-07 - val_loss: 8.8737e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.5729e-08 - val_loss: 8.1707e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.5193e-08 - val_loss: 9.1710e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0110e-07 - val_loss: 9.3852e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7518e-08 - val_loss: 7.9337e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6637e-08 - val_loss: 6.8523e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7745e-07 - val_loss: 1.8039e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9377e-08 - val_loss: 6.0662e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8125e-08 - val_loss: 6.2951e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.3178e-08 - val_loss: 5.3960e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3837e-08 - val_loss: 6.7015e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0657e-08 - val_loss: 7.0157e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1558e-08 - val_loss: 1.1045e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7887e-08 - val_loss: 1.0509e-07 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2248e-08 - val_loss: 4.5985e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0258e-07 - val_loss: 9.1874e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0777e-08 - val_loss: 4.4369e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2353e-08 - val_loss: 4.1254e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0652e-08 - val_loss: 4.1878e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6101e-08 - val_loss: 5.4549e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8109e-08 - val_loss: 3.6700e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8192e-08 - val_loss: 3.9789e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6269e-08 - val_loss: 4.1431e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5443e-08 - val_loss: 3.7536e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6548e-08 - val_loss: 3.9551e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7607e-08 - val_loss: 4.1985e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4974e-08 - val_loss: 3.2118e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3263e-08 - val_loss: 3.1409e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0241e-08 - val_loss: 3.0612e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0374e-08 - val_loss: 3.6843e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6739e-08 - val_loss: 3.3052e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3009e-08 - val_loss: 3.3948e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1001e-08 - val_loss: 3.4032e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8646e-08 - val_loss: 2.8785e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0488e-08 - val_loss: 3.1612e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8021e-08 - val_loss: 2.7518e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7383e-08 - val_loss: 2.6730e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8301e-08 - val_loss: 3.0085e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6053e-08 - val_loss: 2.6286e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5564e-08 - val_loss: 2.5272e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6290e-08 - val_loss: 2.6746e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5096e-08 - val_loss: 2.5634e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4728e-08 - val_loss: 2.4738e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4376e-08 - val_loss: 2.4504e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3809e-08 - val_loss: 2.4392e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3553e-08 - val_loss: 2.3881e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3483e-08 - val_loss: 2.3705e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4555e-08 - val_loss: 2.8455e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4156e-08 - val_loss: 2.3502e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2815e-08 - val_loss: 2.2775e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2704e-08 - val_loss: 2.2861e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2468e-08 - val_loss: 2.3186e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2471e-08 - val_loss: 2.2555e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2213e-08 - val_loss: 2.2218e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1631e-08 - val_loss: 2.2271e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1637e-08 - val_loss: 2.1826e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1711e-08 - val_loss: 2.1658e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1215e-08 - val_loss: 2.1845e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1303e-08 - val_loss: 2.1635e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1241e-08 - val_loss: 2.3512e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1000e-08 - val_loss: 2.0986e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0730e-08 - val_loss: 2.1118e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0738e-08 - val_loss: 2.0883e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0613e-08 - val_loss: 2.1190e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0400e-08 - val_loss: 2.1738e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0432e-08 - val_loss: 2.0972e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0182e-08 - val_loss: 2.0397e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0011e-08 - val_loss: 2.0207e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9995e-08 - val_loss: 2.0360e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9889e-08 - val_loss: 2.0260e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9772e-08 - val_loss: 2.0103e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9564e-08 - val_loss: 2.0307e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9516e-08 - val_loss: 1.9614e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9358e-08 - val_loss: 1.9855e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9355e-08 - val_loss: 1.9584e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9204e-08 - val_loss: 1.9661e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9115e-08 - val_loss: 1.9516e-08 - lr: 0.0031\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8987e-08 - val_loss: 1.9233e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8895e-08 - val_loss: 1.9395e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8927e-08 - val_loss: 1.9289e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8815e-08 - val_loss: 1.9189e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8722e-08 - val_loss: 1.9040e-08 - lr: 0.0028\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8645e-08 - val_loss: 1.8977e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8641e-08 - val_loss: 1.8933e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8550e-08 - val_loss: 1.8965e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8583e-08 - val_loss: 1.8859e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8373e-08 - val_loss: 1.8835e-08 - lr: 0.0025\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8332e-08 - val_loss: 1.8707e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8301e-08 - val_loss: 1.8587e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8214e-08 - val_loss: 1.8493e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8154e-08 - val_loss: 1.8425e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8086e-08 - val_loss: 1.8471e-08 - lr: 0.0023\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8042e-08 - val_loss: 1.8351e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8000e-08 - val_loss: 1.8358e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7984e-08 - val_loss: 1.8409e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7905e-08 - val_loss: 1.8241e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7857e-08 - val_loss: 1.8162e-08 - lr: 0.0021\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7821e-08 - val_loss: 1.8137e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7765e-08 - val_loss: 1.8095e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7796e-08 - val_loss: 1.8038e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7694e-08 - val_loss: 1.8099e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7611e-08 - val_loss: 1.7885e-08 - lr: 0.0019\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7638e-08 - val_loss: 1.7963e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7545e-08 - val_loss: 1.7851e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7528e-08 - val_loss: 1.7825e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7494e-08 - val_loss: 1.7821e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7426e-08 - val_loss: 1.7659e-08 - lr: 0.0017\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7401e-08 - val_loss: 1.7682e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7373e-08 - val_loss: 1.7664e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7350e-08 - val_loss: 1.7615e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7309e-08 - val_loss: 1.7630e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7278e-08 - val_loss: 1.7562e-08 - lr: 0.0015\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7227e-08 - val_loss: 1.7546e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7216e-08 - val_loss: 1.7537e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7175e-08 - val_loss: 1.7528e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7166e-08 - val_loss: 1.7468e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7140e-08 - val_loss: 1.7464e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2728 - val_loss: 0.1524 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1064 - val_loss: 0.0668 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0958 - val_loss: 0.0601 - lr: 0.0100\n",
      "Epoch 4/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0369 - val_loss: 0.0363 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0368 - val_loss: 0.0248 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0255 - val_loss: 0.0283 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0298 - val_loss: 0.0234 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0221 - val_loss: 0.0240 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0345 - val_loss: 0.0271 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0232 - val_loss: 0.0158 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0261 - val_loss: 0.0235 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0303 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0443 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0250 - val_loss: 0.0417 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0268 - val_loss: 0.0242 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0077 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0131 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0116 - val_loss: 0.0101 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0141 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0240 - val_loss: 0.0325 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0220 - val_loss: 0.0092 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0061 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0049 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0126 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0094 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0120 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0091 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0157 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0055 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0119 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0073 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0037 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0135 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0054 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0071 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0061 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0055 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0036 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0088 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0138 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0075 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0040 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0049 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0049 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0069 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0064 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0034 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0053 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - val_loss: 0.0046 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0047 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0083 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0031 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0041 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0033 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0080 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0052 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0037 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0042 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0046 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0030 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0042 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0048 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7217e-04 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0023 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7347e-04 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7753e-04 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5771e-04 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7890e-04 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5432e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5609e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4047e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3861e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6685e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3681e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2832e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7981e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9768e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8677e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3445e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5064e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9818e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1428e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5052e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2447e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2428e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0946e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2793e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4342e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0401e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7027e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3429e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1448e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2230e-04 - val_loss: 9.8533e-04 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8904e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7292e-04 - val_loss: 9.8160e-04 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5901e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1524e-04 - val_loss: 9.5190e-04 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0910e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3979e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5180e-04 - val_loss: 9.8607e-04 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7380e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6224e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9085e-04 - val_loss: 9.8822e-04 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2385e-04 - val_loss: 9.3102e-04 - lr: 5.8150e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3593e-04 - val_loss: 9.3181e-04 - lr: 5.8150e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3976e-04 - val_loss: 9.7850e-04 - lr: 5.8150e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6289e-04 - val_loss: 0.0010 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8573e-04 - val_loss: 9.3988e-04 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2047e-04 - val_loss: 8.9272e-04 - lr: 5.2335e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0381e-04 - val_loss: 9.7699e-04 - lr: 5.2335e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1467e-04 - val_loss: 9.2873e-04 - lr: 5.2335e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0132e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1218e-04 - val_loss: 8.9169e-04 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8190e-04 - val_loss: 9.2719e-04 - lr: 4.7101e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8356e-04 - val_loss: 8.9044e-04 - lr: 4.7101e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8323e-04 - val_loss: 9.1632e-04 - lr: 4.7101e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1437e-04 - val_loss: 9.8666e-04 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0391e-04 - val_loss: 9.1956e-04 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7103e-04 - val_loss: 9.0851e-04 - lr: 4.2391e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7236e-04 - val_loss: 9.3859e-04 - lr: 4.2391e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9078e-04 - val_loss: 9.2639e-04 - lr: 4.2391e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7104e-04 - val_loss: 9.0400e-04 - lr: 4.2391e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7183e-04 - val_loss: 9.1455e-04 - lr: 4.2391e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.5628e-04 - val_loss: 9.4446e-04 - lr: 3.8152e-04\n",
      "Early Stopping\n",
      "5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3290e-05 - val_loss: 2.3217e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3004e-06 - val_loss: 8.9144e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3260e-07 - val_loss: 5.5853e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7147e-07 - val_loss: 4.1017e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8187e-07 - val_loss: 3.5904e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1340e-07 - val_loss: 2.6080e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9156e-07 - val_loss: 2.5438e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0342e-07 - val_loss: 1.8002e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9417e-07 - val_loss: 2.3584e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1081e-07 - val_loss: 1.6274e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8489e-07 - val_loss: 1.9418e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3303e-07 - val_loss: 1.1668e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4709e-07 - val_loss: 2.8340e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1806e-07 - val_loss: 1.0834e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.7959e-08 - val_loss: 9.0803e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.4389e-08 - val_loss: 1.2097e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0175e-07 - val_loss: 8.7648e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1066e-07 - val_loss: 9.8161e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 9.8483e-08 - val_loss: 7.9901e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2298e-07 - val_loss: 9.1521e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4775e-08 - val_loss: 7.7136e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9437e-08 - val_loss: 1.4282e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1759e-07 - val_loss: 9.9127e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9585e-08 - val_loss: 5.8519e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5255e-08 - val_loss: 6.6399e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.6577e-08 - val_loss: 8.6864e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1952e-08 - val_loss: 5.4986e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0056e-08 - val_loss: 5.5098e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8040e-08 - val_loss: 5.5465e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9702e-08 - val_loss: 6.3073e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3366e-08 - val_loss: 4.3618e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6248e-08 - val_loss: 4.4780e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4981e-08 - val_loss: 4.4305e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5942e-08 - val_loss: 5.5417e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.5942e-08 - val_loss: 4.6517e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0657e-08 - val_loss: 4.9200e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0894e-08 - val_loss: 4.2952e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7464e-08 - val_loss: 3.8169e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6924e-08 - val_loss: 3.5811e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7990e-08 - val_loss: 3.5219e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7446e-08 - val_loss: 3.5521e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6291e-08 - val_loss: 3.3635e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5042e-08 - val_loss: 3.5688e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.5672e-08 - val_loss: 3.4083e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3322e-08 - val_loss: 3.3712e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1959e-08 - val_loss: 3.0838e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1460e-08 - val_loss: 3.1299e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1498e-08 - val_loss: 3.3980e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5903e-08 - val_loss: 2.9983e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2374e-08 - val_loss: 3.3140e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2998e-08 - val_loss: 3.3657e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8586e-08 - val_loss: 2.7723e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9115e-08 - val_loss: 2.8474e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7317e-08 - val_loss: 2.7666e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7609e-08 - val_loss: 2.7392e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9243e-08 - val_loss: 2.7345e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6919e-08 - val_loss: 2.6092e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5856e-08 - val_loss: 2.5807e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5358e-08 - val_loss: 2.5638e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5407e-08 - val_loss: 2.6484e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5314e-08 - val_loss: 2.7056e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5036e-08 - val_loss: 2.4852e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5359e-08 - val_loss: 2.8452e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4331e-08 - val_loss: 2.4656e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3862e-08 - val_loss: 2.4415e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3868e-08 - val_loss: 2.3942e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3398e-08 - val_loss: 2.4400e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3474e-08 - val_loss: 2.3484e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2941e-08 - val_loss: 2.3289e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3045e-08 - val_loss: 2.3297e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2650e-08 - val_loss: 2.2833e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2571e-08 - val_loss: 2.2666e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2201e-08 - val_loss: 2.2731e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2101e-08 - val_loss: 2.2394e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1871e-08 - val_loss: 2.2395e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2016e-08 - val_loss: 2.2489e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1759e-08 - val_loss: 2.2042e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1450e-08 - val_loss: 2.1660e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1201e-08 - val_loss: 2.1501e-08 - lr: 0.0039\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1062e-08 - val_loss: 2.1389e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1162e-08 - val_loss: 2.1417e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0951e-08 - val_loss: 2.1233e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0894e-08 - val_loss: 2.1061e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0562e-08 - val_loss: 2.0848e-08 - lr: 0.0035\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0682e-08 - val_loss: 2.0739e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0427e-08 - val_loss: 2.0625e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0423e-08 - val_loss: 2.0600e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0288e-08 - val_loss: 2.0938e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0321e-08 - val_loss: 2.0669e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0142e-08 - val_loss: 2.0334e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9917e-08 - val_loss: 2.0162e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9859e-08 - val_loss: 2.0281e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9768e-08 - val_loss: 2.0050e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9677e-08 - val_loss: 1.9972e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9604e-08 - val_loss: 1.9930e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9439e-08 - val_loss: 1.9835e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9462e-08 - val_loss: 1.9843e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9375e-08 - val_loss: 1.9789e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9291e-08 - val_loss: 1.9708e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9208e-08 - val_loss: 1.9600e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9154e-08 - val_loss: 1.9332e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9098e-08 - val_loss: 1.9482e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9019e-08 - val_loss: 1.9439e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8958e-08 - val_loss: 1.9308e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8972e-08 - val_loss: 1.9279e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8841e-08 - val_loss: 1.9222e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8790e-08 - val_loss: 1.9021e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8722e-08 - val_loss: 1.9176e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8666e-08 - val_loss: 1.9047e-08 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8665e-08 - val_loss: 1.9117e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8530e-08 - val_loss: 1.8967e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8534e-08 - val_loss: 1.9008e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8475e-08 - val_loss: 1.8811e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8464e-08 - val_loss: 1.8690e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8390e-08 - val_loss: 1.8666e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8315e-08 - val_loss: 1.8742e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8294e-08 - val_loss: 1.8723e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8238e-08 - val_loss: 1.8536e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8216e-08 - val_loss: 1.8706e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8186e-08 - val_loss: 1.8524e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8102e-08 - val_loss: 1.8442e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8071e-08 - val_loss: 1.8357e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8043e-08 - val_loss: 1.8381e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8042e-08 - val_loss: 1.8371e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7968e-08 - val_loss: 1.8422e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7963e-08 - val_loss: 1.8292e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7899e-08 - val_loss: 1.8295e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7862e-08 - val_loss: 1.8204e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7838e-08 - val_loss: 1.8249e-08 - lr: 0.0015\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4086 - val_loss: 0.1933 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1247 - val_loss: 0.0766 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0679 - val_loss: 0.0638 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0549 - val_loss: 0.0417 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0353 - val_loss: 0.0434 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0310 - val_loss: 0.0215 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0290 - val_loss: 0.0433 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0247 - val_loss: 0.0148 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0298 - val_loss: 0.0220 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0578 - val_loss: 0.0758 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0325 - val_loss: 0.0128 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0224 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0132 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0104 - val_loss: 0.0093 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0109 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0176 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0251 - val_loss: 0.0299 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0138 - val_loss: 0.0082 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0099 - val_loss: 0.0075 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0059 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0103 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0107 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0103 - val_loss: 0.0130 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0119 - val_loss: 0.0153 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0081 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0075 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0081 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0100 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0191 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0053 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0043 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0067 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0169 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0034 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0062 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0097 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0058 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0081 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0063 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0053 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0143 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.0063 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0082 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0029 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0044 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0046 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0040 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0061 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0029 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0054 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0056 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0073 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0042 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0063 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0042 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0024 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0032 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0046 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0039 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0026 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0029 - lr: 0.0017\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6097e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4726e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8945e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8063e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0889e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6164e-04 - val_loss: 0.0015 - lr: 0.0011\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3707e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5674e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1000e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1987e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3549e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3069e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1670e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2513e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7049e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7776e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0816e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7072e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8442e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5570e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8545e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8046e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1621e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8883e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2111e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1260e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0095e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1350e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6943e-04 - val_loss: 9.8445e-04 - lr: 6.4611e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7627e-04 - val_loss: 9.8057e-04 - lr: 6.4611e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4139e-04 - val_loss: 9.5872e-04 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4532e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7533e-04 - val_loss: 9.7241e-04 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3513e-04 - val_loss: 9.3270e-04 - lr: 5.8150e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3219e-04 - val_loss: 9.5142e-04 - lr: 5.8150e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4241e-04 - val_loss: 8.9849e-04 - lr: 5.8150e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2518e-04 - val_loss: 9.3054e-04 - lr: 5.8150e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3581e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5139e-04 - val_loss: 9.5669e-04 - lr: 5.2335e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0905e-04 - val_loss: 9.9149e-04 - lr: 5.2335e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9120e-04 - val_loss: 9.4669e-04 - lr: 5.2335e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3122e-04 - val_loss: 9.7811e-04 - lr: 5.2335e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1484e-04 - val_loss: 9.5072e-04 - lr: 5.2335e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0538e-04 - val_loss: 9.3994e-04 - lr: 4.7101e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7653e-04 - val_loss: 8.9710e-04 - lr: 4.7101e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9143e-04 - val_loss: 9.2590e-04 - lr: 4.7101e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8214e-04 - val_loss: 9.3613e-04 - lr: 4.7101e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1001e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7503e-04 - val_loss: 8.8413e-04 - lr: 4.2391e-04\n",
      "Early Stopping\n",
      "6\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1964e-05 - val_loss: 2.7012e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6158e-06 - val_loss: 9.6322e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7369e-07 - val_loss: 6.4575e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7410e-07 - val_loss: 3.6904e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6429e-07 - val_loss: 2.9937e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7247e-07 - val_loss: 2.6450e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3701e-07 - val_loss: 2.2281e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7035e-07 - val_loss: 1.7815e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8357e-07 - val_loss: 2.1600e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6315e-07 - val_loss: 1.3902e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1030e-07 - val_loss: 1.3250e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1921e-07 - val_loss: 1.0959e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2598e-07 - val_loss: 2.6363e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5644e-07 - val_loss: 1.3146e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0816e-07 - val_loss: 1.0978e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.7683e-08 - val_loss: 9.1133e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3712e-07 - val_loss: 9.7100e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7253e-08 - val_loss: 1.0648e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3533e-08 - val_loss: 1.0357e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4429e-08 - val_loss: 7.5961e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0407e-08 - val_loss: 2.2406e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5439e-07 - val_loss: 8.4892e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0517e-08 - val_loss: 7.1829e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.9873e-08 - val_loss: 5.4507e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4637e-08 - val_loss: 5.9500e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5917e-08 - val_loss: 6.3007e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2497e-07 - val_loss: 9.7981e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0970e-08 - val_loss: 4.7382e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6913e-08 - val_loss: 4.9202e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1869e-08 - val_loss: 1.0729e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3910e-08 - val_loss: 4.4925e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0976e-08 - val_loss: 5.0645e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0510e-08 - val_loss: 4.2092e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1747e-08 - val_loss: 4.1436e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0149e-08 - val_loss: 5.6093e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4570e-08 - val_loss: 3.8729e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2208e-08 - val_loss: 4.3137e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4283e-08 - val_loss: 5.6334e-08 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0921e-08 - val_loss: 3.3615e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.3404e-08 - val_loss: 3.1493e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3698e-08 - val_loss: 3.2496e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3198e-08 - val_loss: 3.3643e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1510e-08 - val_loss: 3.3410e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1812e-08 - val_loss: 3.1524e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9809e-08 - val_loss: 2.9613e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9154e-08 - val_loss: 2.9612e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9553e-08 - val_loss: 2.7706e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8950e-08 - val_loss: 3.0808e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8389e-08 - val_loss: 3.0489e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9332e-08 - val_loss: 2.8682e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8523e-08 - val_loss: 2.7163e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9213e-08 - val_loss: 2.9961e-08 - lr: 0.0081\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8863e-08 - val_loss: 2.5475e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5048e-08 - val_loss: 2.6829e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5027e-08 - val_loss: 2.5826e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5616e-08 - val_loss: 2.4519e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6119e-08 - val_loss: 2.9061e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6294e-08 - val_loss: 2.3446e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3428e-08 - val_loss: 2.3001e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3278e-08 - val_loss: 2.3413e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3293e-08 - val_loss: 2.3571e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3504e-08 - val_loss: 2.4920e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3021e-08 - val_loss: 2.2376e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2037e-08 - val_loss: 2.2154e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2128e-08 - val_loss: 2.1356e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1603e-08 - val_loss: 2.2249e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1748e-08 - val_loss: 2.1934e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1505e-08 - val_loss: 2.1397e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1255e-08 - val_loss: 2.1213e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1231e-08 - val_loss: 2.0817e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1030e-08 - val_loss: 2.0836e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0694e-08 - val_loss: 2.0315e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0674e-08 - val_loss: 2.1128e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0226e-08 - val_loss: 2.0081e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0040e-08 - val_loss: 1.9916e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9905e-08 - val_loss: 1.9937e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0320e-08 - val_loss: 1.9620e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9722e-08 - val_loss: 1.9841e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9512e-08 - val_loss: 1.9299e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9390e-08 - val_loss: 1.9370e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9250e-08 - val_loss: 1.9140e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9297e-08 - val_loss: 1.9251e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9010e-08 - val_loss: 1.9093e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8876e-08 - val_loss: 1.8939e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8829e-08 - val_loss: 1.8813e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8799e-08 - val_loss: 1.8905e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8598e-08 - val_loss: 1.8530e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8551e-08 - val_loss: 1.8443e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8352e-08 - val_loss: 1.8272e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8291e-08 - val_loss: 1.8148e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8229e-08 - val_loss: 1.8135e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8180e-08 - val_loss: 1.8296e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8050e-08 - val_loss: 1.7974e-08 - lr: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7973e-08 - val_loss: 1.8091e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7919e-08 - val_loss: 1.7967e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7803e-08 - val_loss: 1.7954e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7772e-08 - val_loss: 1.7874e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7774e-08 - val_loss: 1.7731e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7598e-08 - val_loss: 1.7739e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7587e-08 - val_loss: 1.7622e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7494e-08 - val_loss: 1.7500e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7446e-08 - val_loss: 1.7566e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7425e-08 - val_loss: 1.7542e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7286e-08 - val_loss: 1.7340e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7223e-08 - val_loss: 1.7235e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7186e-08 - val_loss: 1.7299e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7169e-08 - val_loss: 1.7222e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7120e-08 - val_loss: 1.7138e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7056e-08 - val_loss: 1.7095e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6952e-08 - val_loss: 1.6943e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6930e-08 - val_loss: 1.6930e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6881e-08 - val_loss: 1.6888e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6886e-08 - val_loss: 1.6861e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6828e-08 - val_loss: 1.6797e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6729e-08 - val_loss: 1.6856e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6687e-08 - val_loss: 1.6699e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6670e-08 - val_loss: 1.6728e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6647e-08 - val_loss: 1.6670e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6639e-08 - val_loss: 1.6631e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6538e-08 - val_loss: 1.6565e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6480e-08 - val_loss: 1.6629e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6483e-08 - val_loss: 1.6632e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6480e-08 - val_loss: 1.6670e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6406e-08 - val_loss: 1.6501e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6335e-08 - val_loss: 1.6339e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6338e-08 - val_loss: 1.6361e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6295e-08 - val_loss: 1.6407e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6299e-08 - val_loss: 1.6342e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6265e-08 - val_loss: 1.6211e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6193e-08 - val_loss: 1.6220e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6182e-08 - val_loss: 1.6233e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6154e-08 - val_loss: 1.6209e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6143e-08 - val_loss: 1.6163e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6096e-08 - val_loss: 1.6116e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6071e-08 - val_loss: 1.6104e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6050e-08 - val_loss: 1.6100e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6039e-08 - val_loss: 1.6118e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6007e-08 - val_loss: 1.6009e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5966e-08 - val_loss: 1.5992e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5935e-08 - val_loss: 1.5994e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5964e-08 - val_loss: 1.6095e-08 - lr: 0.0012\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5924e-08 - val_loss: 1.5912e-08 - lr: 0.0012\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5878e-08 - val_loss: 1.5928e-08 - lr: 0.0012\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5862e-08 - val_loss: 1.5893e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1843 - val_loss: 0.1861 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1405 - val_loss: 0.0697 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0603 - val_loss: 0.0590 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0504 - val_loss: 0.0280 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0416 - val_loss: 0.0461 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0403 - val_loss: 0.0499 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0315 - val_loss: 0.0301 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0301 - val_loss: 0.0378 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0158 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0368 - val_loss: 0.0247 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0314 - val_loss: 0.0265 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0229 - val_loss: 0.0114 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0177 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0202 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0093 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0114 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0129 - lr: 0.0090\n",
      "Epoch 18/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0568 - val_loss: 0.0542 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0099 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0112 - val_loss: 0.0079 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0060 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0058 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0113 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0072 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0045 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0044 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0104 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0077 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0099 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0043 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0110 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0208 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0068 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0083 - val_loss: 0.0071 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0063 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0056 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0181 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0174 - val_loss: 0.0147 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0077 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0036 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0038 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0070 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0115 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0041 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0057 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0166 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0038 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0039 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0065 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0024 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0039 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0085 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0025 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0053 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0080 - val_loss: 0.0055 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0030 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0037 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0029 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0043 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0030 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0029 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0030 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9371e-04 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9715e-04 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2762e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4993e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.8680e-04 - val_loss: 0.0021 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9012e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5088e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6186e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1531e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3391e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2664e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1148e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2666e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7614e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3405e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0663e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6269e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8376e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7246e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6706e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2840e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.6141e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7969e-04 - val_loss: 9.7192e-04 - lr: 7.9766e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4217e-04 - val_loss: 9.9525e-04 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8788e-04 - val_loss: 9.8557e-04 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7416e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2860e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6283e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6960e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4294e-04 - val_loss: 9.9459e-04 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3590e-04 - val_loss: 9.7127e-04 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2404e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2286e-04 - val_loss: 9.5648e-04 - lr: 6.4611e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1034e-04 - val_loss: 9.5685e-04 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1486e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6037e-04 - val_loss: 9.3130e-04 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7420e-04 - val_loss: 9.2278e-04 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7707e-04 - val_loss: 9.2317e-04 - lr: 5.8150e-04\n",
      "Early Stopping\n",
      "7\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 2s 13ms/step - loss: 2.4181e-05 - val_loss: 2.5984e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4392e-06 - val_loss: 8.7247e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9639e-07 - val_loss: 5.8359e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4637e-07 - val_loss: 4.0144e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6876e-07 - val_loss: 4.9072e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2812e-07 - val_loss: 2.6433e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4752e-07 - val_loss: 2.5417e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3881e-07 - val_loss: 1.8733e-07 - lr: 0.0100\n",
      "Epoch 9/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8684e-07 - val_loss: 1.6358e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8499e-07 - val_loss: 1.4995e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4410e-07 - val_loss: 1.3280e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9799e-07 - val_loss: 1.3554e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2158e-07 - val_loss: 1.3707e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3916e-07 - val_loss: 1.1659e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2615e-07 - val_loss: 1.0592e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.3806e-08 - val_loss: 8.9709e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2086e-08 - val_loss: 9.3693e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0871e-07 - val_loss: 1.0579e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8818e-08 - val_loss: 1.8572e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4637e-07 - val_loss: 2.2785e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.2471e-08 - val_loss: 7.1050e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1728e-08 - val_loss: 6.8229e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4135e-08 - val_loss: 6.2988e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1022e-08 - val_loss: 7.5817e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4155e-08 - val_loss: 5.9748e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7739e-08 - val_loss: 6.2029e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2408e-08 - val_loss: 5.7573e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4287e-08 - val_loss: 5.4463e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0003e-08 - val_loss: 3.3941e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1849e-08 - val_loss: 5.4870e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0783e-08 - val_loss: 5.0491e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2984e-08 - val_loss: 2.5165e-07 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7144e-08 - val_loss: 4.6617e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4430e-08 - val_loss: 4.8962e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8904e-08 - val_loss: 5.0387e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8081e-08 - val_loss: 4.7306e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0172e-08 - val_loss: 3.8998e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1423e-08 - val_loss: 4.1675e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8111e-08 - val_loss: 3.7190e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.7274e-08 - val_loss: 3.7641e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.9844e-08 - val_loss: 4.1237e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.6867e-08 - val_loss: 4.7654e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6409e-08 - val_loss: 3.3974e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3360e-08 - val_loss: 3.3586e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2387e-08 - val_loss: 3.2314e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2846e-08 - val_loss: 3.2999e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1023e-08 - val_loss: 3.5935e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2721e-08 - val_loss: 3.3563e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1041e-08 - val_loss: 3.0127e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0169e-08 - val_loss: 3.0884e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0600e-08 - val_loss: 3.0651e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9674e-08 - val_loss: 2.9191e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9579e-08 - val_loss: 3.1534e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9357e-08 - val_loss: 2.8163e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8274e-08 - val_loss: 2.9785e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8014e-08 - val_loss: 2.8422e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7266e-08 - val_loss: 2.7151e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7104e-08 - val_loss: 2.6940e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6590e-08 - val_loss: 2.8337e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6283e-08 - val_loss: 2.7246e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6339e-08 - val_loss: 2.6666e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5807e-08 - val_loss: 2.5979e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5526e-08 - val_loss: 2.5690e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5253e-08 - val_loss: 2.5803e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4845e-08 - val_loss: 2.6145e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5352e-08 - val_loss: 2.5606e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4702e-08 - val_loss: 2.4553e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4208e-08 - val_loss: 2.4123e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4080e-08 - val_loss: 2.4333e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3615e-08 - val_loss: 2.3696e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3394e-08 - val_loss: 2.3770e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3511e-08 - val_loss: 2.3415e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3577e-08 - val_loss: 2.3600e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2997e-08 - val_loss: 2.3315e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2704e-08 - val_loss: 2.3029e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2626e-08 - val_loss: 2.2971e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2540e-08 - val_loss: 2.2890e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2365e-08 - val_loss: 2.2538e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2287e-08 - val_loss: 2.2821e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2101e-08 - val_loss: 2.2172e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1881e-08 - val_loss: 2.2261e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1861e-08 - val_loss: 2.2145e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1615e-08 - val_loss: 2.1914e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1654e-08 - val_loss: 2.1627e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1398e-08 - val_loss: 2.2056e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1256e-08 - val_loss: 2.1735e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1202e-08 - val_loss: 2.1270e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1114e-08 - val_loss: 2.1477e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1072e-08 - val_loss: 2.0994e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0881e-08 - val_loss: 2.0991e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0797e-08 - val_loss: 2.0915e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0643e-08 - val_loss: 2.0837e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0688e-08 - val_loss: 2.0766e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0518e-08 - val_loss: 2.0610e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0436e-08 - val_loss: 2.0858e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0333e-08 - val_loss: 2.0432e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0241e-08 - val_loss: 2.0372e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0161e-08 - val_loss: 2.0329e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0190e-08 - val_loss: 2.0209e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0040e-08 - val_loss: 2.0325e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9948e-08 - val_loss: 2.0140e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9873e-08 - val_loss: 1.9967e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9793e-08 - val_loss: 1.9950e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9720e-08 - val_loss: 1.9966e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9700e-08 - val_loss: 1.9838e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9567e-08 - val_loss: 1.9827e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9548e-08 - val_loss: 1.9720e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9519e-08 - val_loss: 1.9709e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9450e-08 - val_loss: 1.9612e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9401e-08 - val_loss: 1.9642e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9354e-08 - val_loss: 1.9483e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9285e-08 - val_loss: 1.9488e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9222e-08 - val_loss: 1.9384e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9191e-08 - val_loss: 1.9452e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9166e-08 - val_loss: 1.9382e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9074e-08 - val_loss: 1.9296e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9035e-08 - val_loss: 1.9316e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8980e-08 - val_loss: 1.9175e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8952e-08 - val_loss: 1.9099e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8938e-08 - val_loss: 1.9105e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8842e-08 - val_loss: 1.9020e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8821e-08 - val_loss: 1.8980e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8801e-08 - val_loss: 1.9009e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8775e-08 - val_loss: 1.8893e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8708e-08 - val_loss: 1.8955e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8665e-08 - val_loss: 1.9000e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8634e-08 - val_loss: 1.8763e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8600e-08 - val_loss: 1.8882e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8604e-08 - val_loss: 1.8737e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8545e-08 - val_loss: 1.8807e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8498e-08 - val_loss: 1.8670e-08 - lr: 0.0014\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8479e-08 - val_loss: 1.8721e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8445e-08 - val_loss: 1.8659e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8409e-08 - val_loss: 1.8634e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8377e-08 - val_loss: 1.8570e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8361e-08 - val_loss: 1.8519e-08 - lr: 0.0012\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8322e-08 - val_loss: 1.8551e-08 - lr: 0.0012\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8306e-08 - val_loss: 1.8508e-08 - lr: 0.0012\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8277e-08 - val_loss: 1.8458e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8262e-08 - val_loss: 1.8418e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8223e-08 - val_loss: 1.8439e-08 - lr: 0.0011\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8189e-08 - val_loss: 1.8442e-08 - lr: 0.0011\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1556 - val_loss: 0.1873 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1258 - val_loss: 0.0777 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0698 - val_loss: 0.0425 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0448 - val_loss: 0.0419 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0374 - val_loss: 0.0299 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0304 - val_loss: 0.0317 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0377 - val_loss: 0.0172 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0387 - val_loss: 0.0235 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0153 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0153 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0310 - val_loss: 0.0132 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0097 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0227 - val_loss: 0.0214 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0283 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0247 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0237 - val_loss: 0.0208 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0196 - val_loss: 0.0597 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0078 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0075 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0134 - val_loss: 0.0110 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0249 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0348 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0082 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0049 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0094 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0098 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0121 - val_loss: 0.0171 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0074 - val_loss: 0.0064 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0040 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0123 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0062 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0040 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0269 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0067 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0038 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0083 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0059 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0292 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0238 - val_loss: 0.0083 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0030 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0029 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0038 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0042 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0040 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0030 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0032 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0031 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0035 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0049 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0036 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0029 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0026 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0057 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0051 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0027 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0037 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0057 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0026 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0033 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0041 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0026 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0041 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0032 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0055 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0020 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0020 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0054 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0015 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0033 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0014 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0013 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0013 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0052 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9779e-04 - val_loss: 0.0012 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5379e-04 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0011 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.3008e-04 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1549e-04 - val_loss: 0.0011 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0469e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0884e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.8158e-04 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6993e-04 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7998e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5066e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0958e-04 - val_loss: 9.7840e-04 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6318e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4902e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8102e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4923e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8434e-04 - val_loss: 9.4356e-04 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.9092e-04 - val_loss: 9.5411e-04 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7856e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2984e-04 - val_loss: 9.7321e-04 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1846e-04 - val_loss: 9.9103e-04 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8334e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8013e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5954e-04 - val_loss: 9.3113e-04 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2011e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 6.4772e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1350e-04 - val_loss: 8.6440e-04 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1908e-04 - val_loss: 0.0010 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5441e-04 - val_loss: 9.9124e-04 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2053e-04 - val_loss: 9.2133e-04 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6575e-04 - val_loss: 9.0625e-04 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0188e-04 - val_loss: 8.7404e-04 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6676e-04 - val_loss: 8.6771e-04 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5076e-04 - val_loss: 8.2854e-04 - lr: 7.1790e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5922e-04 - val_loss: 9.0170e-04 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7194e-04 - val_loss: 8.7935e-04 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1808e-04 - val_loss: 8.2036e-04 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4706e-04 - val_loss: 8.4763e-04 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3115e-04 - val_loss: 8.7902e-04 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2582e-04 - val_loss: 8.1520e-04 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5763e-04 - val_loss: 8.9001e-04 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3830e-04 - val_loss: 8.4728e-04 - lr: 5.8150e-04\n",
      "Early Stopping\n",
      "8\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2978e-05 - val_loss: 2.6345e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5944e-06 - val_loss: 9.3869e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2611e-07 - val_loss: 5.4390e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8328e-07 - val_loss: 4.0641e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2356e-07 - val_loss: 2.8461e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8822e-07 - val_loss: 2.3290e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2536e-07 - val_loss: 3.5451e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0214e-07 - val_loss: 1.8762e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6757e-07 - val_loss: 1.5430e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3559e-07 - val_loss: 1.4558e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2080e-07 - val_loss: 1.1038e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3800e-07 - val_loss: 1.4247e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7829e-07 - val_loss: 2.1380e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0021e-07 - val_loss: 9.3538e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4565e-07 - val_loss: 2.4638e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2668e-07 - val_loss: 8.1912e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.3888e-08 - val_loss: 7.4192e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1634e-08 - val_loss: 6.9077e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0282e-07 - val_loss: 1.9516e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1328e-07 - val_loss: 7.0392e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2842e-08 - val_loss: 8.5217e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0423e-08 - val_loss: 1.0536e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.6351e-08 - val_loss: 6.5813e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5164e-08 - val_loss: 5.8594e-08 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8375e-08 - val_loss: 5.1040e-08 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8060e-08 - val_loss: 4.8089e-08 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1103e-08 - val_loss: 5.1330e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9247e-08 - val_loss: 4.2305e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9699e-08 - val_loss: 4.5763e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3550e-08 - val_loss: 4.4092e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4709e-08 - val_loss: 1.1030e-07 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2070e-08 - val_loss: 4.3678e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8865e-08 - val_loss: 4.1700e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5931e-08 - val_loss: 3.6933e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6484e-08 - val_loss: 3.6126e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6103e-08 - val_loss: 4.1566e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.5271e-08 - val_loss: 3.7990e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6034e-08 - val_loss: 3.6667e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8870e-08 - val_loss: 3.3628e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4459e-08 - val_loss: 3.0618e-08 - lr: 0.0073\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0549e-08 - val_loss: 3.0389e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0260e-08 - val_loss: 3.2163e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0142e-08 - val_loss: 2.8764e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0816e-08 - val_loss: 3.4412e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5837e-08 - val_loss: 2.9588e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7862e-08 - val_loss: 2.8209e-08 - lr: 0.0066\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7460e-08 - val_loss: 2.7907e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6380e-08 - val_loss: 2.6743e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6264e-08 - val_loss: 2.6128e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5718e-08 - val_loss: 2.6345e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5562e-08 - val_loss: 2.5604e-08 - lr: 0.0059\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4994e-08 - val_loss: 2.5436e-08 - lr: 0.0059\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4648e-08 - val_loss: 2.5083e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4827e-08 - val_loss: 2.5683e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4069e-08 - val_loss: 2.4613e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3918e-08 - val_loss: 2.4469e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3262e-08 - val_loss: 2.3166e-08 - lr: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2811e-08 - val_loss: 2.3426e-08 - lr: 0.0053\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3182e-08 - val_loss: 2.4670e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3345e-08 - val_loss: 2.2655e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2479e-08 - val_loss: 2.2202e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1984e-08 - val_loss: 2.2208e-08 - lr: 0.0048\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1929e-08 - val_loss: 2.1985e-08 - lr: 0.0048\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1784e-08 - val_loss: 2.1680e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1537e-08 - val_loss: 2.1515e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1303e-08 - val_loss: 2.1997e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1370e-08 - val_loss: 2.1430e-08 - lr: 0.0043\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0969e-08 - val_loss: 2.1565e-08 - lr: 0.0043\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0745e-08 - val_loss: 2.1056e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0497e-08 - val_loss: 2.0863e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0397e-08 - val_loss: 2.0712e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0232e-08 - val_loss: 2.0621e-08 - lr: 0.0039\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0174e-08 - val_loss: 2.0197e-08 - lr: 0.0039\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9921e-08 - val_loss: 2.0012e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9797e-08 - val_loss: 1.9977e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9804e-08 - val_loss: 1.9915e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9794e-08 - val_loss: 2.0273e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9505e-08 - val_loss: 1.9722e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9419e-08 - val_loss: 1.9472e-08 - lr: 0.0035\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9256e-08 - val_loss: 1.9283e-08 - lr: 0.0035\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9085e-08 - val_loss: 1.9381e-08 - lr: 0.0035\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9067e-08 - val_loss: 1.9540e-08 - lr: 0.0035\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8899e-08 - val_loss: 1.9270e-08 - lr: 0.0035\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8797e-08 - val_loss: 1.8908e-08 - lr: 0.0031\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8620e-08 - val_loss: 1.8780e-08 - lr: 0.0031\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8559e-08 - val_loss: 1.8841e-08 - lr: 0.0031\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8550e-08 - val_loss: 1.8817e-08 - lr: 0.0031\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8476e-08 - val_loss: 1.8563e-08 - lr: 0.0031\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8321e-08 - val_loss: 1.8444e-08 - lr: 0.0028\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8193e-08 - val_loss: 1.8395e-08 - lr: 0.0028\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8148e-08 - val_loss: 1.8311e-08 - lr: 0.0028\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8060e-08 - val_loss: 1.8341e-08 - lr: 0.0028\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7999e-08 - val_loss: 1.8249e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7881e-08 - val_loss: 1.7975e-08 - lr: 0.0025\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7847e-08 - val_loss: 1.8049e-08 - lr: 0.0025\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7809e-08 - val_loss: 1.7886e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7726e-08 - val_loss: 1.7960e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7623e-08 - val_loss: 1.7909e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7543e-08 - val_loss: 1.7786e-08 - lr: 0.0023\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7504e-08 - val_loss: 1.7784e-08 - lr: 0.0023\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7460e-08 - val_loss: 1.7601e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7394e-08 - val_loss: 1.7640e-08 - lr: 0.0023\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7371e-08 - val_loss: 1.7550e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7254e-08 - val_loss: 1.7441e-08 - lr: 0.0021\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7254e-08 - val_loss: 1.7426e-08 - lr: 0.0021\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7210e-08 - val_loss: 1.7343e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7153e-08 - val_loss: 1.7289e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7119e-08 - val_loss: 1.7359e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7047e-08 - val_loss: 1.7383e-08 - lr: 0.0019\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7007e-08 - val_loss: 1.7163e-08 - lr: 0.0019\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6947e-08 - val_loss: 1.7094e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6909e-08 - val_loss: 1.7109e-08 - lr: 0.0019\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6878e-08 - val_loss: 1.7028e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6802e-08 - val_loss: 1.7069e-08 - lr: 0.0017\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6799e-08 - val_loss: 1.6908e-08 - lr: 0.0017\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6757e-08 - val_loss: 1.6944e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6721e-08 - val_loss: 1.6931e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6677e-08 - val_loss: 1.6888e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6626e-08 - val_loss: 1.6825e-08 - lr: 0.0015\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6583e-08 - val_loss: 1.6757e-08 - lr: 0.0015\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6565e-08 - val_loss: 1.6761e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6540e-08 - val_loss: 1.6698e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6495e-08 - val_loss: 1.6644e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6455e-08 - val_loss: 1.6633e-08 - lr: 0.0014\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6431e-08 - val_loss: 1.6590e-08 - lr: 0.0014\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6400e-08 - val_loss: 1.6578e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6384e-08 - val_loss: 1.6537e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6360e-08 - val_loss: 1.6522e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6320e-08 - val_loss: 1.6443e-08 - lr: 0.0012\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6297e-08 - val_loss: 1.6418e-08 - lr: 0.0012\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6253e-08 - val_loss: 1.6420e-08 - lr: 0.0012\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6257e-08 - val_loss: 1.6381e-08 - lr: 0.0012\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6215e-08 - val_loss: 1.6383e-08 - lr: 0.0012\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6187e-08 - val_loss: 1.6321e-08 - lr: 0.0011\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6167e-08 - val_loss: 1.6334e-08 - lr: 0.0011\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6164e-08 - val_loss: 1.6311e-08 - lr: 0.0011\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6117e-08 - val_loss: 1.6290e-08 - lr: 0.0011\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6100e-08 - val_loss: 1.6225e-08 - lr: 0.0011\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6088e-08 - val_loss: 1.6214e-08 - lr: 9.8477e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6048e-08 - val_loss: 1.6196e-08 - lr: 9.8477e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6033e-08 - val_loss: 1.6185e-08 - lr: 9.8477e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6017e-08 - val_loss: 1.6167e-08 - lr: 9.8477e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5994e-08 - val_loss: 1.6151e-08 - lr: 9.8477e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5970e-08 - val_loss: 1.6146e-08 - lr: 8.8629e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5944e-08 - val_loss: 1.6155e-08 - lr: 8.8629e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5952e-08 - val_loss: 1.6080e-08 - lr: 8.8629e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5921e-08 - val_loss: 1.6061e-08 - lr: 8.8629e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5909e-08 - val_loss: 1.6031e-08 - lr: 8.8629e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5871e-08 - val_loss: 1.6089e-08 - lr: 7.9766e-04\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2412 - val_loss: 0.2338 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1213 - val_loss: 0.0776 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0660 - val_loss: 0.0629 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0665 - val_loss: 0.0640 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0317 - val_loss: 0.0197 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0231 - val_loss: 0.0210 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0401 - val_loss: 0.0350 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0266 - val_loss: 0.0316 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0204 - val_loss: 0.0161 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0232 - val_loss: 0.0157 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.0132 - lr: 0.0090\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0113 - lr: 0.0090\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0101 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0176 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0258 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0216 - val_loss: 0.0128 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0102 - val_loss: 0.0095 - lr: 0.0081\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0122 - lr: 0.0081\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0098 - val_loss: 0.0116 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0260 - val_loss: 0.0119 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0151 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0083 - lr: 0.0073\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0048 - lr: 0.0073\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0056 - lr: 0.0073\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0086 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0246 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0129 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0082 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0088 - val_loss: 0.0074 - lr: 0.0066\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0069 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0099 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0038 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0065 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0056 - lr: 0.0059\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0056 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0148 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0118 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0052 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0046 - lr: 0.0053\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0035 - lr: 0.0053\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0033 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0249 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0074 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0034 - lr: 0.0048\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0040 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0042 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0039 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0031 - lr: 0.0043\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0040 - lr: 0.0043\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0042 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0089 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0053 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0044 - lr: 0.0039\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0069 - val_loss: 0.0107 - lr: 0.0039\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0029 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0021 - lr: 0.0035\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0034 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0042 - lr: 0.0031\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 0.0031\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0043 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0020 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0036 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0029 - lr: 0.0028\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 0.0025\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0028 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0027 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0021\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0022 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0031 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0004e-04 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0019 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9156e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6547e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1773e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6551e-04 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.4091e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1962e-04 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4632e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0012 - lr: 0.0012\n",
      "Early Stopping\n",
      "9\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4654e-05 - val_loss: 2.9638e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6754e-06 - val_loss: 9.5906e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2335e-07 - val_loss: 5.7218e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2192e-07 - val_loss: 4.6341e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9331e-07 - val_loss: 3.3924e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1166e-07 - val_loss: 2.8450e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7761e-07 - val_loss: 2.3065e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1399e-07 - val_loss: 2.0923e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3438e-07 - val_loss: 1.8579e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7088e-07 - val_loss: 1.7233e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5192e-07 - val_loss: 1.5361e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4361e-07 - val_loss: 1.4148e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1968e-07 - val_loss: 1.0964e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2592e-07 - val_loss: 1.3785e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0087e-07 - val_loss: 1.0737e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0002e-07 - val_loss: 1.0344e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0229e-07 - val_loss: 1.2398e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7527e-08 - val_loss: 8.2763e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0212e-08 - val_loss: 9.0966e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7199e-07 - val_loss: 9.3524e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8324e-08 - val_loss: 7.4997e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0750e-08 - val_loss: 6.7755e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.6597e-08 - val_loss: 6.7175e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.5475e-08 - val_loss: 6.8438e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6885e-08 - val_loss: 1.5705e-07 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6304e-07 - val_loss: 6.5696e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5247e-08 - val_loss: 6.1614e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6610e-08 - val_loss: 6.4075e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3934e-08 - val_loss: 4.7545e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5717e-08 - val_loss: 5.1540e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0027e-08 - val_loss: 4.7437e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1837e-08 - val_loss: 4.5257e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5020e-08 - val_loss: 8.1578e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4588e-08 - val_loss: 5.7300e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1335e-08 - val_loss: 4.6553e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7637e-08 - val_loss: 3.8966e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8219e-08 - val_loss: 3.9687e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7945e-08 - val_loss: 3.6054e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6527e-08 - val_loss: 3.4955e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5624e-08 - val_loss: 3.7309e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9317e-08 - val_loss: 3.4823e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3208e-08 - val_loss: 3.2812e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2467e-08 - val_loss: 3.4476e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2097e-08 - val_loss: 3.2534e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0636e-08 - val_loss: 3.2401e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0912e-08 - val_loss: 3.1401e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1190e-08 - val_loss: 4.2571e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0791e-08 - val_loss: 2.9488e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8343e-08 - val_loss: 2.8526e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7993e-08 - val_loss: 2.7946e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9179e-08 - val_loss: 3.1282e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1093e-08 - val_loss: 4.0231e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7911e-08 - val_loss: 2.7091e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6118e-08 - val_loss: 2.6206e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6112e-08 - val_loss: 2.5660e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5577e-08 - val_loss: 2.5307e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5345e-08 - val_loss: 2.5194e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5094e-08 - val_loss: 2.5853e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4360e-08 - val_loss: 2.4479e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4300e-08 - val_loss: 2.4542e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3982e-08 - val_loss: 2.3859e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3700e-08 - val_loss: 2.3641e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3484e-08 - val_loss: 2.3647e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3029e-08 - val_loss: 2.3546e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3224e-08 - val_loss: 2.3381e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2977e-08 - val_loss: 2.3320e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2585e-08 - val_loss: 2.2954e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2413e-08 - val_loss: 2.2613e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2364e-08 - val_loss: 2.2095e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1956e-08 - val_loss: 2.2211e-08 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1848e-08 - val_loss: 2.2030e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1617e-08 - val_loss: 2.2648e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1580e-08 - val_loss: 2.1628e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1365e-08 - val_loss: 2.1801e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1163e-08 - val_loss: 2.1828e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1242e-08 - val_loss: 2.0921e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0926e-08 - val_loss: 2.0788e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0664e-08 - val_loss: 2.0822e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0505e-08 - val_loss: 2.0577e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0403e-08 - val_loss: 2.0385e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0366e-08 - val_loss: 2.0630e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0206e-08 - val_loss: 2.0162e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0041e-08 - val_loss: 2.0039e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9936e-08 - val_loss: 1.9938e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9825e-08 - val_loss: 1.9917e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9851e-08 - val_loss: 1.9890e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9548e-08 - val_loss: 1.9651e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9397e-08 - val_loss: 1.9519e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9343e-08 - val_loss: 1.9403e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9297e-08 - val_loss: 1.9421e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9283e-08 - val_loss: 2.0664e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9112e-08 - val_loss: 1.9004e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9031e-08 - val_loss: 1.9055e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8904e-08 - val_loss: 1.9137e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8868e-08 - val_loss: 1.8992e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8790e-08 - val_loss: 1.9031e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8646e-08 - val_loss: 1.8712e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8580e-08 - val_loss: 1.8658e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8514e-08 - val_loss: 1.8517e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8430e-08 - val_loss: 1.8606e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8370e-08 - val_loss: 1.8539e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8282e-08 - val_loss: 1.8509e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8232e-08 - val_loss: 1.8273e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8154e-08 - val_loss: 1.8255e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8132e-08 - val_loss: 1.8126e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8073e-08 - val_loss: 1.8067e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7988e-08 - val_loss: 1.8069e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7941e-08 - val_loss: 1.8013e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7876e-08 - val_loss: 1.7835e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7861e-08 - val_loss: 1.7980e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7806e-08 - val_loss: 1.7931e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7758e-08 - val_loss: 1.7993e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7664e-08 - val_loss: 1.7831e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7648e-08 - val_loss: 1.7721e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7603e-08 - val_loss: 1.7688e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7569e-08 - val_loss: 1.7703e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7513e-08 - val_loss: 1.7620e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7475e-08 - val_loss: 1.7480e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7430e-08 - val_loss: 1.7572e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7388e-08 - val_loss: 1.7402e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7350e-08 - val_loss: 1.7413e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7306e-08 - val_loss: 1.7378e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7273e-08 - val_loss: 1.7345e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7266e-08 - val_loss: 1.7260e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7218e-08 - val_loss: 1.7261e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7171e-08 - val_loss: 1.7209e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7118e-08 - val_loss: 1.7210e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7099e-08 - val_loss: 1.7232e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7067e-08 - val_loss: 1.7120e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7022e-08 - val_loss: 1.7102e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7044e-08 - val_loss: 1.7120e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6963e-08 - val_loss: 1.7047e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6924e-08 - val_loss: 1.7089e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6917e-08 - val_loss: 1.7012e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6899e-08 - val_loss: 1.6983e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6855e-08 - val_loss: 1.6901e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6848e-08 - val_loss: 1.6934e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6817e-08 - val_loss: 1.6988e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6797e-08 - val_loss: 1.6854e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6752e-08 - val_loss: 1.6832e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6736e-08 - val_loss: 1.6819e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2098 - val_loss: 0.1887 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1296 - val_loss: 0.0889 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0522 - val_loss: 0.0369 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0531 - val_loss: 0.0524 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0599 - val_loss: 0.0608 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0314 - val_loss: 0.0180 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0246 - val_loss: 0.0220 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0302 - val_loss: 0.0511 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0375 - val_loss: 0.0268 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0195 - val_loss: 0.0278 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0381 - val_loss: 0.0201 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0205 - lr: 0.0090\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0159 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0201 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0090 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0232 - val_loss: 0.0167 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0221 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0400 - val_loss: 0.0205 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0236 - val_loss: 0.0131 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0088 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0081 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0098 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0540 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0312 - val_loss: 0.0160 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0065 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0078 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0052 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0072 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0087 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0081 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0132 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0075 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0064 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0030 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0033 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0222 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0051 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0055 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0056 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0047 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0044 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0243 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0053 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0028 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0042 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0031 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0092 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0036 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0031 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0079 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0030 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0048 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0028 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0043 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0064 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0032 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0056 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0049 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0057 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0044 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0032 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0103 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0035 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4506e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9230e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.7794e-04 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.8691e-04 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0487e-04 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5800e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9058e-04 - val_loss: 0.0021 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3824e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7224e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4446e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3480e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2880e-04 - val_loss: 0.0015 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5029e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5713e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5281e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3495e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0237e-04 - val_loss: 0.0017 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9121e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4102e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1081e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.5862e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1891e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0249e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2139e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0933e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Early Stopping\n",
      "10\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3118e-05 - val_loss: 2.9154e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7604e-06 - val_loss: 1.2015e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7548e-07 - val_loss: 6.2534e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1693e-07 - val_loss: 4.3049e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2085e-07 - val_loss: 3.6719e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0322e-07 - val_loss: 2.6479e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3508e-07 - val_loss: 2.3087e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1267e-07 - val_loss: 2.8831e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8257e-07 - val_loss: 1.8002e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4932e-07 - val_loss: 1.4248e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2798e-07 - val_loss: 1.2249e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1758e-07 - val_loss: 1.2003e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1334e-07 - val_loss: 1.1581e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8346e-07 - val_loss: 1.4254e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0703e-07 - val_loss: 8.5493e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4371e-08 - val_loss: 8.2537e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5309e-07 - val_loss: 8.5576e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0781e-08 - val_loss: 8.2439e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0873e-08 - val_loss: 6.6397e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4905e-08 - val_loss: 6.9971e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7982e-08 - val_loss: 6.0859e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0398e-07 - val_loss: 5.9079e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0047e-08 - val_loss: 1.2159e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9961e-08 - val_loss: 8.0063e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5506e-08 - val_loss: 6.1433e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7067e-08 - val_loss: 5.6322e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7478e-08 - val_loss: 4.5818e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5244e-08 - val_loss: 4.3085e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4487e-08 - val_loss: 4.4396e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 4.4051e-08 - val_loss: 4.0705e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.1216e-08 - val_loss: 4.3246e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6188e-08 - val_loss: 4.5181e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9292e-08 - val_loss: 4.0124e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2150e-08 - val_loss: 3.8921e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9341e-08 - val_loss: 3.7791e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6260e-08 - val_loss: 3.3927e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.4793e-08 - val_loss: 3.4093e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4806e-08 - val_loss: 3.2921e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6771e-08 - val_loss: 4.5806e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9380e-08 - val_loss: 3.6463e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8254e-08 - val_loss: 3.4099e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0559e-08 - val_loss: 3.1876e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9876e-08 - val_loss: 2.9001e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0852e-08 - val_loss: 3.1329e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9264e-08 - val_loss: 2.9006e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9163e-08 - val_loss: 2.9117e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7083e-08 - val_loss: 2.6990e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6478e-08 - val_loss: 2.5998e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6115e-08 - val_loss: 2.5556e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5794e-08 - val_loss: 2.6696e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5796e-08 - val_loss: 2.6727e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6044e-08 - val_loss: 3.1499e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5786e-08 - val_loss: 2.5015e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4237e-08 - val_loss: 2.5752e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4286e-08 - val_loss: 2.5423e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3844e-08 - val_loss: 2.3801e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3561e-08 - val_loss: 2.4202e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3076e-08 - val_loss: 2.2874e-08 - lr: 0.0053\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2694e-08 - val_loss: 2.5030e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3118e-08 - val_loss: 2.2698e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2133e-08 - val_loss: 2.2385e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2670e-08 - val_loss: 2.3117e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1756e-08 - val_loss: 2.1876e-08 - lr: 0.0048\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1573e-08 - val_loss: 2.2264e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1434e-08 - val_loss: 2.1517e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1293e-08 - val_loss: 2.1317e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0993e-08 - val_loss: 2.1596e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0934e-08 - val_loss: 2.1263e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0531e-08 - val_loss: 2.0539e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0354e-08 - val_loss: 2.0429e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0204e-08 - val_loss: 2.0669e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0564e-08 - val_loss: 2.0267e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0044e-08 - val_loss: 2.0001e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9776e-08 - val_loss: 1.9973e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9645e-08 - val_loss: 1.9623e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9494e-08 - val_loss: 1.9508e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9394e-08 - val_loss: 1.9654e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9301e-08 - val_loss: 1.9284e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9042e-08 - val_loss: 1.9444e-08 - lr: 0.0035\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8976e-08 - val_loss: 1.8890e-08 - lr: 0.0035\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8810e-08 - val_loss: 1.8995e-08 - lr: 0.0035\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8799e-08 - val_loss: 1.9429e-08 - lr: 0.0035\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8733e-08 - val_loss: 1.8802e-08 - lr: 0.0035\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8519e-08 - val_loss: 1.8527e-08 - lr: 0.0031\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8426e-08 - val_loss: 1.8356e-08 - lr: 0.0031\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8337e-08 - val_loss: 1.8463e-08 - lr: 0.0031\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8278e-08 - val_loss: 1.8357e-08 - lr: 0.0031\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8168e-08 - val_loss: 1.8128e-08 - lr: 0.0031\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8063e-08 - val_loss: 1.8273e-08 - lr: 0.0028\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8154e-08 - val_loss: 1.8131e-08 - lr: 0.0028\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7903e-08 - val_loss: 1.7926e-08 - lr: 0.0028\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7855e-08 - val_loss: 1.8084e-08 - lr: 0.0028\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7868e-08 - val_loss: 1.8088e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7710e-08 - val_loss: 1.7829e-08 - lr: 0.0025\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7604e-08 - val_loss: 1.7641e-08 - lr: 0.0025\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7554e-08 - val_loss: 1.7560e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7509e-08 - val_loss: 1.7578e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7486e-08 - val_loss: 1.7457e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7349e-08 - val_loss: 1.7384e-08 - lr: 0.0023\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7314e-08 - val_loss: 1.7482e-08 - lr: 0.0023\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7269e-08 - val_loss: 1.7365e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7218e-08 - val_loss: 1.7395e-08 - lr: 0.0023\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7148e-08 - val_loss: 1.7206e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7092e-08 - val_loss: 1.7139e-08 - lr: 0.0021\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7032e-08 - val_loss: 1.7134e-08 - lr: 0.0021\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6975e-08 - val_loss: 1.7089e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6942e-08 - val_loss: 1.7094e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6890e-08 - val_loss: 1.7062e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6867e-08 - val_loss: 1.6853e-08 - lr: 0.0019\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6784e-08 - val_loss: 1.6783e-08 - lr: 0.0019\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6769e-08 - val_loss: 1.6822e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6747e-08 - val_loss: 1.6927e-08 - lr: 0.0019\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6685e-08 - val_loss: 1.6697e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6637e-08 - val_loss: 1.6763e-08 - lr: 0.0019\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6584e-08 - val_loss: 1.6773e-08 - lr: 0.0017\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6564e-08 - val_loss: 1.6591e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6515e-08 - val_loss: 1.6615e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6487e-08 - val_loss: 1.6599e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6457e-08 - val_loss: 1.6484e-08 - lr: 0.0017\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6408e-08 - val_loss: 1.6419e-08 - lr: 0.0015\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6365e-08 - val_loss: 1.6451e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6355e-08 - val_loss: 1.6458e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6320e-08 - val_loss: 1.6435e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6278e-08 - val_loss: 1.6321e-08 - lr: 0.0015\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6240e-08 - val_loss: 1.6266e-08 - lr: 0.0014\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6206e-08 - val_loss: 1.6282e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6198e-08 - val_loss: 1.6285e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6181e-08 - val_loss: 1.6237e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6151e-08 - val_loss: 1.6244e-08 - lr: 0.0014\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6117e-08 - val_loss: 1.6220e-08 - lr: 0.0012\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6098e-08 - val_loss: 1.6134e-08 - lr: 0.0012\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6069e-08 - val_loss: 1.6099e-08 - lr: 0.0012\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6038e-08 - val_loss: 1.6159e-08 - lr: 0.0012\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6027e-08 - val_loss: 1.6075e-08 - lr: 0.0012\n",
      "Epoch 135/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5989e-08 - val_loss: 1.6004e-08 - lr: 0.0011\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5963e-08 - val_loss: 1.6002e-08 - lr: 0.0011\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5942e-08 - val_loss: 1.5986e-08 - lr: 0.0011\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5919e-08 - val_loss: 1.5957e-08 - lr: 0.0011\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5900e-08 - val_loss: 1.5936e-08 - lr: 0.0011\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1629 - val_loss: 0.1890 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1099 - val_loss: 0.0566 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0603 - val_loss: 0.0449 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0584 - val_loss: 0.0488 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0478 - val_loss: 0.0209 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0321 - val_loss: 0.0276 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0250 - val_loss: 0.0237 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0245 - val_loss: 0.0235 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0348 - val_loss: 0.0295 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0206 - lr: 0.0090\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0116 - lr: 0.0090\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0088 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0237 - val_loss: 0.0215 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0113 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0302 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0132 - val_loss: 0.0069 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.0171 - lr: 0.0081\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0081 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0065 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0134 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0125 - val_loss: 0.0093 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0126 - val_loss: 0.0117 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0109 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0119 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0065 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0041 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0043 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0290 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0179 - val_loss: 0.0158 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0068 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0262 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0061 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0038 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0053 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0068 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0072 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0034 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0053 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0233 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0050 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0028 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0090 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0031 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0046 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0038 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0044 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0025 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0027 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0040 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0026 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0036 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0030 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0033 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0017 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0053 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0018 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0025 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6925e-04 - val_loss: 0.0012 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1926e-04 - val_loss: 0.0010 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9871e-04 - val_loss: 0.0011 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6913e-04 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7232e-04 - val_loss: 0.0012 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8468e-04 - val_loss: 0.0011 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2791e-04 - val_loss: 0.0011 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4037e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2520e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9167e-04 - val_loss: 0.0010 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7494e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3331e-04 - val_loss: 0.0011 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1539e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6508e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Early Stopping\n",
      "11\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4357e-05 - val_loss: 3.7906e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8629e-06 - val_loss: 1.0194e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3002e-07 - val_loss: 5.2843e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1318e-07 - val_loss: 3.9579e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1607e-07 - val_loss: 2.7461e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0003e-07 - val_loss: 2.6920e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4989e-07 - val_loss: 2.6566e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3561e-07 - val_loss: 2.2319e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5858e-07 - val_loss: 1.4436e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0175e-07 - val_loss: 5.9940e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6311e-07 - val_loss: 1.2694e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1503e-07 - val_loss: 1.0603e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3478e-07 - val_loss: 1.1514e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0009e-07 - val_loss: 1.0780e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4077e-07 - val_loss: 9.0342e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0114e-07 - val_loss: 1.1202e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0601e-07 - val_loss: 7.9619e-08 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1127e-07 - val_loss: 8.8368e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1628e-07 - val_loss: 1.4694e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8227e-08 - val_loss: 7.7806e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3269e-08 - val_loss: 1.6153e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0288e-07 - val_loss: 1.3049e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6029e-08 - val_loss: 5.7710e-08 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5063e-08 - val_loss: 5.5312e-08 - lr: 0.0090\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2647e-08 - val_loss: 5.4205e-08 - lr: 0.0090\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2473e-08 - val_loss: 5.8670e-08 - lr: 0.0090\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4246e-08 - val_loss: 6.3883e-08 - lr: 0.0090\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0194e-08 - val_loss: 5.3866e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5764e-08 - val_loss: 5.2206e-08 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5677e-08 - val_loss: 4.7898e-08 - lr: 0.0081\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3050e-08 - val_loss: 4.5061e-08 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6797e-08 - val_loss: 4.1489e-08 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.3361e-08 - val_loss: 4.2744e-08 - lr: 0.0081\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4546e-08 - val_loss: 5.2574e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1565e-08 - val_loss: 5.1063e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3042e-08 - val_loss: 8.5013e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3797e-08 - val_loss: 3.6072e-08 - lr: 0.0073\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5612e-08 - val_loss: 3.6212e-08 - lr: 0.0073\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4611e-08 - val_loss: 3.4422e-08 - lr: 0.0073\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3771e-08 - val_loss: 3.4004e-08 - lr: 0.0073\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3352e-08 - val_loss: 3.4171e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5163e-08 - val_loss: 3.3645e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0883e-08 - val_loss: 3.2758e-08 - lr: 0.0066\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0358e-08 - val_loss: 3.0305e-08 - lr: 0.0066\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9874e-08 - val_loss: 3.1539e-08 - lr: 0.0066\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9833e-08 - val_loss: 3.0060e-08 - lr: 0.0066\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9560e-08 - val_loss: 2.9593e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0752e-08 - val_loss: 3.6184e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8931e-08 - val_loss: 2.8960e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7321e-08 - val_loss: 2.7741e-08 - lr: 0.0059\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7435e-08 - val_loss: 2.8794e-08 - lr: 0.0059\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7786e-08 - val_loss: 2.7958e-08 - lr: 0.0059\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7015e-08 - val_loss: 2.7388e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7224e-08 - val_loss: 2.7271e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5291e-08 - val_loss: 2.5686e-08 - lr: 0.0053\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5083e-08 - val_loss: 2.5911e-08 - lr: 0.0053\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5758e-08 - val_loss: 2.5409e-08 - lr: 0.0053\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4606e-08 - val_loss: 2.5666e-08 - lr: 0.0053\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5205e-08 - val_loss: 2.5771e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3702e-08 - val_loss: 2.4355e-08 - lr: 0.0048\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3454e-08 - val_loss: 2.4010e-08 - lr: 0.0048\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3825e-08 - val_loss: 2.3424e-08 - lr: 0.0048\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3087e-08 - val_loss: 2.4652e-08 - lr: 0.0048\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2781e-08 - val_loss: 2.3977e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2696e-08 - val_loss: 2.3030e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2177e-08 - val_loss: 2.2563e-08 - lr: 0.0043\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2093e-08 - val_loss: 2.2651e-08 - lr: 0.0043\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1927e-08 - val_loss: 2.2407e-08 - lr: 0.0043\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1986e-08 - val_loss: 2.2674e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1703e-08 - val_loss: 2.2111e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1338e-08 - val_loss: 2.1731e-08 - lr: 0.0039\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1141e-08 - val_loss: 2.1846e-08 - lr: 0.0039\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1083e-08 - val_loss: 2.1664e-08 - lr: 0.0039\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0940e-08 - val_loss: 2.1499e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0886e-08 - val_loss: 2.1653e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0613e-08 - val_loss: 2.1281e-08 - lr: 0.0035\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0495e-08 - val_loss: 2.0816e-08 - lr: 0.0035\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0277e-08 - val_loss: 2.0815e-08 - lr: 0.0035\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0146e-08 - val_loss: 2.0470e-08 - lr: 0.0035\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0132e-08 - val_loss: 2.0643e-08 - lr: 0.0035\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9847e-08 - val_loss: 2.0348e-08 - lr: 0.0031\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9820e-08 - val_loss: 2.0277e-08 - lr: 0.0031\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9696e-08 - val_loss: 2.0149e-08 - lr: 0.0031\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9609e-08 - val_loss: 1.9924e-08 - lr: 0.0031\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9556e-08 - val_loss: 1.9787e-08 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9347e-08 - val_loss: 2.0031e-08 - lr: 0.0028\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9361e-08 - val_loss: 1.9723e-08 - lr: 0.0028\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9274e-08 - val_loss: 1.9809e-08 - lr: 0.0028\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9209e-08 - val_loss: 1.9758e-08 - lr: 0.0028\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9077e-08 - val_loss: 1.9521e-08 - lr: 0.0028\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8916e-08 - val_loss: 1.9379e-08 - lr: 0.0025\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8847e-08 - val_loss: 1.9298e-08 - lr: 0.0025\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8765e-08 - val_loss: 1.9137e-08 - lr: 0.0025\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8749e-08 - val_loss: 1.9083e-08 - lr: 0.0025\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8680e-08 - val_loss: 1.9049e-08 - lr: 0.0025\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8548e-08 - val_loss: 1.8960e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8488e-08 - val_loss: 1.8912e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8424e-08 - val_loss: 1.8831e-08 - lr: 0.0023\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8337e-08 - val_loss: 1.8647e-08 - lr: 0.0023\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8291e-08 - val_loss: 1.8783e-08 - lr: 0.0023\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8242e-08 - val_loss: 1.8773e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8197e-08 - val_loss: 1.8575e-08 - lr: 0.0023\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8105e-08 - val_loss: 1.8519e-08 - lr: 0.0021\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8063e-08 - val_loss: 1.8529e-08 - lr: 0.0021\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8001e-08 - val_loss: 1.8361e-08 - lr: 0.0021\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7924e-08 - val_loss: 1.8379e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7914e-08 - val_loss: 1.8280e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7814e-08 - val_loss: 1.8165e-08 - lr: 0.0019\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7780e-08 - val_loss: 1.8224e-08 - lr: 0.0019\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7697e-08 - val_loss: 1.8085e-08 - lr: 0.0019\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7659e-08 - val_loss: 1.8091e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7644e-08 - val_loss: 1.8001e-08 - lr: 0.0019\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7574e-08 - val_loss: 1.7935e-08 - lr: 0.0017\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7502e-08 - val_loss: 1.7939e-08 - lr: 0.0017\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7479e-08 - val_loss: 1.7835e-08 - lr: 0.0017\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7436e-08 - val_loss: 1.7784e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7399e-08 - val_loss: 1.7816e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7347e-08 - val_loss: 1.7661e-08 - lr: 0.0015\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7311e-08 - val_loss: 1.7758e-08 - lr: 0.0015\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7313e-08 - val_loss: 1.7681e-08 - lr: 0.0015\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7249e-08 - val_loss: 1.7601e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7212e-08 - val_loss: 1.7596e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7158e-08 - val_loss: 1.7493e-08 - lr: 0.0014\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7151e-08 - val_loss: 1.7549e-08 - lr: 0.0014\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7103e-08 - val_loss: 1.7523e-08 - lr: 0.0014\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7092e-08 - val_loss: 1.7475e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7065e-08 - val_loss: 1.7412e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7012e-08 - val_loss: 1.7384e-08 - lr: 0.0012\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6976e-08 - val_loss: 1.7323e-08 - lr: 0.0012\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6961e-08 - val_loss: 1.7315e-08 - lr: 0.0012\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6931e-08 - val_loss: 1.7252e-08 - lr: 0.0012\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6895e-08 - val_loss: 1.7312e-08 - lr: 0.0012\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6862e-08 - val_loss: 1.7184e-08 - lr: 0.0011\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6848e-08 - val_loss: 1.7275e-08 - lr: 0.0011\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6836e-08 - val_loss: 1.7135e-08 - lr: 0.0011\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6794e-08 - val_loss: 1.7161e-08 - lr: 0.0011\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6772e-08 - val_loss: 1.7145e-08 - lr: 0.0011\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6746e-08 - val_loss: 1.7064e-08 - lr: 9.8477e-04\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0893 - val_loss: 0.2207 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1085 - val_loss: 0.0525 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0658 - val_loss: 0.0591 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0456 - val_loss: 0.0720 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0447 - val_loss: 0.0289 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0337 - val_loss: 0.0217 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0228 - val_loss: 0.0165 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0287 - val_loss: 0.0744 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0201 - val_loss: 0.0124 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0152 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0212 - val_loss: 0.0193 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0185 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0103 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0139 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0089 - lr: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0221 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0115 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0200 - val_loss: 0.0222 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0058 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0068 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0102 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0079 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0111 - lr: 0.0073\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0062 - lr: 0.0073\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0080 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0328 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0162 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0051 - lr: 0.0066\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0039 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0072 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0059 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0137 - val_loss: 0.0221 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0051 - lr: 0.0059\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0058 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0115 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0055 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0028 - lr: 0.0053\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0032 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0038 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0129 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0093 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0031 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0034 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0042 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0036 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0041 - lr: 0.0043\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0032 - lr: 0.0043\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0026 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0051 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0032 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0029 - lr: 0.0039\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0039\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0023 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0029 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0087 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0038 - lr: 0.0035\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0039 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0050 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0031\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0034 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0033 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0025\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0019 - val_loss: 0.0023 - lr: 0.0025\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0027 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0013 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0013 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.8400e-04 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9153e-04 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0014 - lr: 0.0015\n",
      "Early Stopping\n",
      "12\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6191e-05 - val_loss: 3.4047e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7021e-06 - val_loss: 9.7366e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8635e-07 - val_loss: 6.1776e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1118e-07 - val_loss: 4.1737e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7599e-07 - val_loss: 3.5169e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.2509e-07 - val_loss: 3.0037e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1023e-07 - val_loss: 2.2437e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3589e-07 - val_loss: 3.5639e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9393e-07 - val_loss: 1.8664e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6407e-07 - val_loss: 1.5885e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5447e-07 - val_loss: 1.8416e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4660e-07 - val_loss: 1.2330e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2691e-07 - val_loss: 1.1777e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0981e-07 - val_loss: 1.0370e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4751e-07 - val_loss: 2.2450e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6873e-07 - val_loss: 1.0114e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7226e-08 - val_loss: 9.0026e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.6999e-08 - val_loss: 7.7221e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1147e-07 - val_loss: 7.9362e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4520e-08 - val_loss: 2.2336e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.7474e-08 - val_loss: 6.6903e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.7497e-08 - val_loss: 6.3269e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5348e-08 - val_loss: 8.5046e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3171e-08 - val_loss: 6.8479e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7461e-08 - val_loss: 7.6823e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8151e-08 - val_loss: 5.5552e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9944e-08 - val_loss: 5.6781e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6936e-08 - val_loss: 5.3686e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.6437e-08 - val_loss: 5.8273e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3407e-07 - val_loss: 5.8831e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9493e-08 - val_loss: 4.2916e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6772e-08 - val_loss: 4.4423e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3421e-08 - val_loss: 4.5092e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0275e-07 - val_loss: 7.3837e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.8358e-08 - val_loss: 6.5070e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2225e-08 - val_loss: 4.0210e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.5654e-08 - val_loss: 3.6068e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4551e-08 - val_loss: 3.4771e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7257e-08 - val_loss: 4.1804e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4319e-08 - val_loss: 4.6294e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2128e-08 - val_loss: 3.2399e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6832e-08 - val_loss: 4.3253e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2810e-08 - val_loss: 2.9940e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0543e-08 - val_loss: 2.9572e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0366e-08 - val_loss: 2.8726e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0193e-08 - val_loss: 2.8494e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.9491e-08 - val_loss: 3.0631e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8849e-08 - val_loss: 3.0790e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8433e-08 - val_loss: 2.6112e-08 - lr: 0.0073\n",
      "Epoch 50/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7464e-08 - val_loss: 2.7038e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6630e-08 - val_loss: 2.5921e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5911e-08 - val_loss: 2.5872e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5477e-08 - val_loss: 2.4651e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5130e-08 - val_loss: 2.4630e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6284e-08 - val_loss: 2.7480e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6898e-08 - val_loss: 2.4162e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4954e-08 - val_loss: 2.4067e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8034e-08 - val_loss: 3.1619e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3846e-08 - val_loss: 2.3093e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2954e-08 - val_loss: 2.2576e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3848e-08 - val_loss: 2.2919e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4306e-08 - val_loss: 2.3650e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2897e-08 - val_loss: 2.1881e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1645e-08 - val_loss: 2.1252e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2016e-08 - val_loss: 2.1472e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1853e-08 - val_loss: 2.1457e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1080e-08 - val_loss: 2.1064e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1416e-08 - val_loss: 2.0808e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0845e-08 - val_loss: 2.0412e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0331e-08 - val_loss: 2.0037e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0174e-08 - val_loss: 1.9784e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0221e-08 - val_loss: 2.0489e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2252e-08 - val_loss: 2.0839e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9987e-08 - val_loss: 1.9321e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9548e-08 - val_loss: 1.9019e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9359e-08 - val_loss: 1.9864e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9294e-08 - val_loss: 1.8997e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9048e-08 - val_loss: 1.9470e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9047e-08 - val_loss: 1.8966e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8808e-08 - val_loss: 1.8548e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8539e-08 - val_loss: 1.8510e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8508e-08 - val_loss: 1.8369e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8473e-08 - val_loss: 1.8147e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8409e-08 - val_loss: 1.8311e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8131e-08 - val_loss: 1.7825e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7987e-08 - val_loss: 1.7881e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7977e-08 - val_loss: 1.7887e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7974e-08 - val_loss: 1.7906e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7725e-08 - val_loss: 1.7631e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7619e-08 - val_loss: 1.7407e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7612e-08 - val_loss: 1.7404e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7409e-08 - val_loss: 1.7360e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7381e-08 - val_loss: 1.7286e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7312e-08 - val_loss: 1.7079e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7187e-08 - val_loss: 1.7177e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7127e-08 - val_loss: 1.7409e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7114e-08 - val_loss: 1.6938e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6973e-08 - val_loss: 1.6875e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6953e-08 - val_loss: 1.6765e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6781e-08 - val_loss: 1.6574e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6735e-08 - val_loss: 1.6607e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6755e-08 - val_loss: 1.6631e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6657e-08 - val_loss: 1.6477e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6622e-08 - val_loss: 1.6637e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6517e-08 - val_loss: 1.6448e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6473e-08 - val_loss: 1.6337e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6417e-08 - val_loss: 1.6291e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6410e-08 - val_loss: 1.6273e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6297e-08 - val_loss: 1.6169e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6243e-08 - val_loss: 1.6073e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6199e-08 - val_loss: 1.6090e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6148e-08 - val_loss: 1.5965e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6126e-08 - val_loss: 1.5966e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6075e-08 - val_loss: 1.5947e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6010e-08 - val_loss: 1.5814e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5952e-08 - val_loss: 1.5912e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5901e-08 - val_loss: 1.5837e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5911e-08 - val_loss: 1.5752e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5863e-08 - val_loss: 1.5687e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5821e-08 - val_loss: 1.5634e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5773e-08 - val_loss: 1.5573e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5726e-08 - val_loss: 1.5547e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5718e-08 - val_loss: 1.5591e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5693e-08 - val_loss: 1.5540e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5639e-08 - val_loss: 1.5549e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5613e-08 - val_loss: 1.5385e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5563e-08 - val_loss: 1.5510e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5549e-08 - val_loss: 1.5398e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5524e-08 - val_loss: 1.5317e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5453e-08 - val_loss: 1.5282e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5434e-08 - val_loss: 1.5296e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5421e-08 - val_loss: 1.5231e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5392e-08 - val_loss: 1.5213e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5378e-08 - val_loss: 1.5307e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5350e-08 - val_loss: 1.5250e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2518 - val_loss: 0.2533 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1235 - val_loss: 0.1021 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0828 - val_loss: 0.0612 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0545 - val_loss: 0.0465 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0464 - val_loss: 0.0390 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0383 - val_loss: 0.0236 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0373 - val_loss: 0.0770 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0330 - val_loss: 0.0207 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.0242 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0415 - val_loss: 0.0306 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0174 - val_loss: 0.0162 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0316 - val_loss: 0.0204 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0263 - val_loss: 0.0106 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0318 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0301 - val_loss: 0.0166 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0185 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0220 - val_loss: 0.0215 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0118 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0128 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0263 - val_loss: 0.0122 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0061 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0162 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0349 - val_loss: 0.0190 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0076 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0063 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0130 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0092 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0068 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0074 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0070 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.0132 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0110 - val_loss: 0.0081 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0108 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0112 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0780 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0215 - val_loss: 0.0138 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0079 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0068 - val_loss: 0.0050 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0038 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0039 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0046 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0037 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0071 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0050 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0305 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0046 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0043 - lr: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0056 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0044 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0042 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0043 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0047 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0029 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0041 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0056 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0100 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0027 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0081 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0027 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0076 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0067 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0023 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0042 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0036 - lr: 0.0023\n",
      "Early Stopping\n",
      "13\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5175e-05 - val_loss: 3.4514e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7482e-06 - val_loss: 9.1230e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9403e-07 - val_loss: 5.5519e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5600e-07 - val_loss: 7.5428e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1373e-07 - val_loss: 2.9732e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1065e-07 - val_loss: 6.4985e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7849e-07 - val_loss: 2.3522e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8891e-07 - val_loss: 1.6786e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0363e-07 - val_loss: 6.7988e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3904e-07 - val_loss: 1.3256e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3331e-07 - val_loss: 1.2374e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1513e-07 - val_loss: 1.0708e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2821e-07 - val_loss: 1.0106e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8115e-08 - val_loss: 9.8239e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0773e-07 - val_loss: 1.0761e-07 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.6790e-08 - val_loss: 7.9530e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3821e-08 - val_loss: 8.8958e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6446e-07 - val_loss: 4.6655e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.3850e-07 - val_loss: 7.1262e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5280e-08 - val_loss: 6.1104e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0711e-08 - val_loss: 1.2021e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4752e-08 - val_loss: 5.5508e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9836e-08 - val_loss: 6.2431e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0329e-08 - val_loss: 5.8934e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3599e-08 - val_loss: 7.2038e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1862e-08 - val_loss: 1.0640e-07 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2434e-08 - val_loss: 7.4109e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8544e-08 - val_loss: 4.1416e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9631e-08 - val_loss: 4.6185e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6347e-08 - val_loss: 4.7922e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.2155e-08 - val_loss: 4.5598e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1939e-08 - val_loss: 3.7857e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9218e-08 - val_loss: 4.0237e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.6873e-08 - val_loss: 3.6968e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4936e-08 - val_loss: 3.5444e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3344e-08 - val_loss: 3.2808e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3390e-08 - val_loss: 3.3557e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4934e-08 - val_loss: 3.2062e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3017e-08 - val_loss: 3.3429e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2935e-08 - val_loss: 3.4224e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1757e-08 - val_loss: 3.3570e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0111e-08 - val_loss: 3.1539e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9442e-08 - val_loss: 2.9073e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8634e-08 - val_loss: 2.9049e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8687e-08 - val_loss: 2.8295e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4105e-08 - val_loss: 2.9086e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8933e-08 - val_loss: 2.7989e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8707e-08 - val_loss: 2.6804e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6722e-08 - val_loss: 2.8626e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6467e-08 - val_loss: 2.8469e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6282e-08 - val_loss: 2.9603e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8646e-08 - val_loss: 2.5078e-08 - lr: 0.0066\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5633e-08 - val_loss: 2.6365e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4208e-08 - val_loss: 2.4835e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3558e-08 - val_loss: 2.4349e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4039e-08 - val_loss: 2.4556e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3518e-08 - val_loss: 2.3797e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4038e-08 - val_loss: 2.4503e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4285e-08 - val_loss: 2.3916e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3390e-08 - val_loss: 2.2622e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2134e-08 - val_loss: 2.2435e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2332e-08 - val_loss: 2.2506e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1504e-08 - val_loss: 2.1731e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1442e-08 - val_loss: 2.2728e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1635e-08 - val_loss: 2.0942e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1293e-08 - val_loss: 2.2666e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1276e-08 - val_loss: 2.2276e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1257e-08 - val_loss: 2.0655e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0436e-08 - val_loss: 2.0523e-08 - lr: 0.0048\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0180e-08 - val_loss: 2.0429e-08 - lr: 0.0048\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0245e-08 - val_loss: 2.0997e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0412e-08 - val_loss: 1.9778e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9552e-08 - val_loss: 1.9721e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9459e-08 - val_loss: 1.9410e-08 - lr: 0.0043\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9449e-08 - val_loss: 1.9557e-08 - lr: 0.0043\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9236e-08 - val_loss: 1.9466e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9345e-08 - val_loss: 1.9111e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8887e-08 - val_loss: 1.8982e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8811e-08 - val_loss: 1.9030e-08 - lr: 0.0039\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8729e-08 - val_loss: 1.9170e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8713e-08 - val_loss: 1.8678e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8521e-08 - val_loss: 1.8701e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8407e-08 - val_loss: 1.8802e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8489e-08 - val_loss: 1.8191e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8148e-08 - val_loss: 1.8153e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8154e-08 - val_loss: 1.8755e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7951e-08 - val_loss: 1.7910e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7924e-08 - val_loss: 1.8051e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7737e-08 - val_loss: 1.7607e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7666e-08 - val_loss: 1.7847e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7609e-08 - val_loss: 1.7749e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7406e-08 - val_loss: 1.7433e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7394e-08 - val_loss: 1.7494e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7401e-08 - val_loss: 1.7327e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7209e-08 - val_loss: 1.7433e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7136e-08 - val_loss: 1.7179e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7017e-08 - val_loss: 1.7040e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6954e-08 - val_loss: 1.6994e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6907e-08 - val_loss: 1.7024e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6879e-08 - val_loss: 1.7073e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6827e-08 - val_loss: 1.6822e-08 - lr: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6673e-08 - val_loss: 1.6744e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6631e-08 - val_loss: 1.6631e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6562e-08 - val_loss: 1.6591e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6550e-08 - val_loss: 1.6814e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.6462e-08 - val_loss: 1.6501e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6388e-08 - val_loss: 1.6519e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6351e-08 - val_loss: 1.6469e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6301e-08 - val_loss: 1.6448e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6240e-08 - val_loss: 1.6320e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6175e-08 - val_loss: 1.6300e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.6136e-08 - val_loss: 1.6170e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6067e-08 - val_loss: 1.6143e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6040e-08 - val_loss: 1.6222e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6021e-08 - val_loss: 1.6042e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5988e-08 - val_loss: 1.6022e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5889e-08 - val_loss: 1.6008e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5871e-08 - val_loss: 1.5961e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5841e-08 - val_loss: 1.6008e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5779e-08 - val_loss: 1.5886e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5763e-08 - val_loss: 1.5896e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5710e-08 - val_loss: 1.5815e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5658e-08 - val_loss: 1.5739e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5648e-08 - val_loss: 1.5696e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5628e-08 - val_loss: 1.5664e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5579e-08 - val_loss: 1.5640e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5514e-08 - val_loss: 1.5656e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5506e-08 - val_loss: 1.5564e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.5484e-08 - val_loss: 1.5559e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5449e-08 - val_loss: 1.5549e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5427e-08 - val_loss: 1.5497e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5390e-08 - val_loss: 1.5489e-08 - lr: 0.0014\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5349e-08 - val_loss: 1.5413e-08 - lr: 0.0014\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5333e-08 - val_loss: 1.5387e-08 - lr: 0.0014\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5303e-08 - val_loss: 1.5428e-08 - lr: 0.0014\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5280e-08 - val_loss: 1.5385e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5242e-08 - val_loss: 1.5345e-08 - lr: 0.0012\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5212e-08 - val_loss: 1.5286e-08 - lr: 0.0012\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5193e-08 - val_loss: 1.5254e-08 - lr: 0.0012\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5206e-08 - val_loss: 1.5268e-08 - lr: 0.0012\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5155e-08 - val_loss: 1.5230e-08 - lr: 0.0012\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5138e-08 - val_loss: 1.5177e-08 - lr: 0.0011\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5121e-08 - val_loss: 1.5237e-08 - lr: 0.0011\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5099e-08 - val_loss: 1.5160e-08 - lr: 0.0011\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5087e-08 - val_loss: 1.5214e-08 - lr: 0.0011\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5055e-08 - val_loss: 1.5134e-08 - lr: 0.0011\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5026e-08 - val_loss: 1.5173e-08 - lr: 9.8477e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5020e-08 - val_loss: 1.5080e-08 - lr: 9.8477e-04\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2790 - val_loss: 0.1971 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1246 - val_loss: 0.1080 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0804 - val_loss: 0.0671 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0388 - val_loss: 0.0432 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0396 - val_loss: 0.0187 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0329 - val_loss: 0.0653 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0278 - val_loss: 0.0171 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0269 - val_loss: 0.0346 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0236 - val_loss: 0.0440 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0249 - val_loss: 0.0132 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0162 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0362 - val_loss: 0.0199 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0116 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0329 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0232 - val_loss: 0.0245 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.0075 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0085 - val_loss: 0.0071 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0218 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0146 - val_loss: 0.0096 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0246 - val_loss: 0.0133 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0098 - lr: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0063 - val_loss: 0.0050 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0071 - val_loss: 0.0192 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0131 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0103 - val_loss: 0.0113 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0110 - val_loss: 0.0117 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0114 - val_loss: 0.0095 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0120 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0081 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0117 - val_loss: 0.0122 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0083 - val_loss: 0.0071 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0057 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0052 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0074 - val_loss: 0.0170 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0165 - val_loss: 0.0088 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0057 - val_loss: 0.0070 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0049 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0049 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0058 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0139 - val_loss: 0.0267 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0032 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0037 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0085 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0095 - val_loss: 0.0316 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0107 - val_loss: 0.0041 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0035 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0025 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0051 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0042 - val_loss: 0.0095 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0047 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0050 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0069 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0029 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0022 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0052 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - val_loss: 0.0060 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0045 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0020 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0024 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0022 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0028 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0044 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0034 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0045 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0102 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0023 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0017 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0079 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0037 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0025 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0057 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0023 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0027 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6568e-04 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.8037e-04 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9180e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.3737e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1793e-04 - val_loss: 0.0012 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6078e-04 - val_loss: 0.0013 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9269e-04 - val_loss: 0.0012 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9416e-04 - val_loss: 0.0019 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1365e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1809e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7551e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.0509e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7083e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1626e-04 - val_loss: 0.0011 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2387e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7669e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3388e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5754e-04 - val_loss: 0.0011 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2954e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0922e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3616e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6494e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.9297e-04 - val_loss: 0.0011 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.9314e-04 - val_loss: 0.0010 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.4397e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.5779e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.2611e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.7060e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 7.0246e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.6061e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 6.4344e-04 - val_loss: 9.5034e-04 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.8224e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3072e-04 - val_loss: 9.6516e-04 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2558e-04 - val_loss: 0.0010 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7946e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1779e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9625e-04 - val_loss: 9.2133e-04 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6804e-04 - val_loss: 9.0444e-04 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8205e-04 - val_loss: 0.0010 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9786e-04 - val_loss: 9.6465e-04 - lr: 5.8150e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8532e-04 - val_loss: 9.2190e-04 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6905e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.5673e-04 - val_loss: 9.3689e-04 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4607e-04 - val_loss: 9.1499e-04 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0967e-04 - val_loss: 9.0532e-04 - lr: 5.2335e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0724e-04 - val_loss: 8.9576e-04 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.1957e-04 - val_loss: 9.2993e-04 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3118e-04 - val_loss: 9.0311e-04 - lr: 5.2335e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3224e-04 - val_loss: 9.8524e-04 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9966e-04 - val_loss: 8.4853e-04 - lr: 4.7101e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.0094e-04 - val_loss: 9.0514e-04 - lr: 4.7101e-04\n",
      "Epoch 162/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2453e-04 - val_loss: 8.7271e-04 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.2003e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.3308e-04 - val_loss: 8.7515e-04 - lr: 4.7101e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8262e-04 - val_loss: 8.4702e-04 - lr: 4.2391e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8986e-04 - val_loss: 8.8257e-04 - lr: 4.2391e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.8484e-04 - val_loss: 9.0034e-04 - lr: 4.2391e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.7265e-04 - val_loss: 8.6728e-04 - lr: 4.2391e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8430e-04 - val_loss: 8.8632e-04 - lr: 4.2391e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6475e-04 - val_loss: 8.5736e-04 - lr: 3.8152e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5730e-04 - val_loss: 8.2925e-04 - lr: 3.8152e-04\n",
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.6260e-04 - val_loss: 8.6625e-04 - lr: 3.8152e-04\n",
      "Epoch 173/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.7834e-04 - val_loss: 8.5907e-04 - lr: 3.8152e-04\n",
      "Epoch 174/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.7150e-04 - val_loss: 8.9484e-04 - lr: 3.8152e-04\n",
      "Epoch 175/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.5998e-04 - val_loss: 8.9552e-04 - lr: 3.4337e-04\n",
      "Epoch 176/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5721e-04 - val_loss: 8.2473e-04 - lr: 3.4337e-04\n",
      "Epoch 177/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.4097e-04 - val_loss: 8.1232e-04 - lr: 3.4337e-04\n",
      "Epoch 178/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3983e-04 - val_loss: 8.4006e-04 - lr: 3.4337e-04\n",
      "Epoch 179/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5467e-04 - val_loss: 8.4792e-04 - lr: 3.4337e-04\n",
      "Epoch 180/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4294e-04 - val_loss: 8.1365e-04 - lr: 3.0903e-04\n",
      "Epoch 181/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.4191e-04 - val_loss: 8.3183e-04 - lr: 3.0903e-04\n",
      "Epoch 182/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.4403e-04 - val_loss: 8.9510e-04 - lr: 3.0903e-04\n",
      "Epoch 183/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.5180e-04 - val_loss: 8.3269e-04 - lr: 3.0903e-04\n",
      "Epoch 184/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.5111e-04 - val_loss: 8.3588e-04 - lr: 3.0903e-04\n",
      "Epoch 185/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3075e-04 - val_loss: 8.3148e-04 - lr: 2.7813e-04\n",
      "Epoch 186/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2300e-04 - val_loss: 7.9602e-04 - lr: 2.7813e-04\n",
      "Early Stopping\n",
      "Old Best was = \n",
      "0.0040366896\n",
      "NEW BEST is\n",
      "0.0038928518\n",
      "Old Best idx was = \n",
      "3\n",
      "NEW BEST idx is\n",
      "13\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "14\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8678e-05 - val_loss: 3.0256e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6886e-06 - val_loss: 8.8919e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.8621e-07 - val_loss: 5.2580e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8023e-07 - val_loss: 3.7161e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8800e-07 - val_loss: 3.0225e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1068e-07 - val_loss: 2.6912e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3885e-07 - val_loss: 2.0766e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0368e-07 - val_loss: 1.8356e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8630e-07 - val_loss: 1.5930e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5525e-07 - val_loss: 1.6260e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6366e-07 - val_loss: 1.3493e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7490e-07 - val_loss: 1.3445e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2714e-07 - val_loss: 1.6649e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5561e-07 - val_loss: 1.2417e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.9218e-08 - val_loss: 9.0567e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.9470e-08 - val_loss: 8.3755e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.1705e-07 - val_loss: 1.0813e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5013e-07 - val_loss: 1.1703e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.0832e-08 - val_loss: 7.7459e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5159e-08 - val_loss: 7.0066e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7218e-08 - val_loss: 8.3454e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.4837e-08 - val_loss: 6.2598e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7194e-07 - val_loss: 1.0955e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.2625e-08 - val_loss: 5.8774e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.0522e-08 - val_loss: 6.8724e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 9.6062e-08 - val_loss: 6.0461e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 6.5582e-08 - val_loss: 8.0411e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.2435e-08 - val_loss: 4.8614e-08 - lr: 0.0090\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 4.5626e-08 - val_loss: 4.4603e-08 - lr: 0.0090\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.3881e-08 - val_loss: 4.5224e-08 - lr: 0.0090\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4373e-08 - val_loss: 8.5310e-08 - lr: 0.0090\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0352e-08 - val_loss: 4.5160e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0045e-08 - val_loss: 5.0624e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1467e-08 - val_loss: 3.8794e-08 - lr: 0.0081\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7586e-08 - val_loss: 3.9404e-08 - lr: 0.0081\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7199e-08 - val_loss: 3.7245e-08 - lr: 0.0081\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.7892e-08 - val_loss: 3.6189e-08 - lr: 0.0081\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8193e-08 - val_loss: 3.5526e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6730e-08 - val_loss: 4.2091e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6445e-08 - val_loss: 3.4076e-08 - lr: 0.0073\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3888e-08 - val_loss: 3.3180e-08 - lr: 0.0073\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.3530e-08 - val_loss: 3.6720e-08 - lr: 0.0073\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3582e-08 - val_loss: 4.3240e-08 - lr: 0.0073\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2886e-08 - val_loss: 3.3114e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.4376e-08 - val_loss: 3.3032e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4310e-08 - val_loss: 3.3456e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1014e-08 - val_loss: 3.0133e-08 - lr: 0.0066\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9483e-08 - val_loss: 2.9456e-08 - lr: 0.0066\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8725e-08 - val_loss: 3.1414e-08 - lr: 0.0066\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.0272e-08 - val_loss: 2.9331e-08 - lr: 0.0066\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8912e-08 - val_loss: 3.1512e-08 - lr: 0.0066\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7856e-08 - val_loss: 2.8309e-08 - lr: 0.0059\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6849e-08 - val_loss: 2.7563e-08 - lr: 0.0059\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7166e-08 - val_loss: 2.6889e-08 - lr: 0.0059\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6134e-08 - val_loss: 2.6630e-08 - lr: 0.0059\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7266e-08 - val_loss: 2.8813e-08 - lr: 0.0059\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6322e-08 - val_loss: 2.7147e-08 - lr: 0.0059\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.6906e-08 - val_loss: 2.7608e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5170e-08 - val_loss: 2.5877e-08 - lr: 0.0053\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4906e-08 - val_loss: 2.5324e-08 - lr: 0.0053\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4363e-08 - val_loss: 2.4684e-08 - lr: 0.0053\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4231e-08 - val_loss: 2.4680e-08 - lr: 0.0053\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4367e-08 - val_loss: 2.4849e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3730e-08 - val_loss: 2.4684e-08 - lr: 0.0048\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3477e-08 - val_loss: 2.4111e-08 - lr: 0.0048\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3683e-08 - val_loss: 2.4224e-08 - lr: 0.0048\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3263e-08 - val_loss: 2.3835e-08 - lr: 0.0048\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3076e-08 - val_loss: 2.3907e-08 - lr: 0.0048\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2614e-08 - val_loss: 2.3092e-08 - lr: 0.0043\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2414e-08 - val_loss: 2.2936e-08 - lr: 0.0043\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2932e-08 - val_loss: 2.3284e-08 - lr: 0.0043\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2178e-08 - val_loss: 2.3056e-08 - lr: 0.0043\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2018e-08 - val_loss: 2.2577e-08 - lr: 0.0043\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1806e-08 - val_loss: 2.3050e-08 - lr: 0.0039\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1786e-08 - val_loss: 2.2275e-08 - lr: 0.0039\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1519e-08 - val_loss: 2.2266e-08 - lr: 0.0039\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1640e-08 - val_loss: 2.3322e-08 - lr: 0.0039\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1304e-08 - val_loss: 2.2126e-08 - lr: 0.0039\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1321e-08 - val_loss: 2.2039e-08 - lr: 0.0039\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1211e-08 - val_loss: 2.1755e-08 - lr: 0.0039\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0933e-08 - val_loss: 2.1706e-08 - lr: 0.0035\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0871e-08 - val_loss: 2.1362e-08 - lr: 0.0035\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0716e-08 - val_loss: 2.1432e-08 - lr: 0.0035\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0659e-08 - val_loss: 2.1148e-08 - lr: 0.0035\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0453e-08 - val_loss: 2.1215e-08 - lr: 0.0035\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0409e-08 - val_loss: 2.0923e-08 - lr: 0.0031\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0258e-08 - val_loss: 2.0907e-08 - lr: 0.0031\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0229e-08 - val_loss: 2.0904e-08 - lr: 0.0031\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0044e-08 - val_loss: 2.0627e-08 - lr: 0.0031\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0028e-08 - val_loss: 2.0577e-08 - lr: 0.0031\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9864e-08 - val_loss: 2.0449e-08 - lr: 0.0028\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9751e-08 - val_loss: 2.0316e-08 - lr: 0.0028\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9667e-08 - val_loss: 2.0352e-08 - lr: 0.0028\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9662e-08 - val_loss: 2.0631e-08 - lr: 0.0028\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9588e-08 - val_loss: 2.0233e-08 - lr: 0.0028\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9459e-08 - val_loss: 1.9963e-08 - lr: 0.0025\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9465e-08 - val_loss: 2.0019e-08 - lr: 0.0025\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9352e-08 - val_loss: 2.0001e-08 - lr: 0.0025\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9259e-08 - val_loss: 1.9958e-08 - lr: 0.0025\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9208e-08 - val_loss: 1.9795e-08 - lr: 0.0025\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9086e-08 - val_loss: 1.9708e-08 - lr: 0.0023\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9012e-08 - val_loss: 1.9741e-08 - lr: 0.0023\n",
      "Epoch 103/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9026e-08 - val_loss: 1.9519e-08 - lr: 0.0023\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 1.8936e-08 - val_loss: 1.9457e-08 - lr: 0.0023\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8886e-08 - val_loss: 1.9491e-08 - lr: 0.0023\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8760e-08 - val_loss: 1.9360e-08 - lr: 0.0021\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8724e-08 - val_loss: 1.9403e-08 - lr: 0.0021\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8726e-08 - val_loss: 1.9210e-08 - lr: 0.0021\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8636e-08 - val_loss: 1.9382e-08 - lr: 0.0021\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8582e-08 - val_loss: 1.9230e-08 - lr: 0.0021\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8530e-08 - val_loss: 1.9048e-08 - lr: 0.0019\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8477e-08 - val_loss: 1.9234e-08 - lr: 0.0019\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8466e-08 - val_loss: 1.8975e-08 - lr: 0.0019\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8381e-08 - val_loss: 1.9122e-08 - lr: 0.0019\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8386e-08 - val_loss: 1.8951e-08 - lr: 0.0019\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8305e-08 - val_loss: 1.8850e-08 - lr: 0.0017\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8228e-08 - val_loss: 1.8859e-08 - lr: 0.0017\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8238e-08 - val_loss: 1.8771e-08 - lr: 0.0017\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8214e-08 - val_loss: 1.8847e-08 - lr: 0.0017\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8140e-08 - val_loss: 1.8769e-08 - lr: 0.0017\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8111e-08 - val_loss: 1.8695e-08 - lr: 0.0015\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8043e-08 - val_loss: 1.8588e-08 - lr: 0.0015\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8059e-08 - val_loss: 1.8671e-08 - lr: 0.0015\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8045e-08 - val_loss: 1.8577e-08 - lr: 0.0015\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7974e-08 - val_loss: 1.8567e-08 - lr: 0.0015\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7916e-08 - val_loss: 1.8569e-08 - lr: 0.0014\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7895e-08 - val_loss: 1.8464e-08 - lr: 0.0014\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7881e-08 - val_loss: 1.8477e-08 - lr: 0.0014\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7841e-08 - val_loss: 1.8431e-08 - lr: 0.0014\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7821e-08 - val_loss: 1.8419e-08 - lr: 0.0014\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7763e-08 - val_loss: 1.8366e-08 - lr: 0.0012\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7742e-08 - val_loss: 1.8355e-08 - lr: 0.0012\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7736e-08 - val_loss: 1.8294e-08 - lr: 0.0012\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7719e-08 - val_loss: 1.8295e-08 - lr: 0.0012\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7669e-08 - val_loss: 1.8251e-08 - lr: 0.0012\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7624e-08 - val_loss: 1.8281e-08 - lr: 0.0011\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7618e-08 - val_loss: 1.8205e-08 - lr: 0.0011\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.7596e-08 - val_loss: 1.8156e-08 - lr: 0.0011\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7564e-08 - val_loss: 1.8123e-08 - lr: 0.0011\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7542e-08 - val_loss: 1.8090e-08 - lr: 0.0011\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.7511e-08 - val_loss: 1.8088e-08 - lr: 9.8477e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7485e-08 - val_loss: 1.8065e-08 - lr: 9.8477e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7484e-08 - val_loss: 1.8044e-08 - lr: 9.8477e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7477e-08 - val_loss: 1.8040e-08 - lr: 9.8477e-04\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.7938 - val_loss: 0.5940 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.3411 - val_loss: 0.1751 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1316 - val_loss: 0.0860 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0737 - val_loss: 0.0629 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0687 - val_loss: 0.0828 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0548 - val_loss: 0.0704 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0596 - val_loss: 0.0491 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0375 - val_loss: 0.0281 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0363 - val_loss: 0.0592 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0382 - val_loss: 0.0265 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0336 - val_loss: 0.0425 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0342 - val_loss: 0.0357 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0284 - val_loss: 0.0421 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0216 - val_loss: 0.0176 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0184 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0235 - val_loss: 0.0172 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0358 - val_loss: 0.0184 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0206 - val_loss: 0.0176 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0179 - val_loss: 0.0174 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0141 - val_loss: 0.0125 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0157 - val_loss: 0.0132 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.0119 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.0248 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0180 - val_loss: 0.0205 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0305 - val_loss: 0.0361 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.0151 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0107 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0108 - val_loss: 0.0134 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0115 - val_loss: 0.0096 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0188 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0095 - val_loss: 0.0083 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0074 - val_loss: 0.0121 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0107 - val_loss: 0.0134 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0122 - val_loss: 0.0085 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0080 - val_loss: 0.0090 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0072 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0080 - val_loss: 0.0128 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0127 - val_loss: 0.0111 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0088 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0085 - val_loss: 0.0094 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0125 - val_loss: 0.0179 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0061 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0064 - val_loss: 0.0057 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0073 - val_loss: 0.0083 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0075 - val_loss: 0.0079 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0079 - val_loss: 0.0096 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.0056 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - val_loss: 0.0084 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0050 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - val_loss: 0.0084 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0077 - val_loss: 0.0113 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0059 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0071 - val_loss: 0.0051 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0082 - val_loss: 0.0065 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0052 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0076 - val_loss: 0.0070 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0054 - lr: 0.0039\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0043 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0042 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0067 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - val_loss: 0.0098 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - val_loss: 0.0045 - lr: 0.0035\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0059 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0047 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0050 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0047 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0048 - lr: 0.0031\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0043 - val_loss: 0.0045 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0054 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0048 - val_loss: 0.0040 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0054 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0042 - lr: 0.0028\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0040 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0064 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0039 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0031 - lr: 0.0025\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0039 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0041 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0035 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0037 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0036 - lr: 0.0023\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0038 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0039 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0032 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0054 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0040 - lr: 0.0021\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0028 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0039 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0031 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0034 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0032 - lr: 0.0019\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0031 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0028 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0033 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0034 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0030 - lr: 0.0017\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0030 - lr: 0.0017\n",
      "Epoch 99/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0029 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0028 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0031 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0027 - lr: 0.0015\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0031 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0032 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0034 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0037 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0025 - lr: 0.0014\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0025 - lr: 0.0012\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0025 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 0.0011\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0025 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 9.8477e-04\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0023 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0022 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0022 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0023 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 7.1790e-04\n",
      "Early Stopping\n",
      "15\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4830e-05 - val_loss: 3.2401e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5564e-06 - val_loss: 8.8593e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0150e-07 - val_loss: 5.4779e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3576e-07 - val_loss: 3.7568e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3731e-07 - val_loss: 3.1021e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2132e-07 - val_loss: 2.1920e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2414e-07 - val_loss: 2.2291e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6791e-07 - val_loss: 1.6761e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8291e-07 - val_loss: 1.6511e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5121e-07 - val_loss: 1.2502e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1055e-07 - val_loss: 1.7530e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1156e-07 - val_loss: 9.9737e-08 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0543e-07 - val_loss: 1.6824e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7138e-07 - val_loss: 1.6597e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2467e-07 - val_loss: 8.7911e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.4661e-08 - val_loss: 7.4257e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8020e-08 - val_loss: 8.2464e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1193e-08 - val_loss: 7.3679e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2816e-08 - val_loss: 1.0249e-07 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2031e-08 - val_loss: 6.4684e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9520e-07 - val_loss: 3.6872e-07 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1712e-07 - val_loss: 7.3480e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9485e-08 - val_loss: 5.4825e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2518e-08 - val_loss: 5.2584e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9391e-08 - val_loss: 5.0930e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7442e-08 - val_loss: 4.6440e-08 - lr: 0.0100\n",
      "Epoch 27/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 4.6171e-08 - val_loss: 4.5743e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4860e-08 - val_loss: 5.5448e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1932e-08 - val_loss: 4.9875e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1568e-08 - val_loss: 1.0135e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9781e-08 - val_loss: 4.5209e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.1608e-08 - val_loss: 3.8033e-08 - lr: 0.0090\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6373e-08 - val_loss: 3.5414e-08 - lr: 0.0090\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5666e-08 - val_loss: 3.6371e-08 - lr: 0.0090\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8390e-08 - val_loss: 3.7299e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6648e-08 - val_loss: 4.0020e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6861e-08 - val_loss: 4.3306e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2301e-08 - val_loss: 3.1303e-08 - lr: 0.0081\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5278e-08 - val_loss: 3.6636e-08 - lr: 0.0081\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1985e-08 - val_loss: 3.1151e-08 - lr: 0.0081\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9607e-08 - val_loss: 3.1058e-08 - lr: 0.0081\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9291e-08 - val_loss: 3.0262e-08 - lr: 0.0081\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9231e-08 - val_loss: 2.8230e-08 - lr: 0.0081\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7242e-08 - val_loss: 2.7874e-08 - lr: 0.0073\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7858e-08 - val_loss: 2.8817e-08 - lr: 0.0073\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7119e-08 - val_loss: 2.8040e-08 - lr: 0.0073\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8600e-08 - val_loss: 2.6182e-08 - lr: 0.0073\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6258e-08 - val_loss: 2.8055e-08 - lr: 0.0073\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5105e-08 - val_loss: 2.5652e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0619e-08 - val_loss: 4.1246e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.5813e-08 - val_loss: 3.6959e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6422e-08 - val_loss: 2.4862e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3663e-08 - val_loss: 2.4119e-08 - lr: 0.0066\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3333e-08 - val_loss: 2.4357e-08 - lr: 0.0066\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2728e-08 - val_loss: 2.2916e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3442e-08 - val_loss: 2.3240e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2845e-08 - val_loss: 2.2625e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2392e-08 - val_loss: 2.2560e-08 - lr: 0.0059\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1837e-08 - val_loss: 2.2006e-08 - lr: 0.0059\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1649e-08 - val_loss: 2.2226e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1863e-08 - val_loss: 2.4490e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1590e-08 - val_loss: 2.1931e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0831e-08 - val_loss: 2.1587e-08 - lr: 0.0053\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0783e-08 - val_loss: 2.1613e-08 - lr: 0.0053\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0892e-08 - val_loss: 2.1357e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0408e-08 - val_loss: 2.1495e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0126e-08 - val_loss: 2.0496e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0108e-08 - val_loss: 2.0918e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9842e-08 - val_loss: 2.1249e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9862e-08 - val_loss: 2.0307e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9657e-08 - val_loss: 2.0767e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9583e-08 - val_loss: 2.0010e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9127e-08 - val_loss: 1.9791e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9128e-08 - val_loss: 1.9697e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8929e-08 - val_loss: 1.9522e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8973e-08 - val_loss: 1.9573e-08 - lr: 0.0048\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9054e-08 - val_loss: 1.9424e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8468e-08 - val_loss: 1.8967e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8485e-08 - val_loss: 1.9996e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8689e-08 - val_loss: 1.9118e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8429e-08 - val_loss: 1.9127e-08 - lr: 0.0043\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8218e-08 - val_loss: 1.8506e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7941e-08 - val_loss: 1.8855e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7877e-08 - val_loss: 1.8392e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7710e-08 - val_loss: 1.8177e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7646e-08 - val_loss: 1.8173e-08 - lr: 0.0039\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7569e-08 - val_loss: 1.8186e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7522e-08 - val_loss: 1.7942e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7461e-08 - val_loss: 1.7889e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7297e-08 - val_loss: 1.7818e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7201e-08 - val_loss: 1.8083e-08 - lr: 0.0035\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7260e-08 - val_loss: 1.7818e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7066e-08 - val_loss: 1.7581e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6966e-08 - val_loss: 1.7521e-08 - lr: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6911e-08 - val_loss: 1.7361e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6855e-08 - val_loss: 1.7408e-08 - lr: 0.0031\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6815e-08 - val_loss: 1.7376e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6732e-08 - val_loss: 1.7538e-08 - lr: 0.0028\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6671e-08 - val_loss: 1.7201e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6593e-08 - val_loss: 1.7174e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6563e-08 - val_loss: 1.7133e-08 - lr: 0.0028\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6513e-08 - val_loss: 1.6985e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6428e-08 - val_loss: 1.6927e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6379e-08 - val_loss: 1.6899e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6338e-08 - val_loss: 1.6785e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6272e-08 - val_loss: 1.6901e-08 - lr: 0.0025\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6275e-08 - val_loss: 1.6740e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6158e-08 - val_loss: 1.6719e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6103e-08 - val_loss: 1.6659e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6075e-08 - val_loss: 1.6566e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6091e-08 - val_loss: 1.6495e-08 - lr: 0.0023\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6040e-08 - val_loss: 1.6467e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5970e-08 - val_loss: 1.6535e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5953e-08 - val_loss: 1.6384e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5878e-08 - val_loss: 1.6411e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5866e-08 - val_loss: 1.6425e-08 - lr: 0.0021\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5829e-08 - val_loss: 1.6333e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5765e-08 - val_loss: 1.6278e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5753e-08 - val_loss: 1.6247e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5730e-08 - val_loss: 1.6231e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5704e-08 - val_loss: 1.6182e-08 - lr: 0.0019\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5657e-08 - val_loss: 1.6134e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5609e-08 - val_loss: 1.6074e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5592e-08 - val_loss: 1.6103e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5538e-08 - val_loss: 1.6083e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5523e-08 - val_loss: 1.6065e-08 - lr: 0.0017\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5494e-08 - val_loss: 1.5951e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5440e-08 - val_loss: 1.5901e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5433e-08 - val_loss: 1.5962e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5418e-08 - val_loss: 1.5886e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5385e-08 - val_loss: 1.5832e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5366e-08 - val_loss: 1.5818e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5320e-08 - val_loss: 1.5808e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7947 - val_loss: 0.2684 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.1455 - val_loss: 0.1475 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0743 - val_loss: 0.0518 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0533 - val_loss: 0.0377 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0448 - val_loss: 0.0506 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0532 - val_loss: 0.0503 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0294 - val_loss: 0.0313 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0454 - val_loss: 0.0314 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0293 - val_loss: 0.0166 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0346 - val_loss: 0.0380 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0331 - val_loss: 0.0234 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0523 - val_loss: 0.0298 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0108 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0116 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0237 - val_loss: 0.0141 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0322 - val_loss: 0.0312 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0236 - val_loss: 0.0240 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0254 - val_loss: 0.0390 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0137 - val_loss: 0.0112 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0074 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0181 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0316 - val_loss: 0.0274 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0149 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0090 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0065 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0063 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0051 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0290 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0201 - val_loss: 0.0133 - lr: 0.0081\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0072 - lr: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0312 - val_loss: 0.0117 - lr: 0.0081\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0061 - lr: 0.0081\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0062 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0059 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0040 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0105 - lr: 0.0073\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0225 - lr: 0.0073\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0078 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0057 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0072 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0110 - val_loss: 0.0132 - lr: 0.0066\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0050 - lr: 0.0066\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0048 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0049 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0052 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0090 - val_loss: 0.0108 - lr: 0.0059\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0100 - lr: 0.0059\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - val_loss: 0.0038 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0040 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0064 - lr: 0.0053\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0150 - lr: 0.0053\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0052 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0094 - lr: 0.0048\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0122 - lr: 0.0048\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0030 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0093 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - val_loss: 0.0161 - lr: 0.0043\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0058 - lr: 0.0043\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0026 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0029 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0036 - lr: 0.0039\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0040 - lr: 0.0039\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0025 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0090 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0064 - lr: 0.0035\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0065 - lr: 0.0035\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0030 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0025 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0032 - lr: 0.0031\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0060 - lr: 0.0031\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0020 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0027 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0021 - lr: 0.0025\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0030 - lr: 0.0025\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0017 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0025 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0036 - lr: 0.0023\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0023 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0021\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0036 - lr: 0.0019\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0023 - lr: 0.0019\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0012 - val_loss: 0.0025 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0020 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0014\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0012\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.8791e-04 - val_loss: 0.0015 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0808e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0011\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5232e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.4248e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.9741e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1396e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.8218e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.2980e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2870e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6477e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5909e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.8719e-04 - val_loss: 0.0014 - lr: 8.8629e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8783e-04 - val_loss: 0.0011 - lr: 7.9766e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.0784e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2793e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.2146e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.7774e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3021e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1081e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3209e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1645e-04 - val_loss: 0.0011 - lr: 7.1790e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.4185e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.1902e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7427e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9683e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.7020e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0591e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6464e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3486e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4888e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.5071e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3099e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4685e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6826e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2201e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.1185e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9749e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0946e-04 - val_loss: 9.9878e-04 - lr: 4.7101e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8607e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2147e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9152e-04 - val_loss: 9.9650e-04 - lr: 4.7101e-04\n",
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9274e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5547e-04 - val_loss: 9.4785e-04 - lr: 4.2391e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7085e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8281e-04 - val_loss: 9.7427e-04 - lr: 4.2391e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7562e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6660e-04 - val_loss: 9.8013e-04 - lr: 4.2391e-04\n",
      "Epoch 173/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5020e-04 - val_loss: 9.5297e-04 - lr: 3.8152e-04\n",
      "Epoch 174/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4015e-04 - val_loss: 9.8734e-04 - lr: 3.8152e-04\n",
      "Epoch 175/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4693e-04 - val_loss: 9.7086e-04 - lr: 3.8152e-04\n",
      "Epoch 176/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9465e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 177/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5440e-04 - val_loss: 9.6220e-04 - lr: 3.8152e-04\n",
      "Epoch 178/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2801e-04 - val_loss: 9.5400e-04 - lr: 3.4337e-04\n",
      "Epoch 179/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2847e-04 - val_loss: 9.3727e-04 - lr: 3.4337e-04\n",
      "Epoch 180/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3318e-04 - val_loss: 9.4836e-04 - lr: 3.4337e-04\n",
      "Epoch 181/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2462e-04 - val_loss: 9.4544e-04 - lr: 3.4337e-04\n",
      "Epoch 182/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3273e-04 - val_loss: 9.7245e-04 - lr: 3.4337e-04\n",
      "Epoch 183/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.0973e-04 - val_loss: 9.2267e-04 - lr: 3.0903e-04\n",
      "Early Stopping\n",
      "Old Best was = \n",
      "0.0038928518\n",
      "NEW BEST is\n",
      "0.0038928029\n",
      "Old Best idx was = \n",
      "13\n",
      "NEW BEST idx is\n",
      "15\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "16\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7213e-05 - val_loss: 2.7075e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5882e-06 - val_loss: 9.5671e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3400e-07 - val_loss: 6.1722e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8502e-07 - val_loss: 4.2940e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7300e-07 - val_loss: 3.3090e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2831e-07 - val_loss: 3.5091e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0316e-07 - val_loss: 1.0541e-06 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3597e-07 - val_loss: 1.9577e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7700e-07 - val_loss: 1.6943e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5505e-07 - val_loss: 1.4592e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3875e-07 - val_loss: 1.2851e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3753e-07 - val_loss: 1.2930e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3136e-07 - val_loss: 1.1251e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6534e-07 - val_loss: 5.1641e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2875e-07 - val_loss: 9.3774e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1835e-07 - val_loss: 1.4241e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3040e-07 - val_loss: 9.0048e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.1522e-08 - val_loss: 1.0869e-07 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1503e-08 - val_loss: 7.8806e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4523e-08 - val_loss: 7.6325e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.8731e-08 - val_loss: 7.4567e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.3874e-08 - val_loss: 7.4919e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.2949e-07 - val_loss: 1.0937e-07 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4627e-07 - val_loss: 6.2914e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8507e-08 - val_loss: 5.7367e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6056e-08 - val_loss: 5.3359e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.7581e-08 - val_loss: 6.5850e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0455e-07 - val_loss: 2.8245e-07 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0905e-08 - val_loss: 4.7588e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.6048e-08 - val_loss: 5.6171e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.8254e-08 - val_loss: 4.5867e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4897e-08 - val_loss: 6.3875e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0759e-08 - val_loss: 5.1318e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0717e-08 - val_loss: 4.3679e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0790e-08 - val_loss: 3.8390e-08 - lr: 0.0090\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5322e-08 - val_loss: 5.1547e-08 - lr: 0.0090\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8129e-08 - val_loss: 3.6198e-08 - lr: 0.0090\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6037e-08 - val_loss: 4.2207e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6166e-08 - val_loss: 3.3483e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3472e-08 - val_loss: 3.2653e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.3094e-08 - val_loss: 7.6754e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7143e-07 - val_loss: 6.3387e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1078e-08 - val_loss: 3.3968e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3451e-08 - val_loss: 3.3077e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2683e-08 - val_loss: 3.3678e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0307e-08 - val_loss: 2.9842e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9374e-08 - val_loss: 2.8648e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8829e-08 - val_loss: 2.8735e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8380e-08 - val_loss: 2.9803e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0140e-08 - val_loss: 3.0855e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7103e-08 - val_loss: 2.6417e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6268e-08 - val_loss: 2.7291e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5792e-08 - val_loss: 2.6351e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5684e-08 - val_loss: 2.6318e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5431e-08 - val_loss: 2.5521e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5458e-08 - val_loss: 2.5342e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4442e-08 - val_loss: 2.4236e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4028e-08 - val_loss: 2.3679e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3652e-08 - val_loss: 2.4216e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3616e-08 - val_loss: 2.3491e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3598e-08 - val_loss: 2.3395e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2796e-08 - val_loss: 2.3475e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2598e-08 - val_loss: 2.2988e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2327e-08 - val_loss: 2.2278e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2036e-08 - val_loss: 2.2482e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1979e-08 - val_loss: 2.2217e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1644e-08 - val_loss: 2.2044e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1363e-08 - val_loss: 2.1715e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1216e-08 - val_loss: 2.2182e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1388e-08 - val_loss: 2.1667e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1079e-08 - val_loss: 2.1296e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0896e-08 - val_loss: 2.0918e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0593e-08 - val_loss: 2.1024e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0609e-08 - val_loss: 2.1227e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0275e-08 - val_loss: 2.1201e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0929e-08 - val_loss: 2.1491e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9986e-08 - val_loss: 1.9989e-08 - lr: 0.0048\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9696e-08 - val_loss: 1.9982e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9500e-08 - val_loss: 1.9659e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9564e-08 - val_loss: 1.9983e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9644e-08 - val_loss: 2.0110e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9283e-08 - val_loss: 1.9479e-08 - lr: 0.0043\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9199e-08 - val_loss: 1.9301e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8930e-08 - val_loss: 1.8944e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8803e-08 - val_loss: 1.9050e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8765e-08 - val_loss: 1.8817e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8539e-08 - val_loss: 1.8867e-08 - lr: 0.0039\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8501e-08 - val_loss: 1.8858e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8395e-08 - val_loss: 1.9135e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8322e-08 - val_loss: 1.8430e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8147e-08 - val_loss: 1.8494e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8119e-08 - val_loss: 1.8471e-08 - lr: 0.0035\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8009e-08 - val_loss: 1.8120e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7890e-08 - val_loss: 1.8138e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7862e-08 - val_loss: 1.7898e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7730e-08 - val_loss: 1.7880e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7596e-08 - val_loss: 1.7971e-08 - lr: 0.0031\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7556e-08 - val_loss: 1.7683e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7472e-08 - val_loss: 1.7526e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7468e-08 - val_loss: 1.7662e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7344e-08 - val_loss: 1.7487e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7236e-08 - val_loss: 1.7353e-08 - lr: 0.0028\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7180e-08 - val_loss: 1.7280e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7118e-08 - val_loss: 1.7220e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7111e-08 - val_loss: 1.7200e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7005e-08 - val_loss: 1.7122e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6904e-08 - val_loss: 1.7089e-08 - lr: 0.0025\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6844e-08 - val_loss: 1.7123e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6784e-08 - val_loss: 1.7055e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6873e-08 - val_loss: 1.7060e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6802e-08 - val_loss: 1.6965e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6636e-08 - val_loss: 1.6768e-08 - lr: 0.0023\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6613e-08 - val_loss: 1.6785e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6552e-08 - val_loss: 1.6745e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6536e-08 - val_loss: 1.6733e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6508e-08 - val_loss: 1.6624e-08 - lr: 0.0023\n",
      "Epoch 117/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6388e-08 - val_loss: 1.6619e-08 - lr: 0.0021\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6371e-08 - val_loss: 1.6646e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6329e-08 - val_loss: 1.6549e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6330e-08 - val_loss: 1.6507e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6259e-08 - val_loss: 1.6492e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6224e-08 - val_loss: 1.6388e-08 - lr: 0.0019\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6189e-08 - val_loss: 1.6367e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6132e-08 - val_loss: 1.6365e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6135e-08 - val_loss: 1.6322e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6110e-08 - val_loss: 1.6301e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6036e-08 - val_loss: 1.6250e-08 - lr: 0.0017\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5999e-08 - val_loss: 1.6193e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5991e-08 - val_loss: 1.6208e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5940e-08 - val_loss: 1.6118e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5910e-08 - val_loss: 1.6158e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5889e-08 - val_loss: 1.6058e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5829e-08 - val_loss: 1.6085e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5818e-08 - val_loss: 1.6071e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5806e-08 - val_loss: 1.6058e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5787e-08 - val_loss: 1.5984e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5744e-08 - val_loss: 1.5926e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5720e-08 - val_loss: 1.5907e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5685e-08 - val_loss: 1.5828e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5657e-08 - val_loss: 1.5857e-08 - lr: 0.0014\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5642e-08 - val_loss: 1.5815e-08 - lr: 0.0014\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5611e-08 - val_loss: 1.5831e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3868 - val_loss: 0.2178 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1377 - val_loss: 0.0706 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0673 - val_loss: 0.0411 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0530 - val_loss: 0.0618 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0542 - val_loss: 0.0405 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0496 - val_loss: 0.0359 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0317 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0277 - val_loss: 0.0448 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0255 - val_loss: 0.0304 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0564 - val_loss: 0.0277 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0260 - val_loss: 0.0298 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0212 - val_loss: 0.0165 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0131 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0452 - val_loss: 0.0222 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.0206 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0254 - val_loss: 0.0181 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0248 - val_loss: 0.0308 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0109 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0112 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0084 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0129 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0246 - val_loss: 0.0181 - lr: 0.0090\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0251 - val_loss: 0.0207 - lr: 0.0090\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0072 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0133 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0094 - val_loss: 0.0137 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0102 - lr: 0.0081\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0124 - val_loss: 0.0094 - lr: 0.0081\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0061 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0098 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0055 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0137 - val_loss: 0.0121 - lr: 0.0073\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0060 - lr: 0.0073\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.0105 - val_loss: 0.0219 - lr: 0.0073\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0345 - lr: 0.0073\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0217 - val_loss: 0.0114 - lr: 0.0073\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0083 - lr: 0.0066\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0057 - lr: 0.0066\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0067 - lr: 0.0066\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0068 - lr: 0.0066\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0082 - lr: 0.0066\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0062 - lr: 0.0059\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0041 - lr: 0.0059\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0078 - lr: 0.0059\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0087 - lr: 0.0059\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0115 - val_loss: 0.0117 - lr: 0.0059\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0031 - lr: 0.0053\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0058 - lr: 0.0053\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0061 - lr: 0.0053\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0081 - lr: 0.0053\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0092 - lr: 0.0053\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0140 - lr: 0.0048\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0049 - lr: 0.0048\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0039 - lr: 0.0048\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0063 - lr: 0.0048\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0025 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0050 - lr: 0.0043\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0099 - lr: 0.0043\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0047 - lr: 0.0043\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0037 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0025 - lr: 0.0039\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0044 - lr: 0.0039\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0026 - lr: 0.0035\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0048 - lr: 0.0035\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0107 - lr: 0.0035\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0064 - lr: 0.0035\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 0.0032 - lr: 0.0031\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0035 - lr: 0.0031\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0048 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0030 - lr: 0.0028\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0023 - lr: 0.0028\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0028 - lr: 0.0025\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0026 - lr: 0.0025\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0037 - lr: 0.0025\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0030 - lr: 0.0023\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0026 - lr: 0.0021\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0023 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0019\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0019\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0018 - lr: 0.0017\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.6869e-04 - val_loss: 0.0014 - lr: 0.0015\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0015\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0021 - lr: 0.0014\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0014\n",
      "Epoch 117/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1823e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.6321e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1199e-04 - val_loss: 0.0015 - lr: 0.0012\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4484e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.5099e-04 - val_loss: 0.0012 - lr: 0.0011\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0216e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9968e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.1031e-04 - val_loss: 0.0015 - lr: 0.0011\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.5685e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3808e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0501e-04 - val_loss: 0.0012 - lr: 9.8477e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.0571e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.0566e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3822e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Early Stopping\n",
      "17\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2229e-05 - val_loss: 2.5438e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4411e-06 - val_loss: 8.5363e-07 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0801e-07 - val_loss: 6.8944e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.6222e-07 - val_loss: 3.7307e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2953e-07 - val_loss: 2.9276e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6987e-07 - val_loss: 2.1657e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.3732e-07 - val_loss: 2.0790e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9981e-07 - val_loss: 1.4951e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9742e-07 - val_loss: 1.5647e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4015e-07 - val_loss: 1.2427e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9512e-07 - val_loss: 2.4206e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3301e-07 - val_loss: 9.9392e-08 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1186e-07 - val_loss: 9.6161e-08 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.0652e-07 - val_loss: 9.0984e-08 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0499e-07 - val_loss: 7.9783e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.0143e-08 - val_loss: 7.6771e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1752e-07 - val_loss: 1.7201e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9438e-08 - val_loss: 9.3716e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.6140e-08 - val_loss: 6.9884e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6533e-08 - val_loss: 9.6237e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5999e-07 - val_loss: 6.8656e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8461e-08 - val_loss: 5.6266e-08 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.7360e-08 - val_loss: 7.9091e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.0519e-08 - val_loss: 2.2289e-07 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.7876e-08 - val_loss: 5.0081e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3213e-08 - val_loss: 5.6063e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9061e-08 - val_loss: 5.3249e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3415e-08 - val_loss: 6.0990e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3343e-08 - val_loss: 6.3292e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1680e-08 - val_loss: 4.3477e-08 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1463e-07 - val_loss: 1.1668e-07 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6072e-08 - val_loss: 4.0427e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4855e-08 - val_loss: 4.1448e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9200e-08 - val_loss: 1.1488e-07 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1229e-08 - val_loss: 3.7230e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4292e-08 - val_loss: 4.1997e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7021e-08 - val_loss: 3.5167e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0114e-08 - val_loss: 6.0511e-08 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.0005e-08 - val_loss: 3.3822e-08 - lr: 0.0100\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.7273e-08 - val_loss: 3.7679e-08 - lr: 0.0100\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.3744e-08 - val_loss: 3.0777e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3218e-08 - val_loss: 3.0499e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0447e-08 - val_loss: 3.0592e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.9656e-08 - val_loss: 6.2201e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.3616e-08 - val_loss: 2.8286e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1544e-08 - val_loss: 4.8749e-08 - lr: 0.0090\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9407e-08 - val_loss: 2.6359e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7057e-08 - val_loss: 2.6428e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5951e-08 - val_loss: 2.6680e-08 - lr: 0.0081\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6145e-08 - val_loss: 2.6360e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6620e-08 - val_loss: 2.7969e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.5164e-08 - val_loss: 2.5780e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4646e-08 - val_loss: 2.4931e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4671e-08 - val_loss: 2.4302e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4099e-08 - val_loss: 2.3529e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4602e-08 - val_loss: 2.4553e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3585e-08 - val_loss: 2.3330e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3373e-08 - val_loss: 2.5148e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2541e-08 - val_loss: 2.2533e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2092e-08 - val_loss: 2.2245e-08 - lr: 0.0066\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1847e-08 - val_loss: 2.2283e-08 - lr: 0.0066\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1920e-08 - val_loss: 2.2370e-08 - lr: 0.0066\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.1838e-08 - val_loss: 2.1904e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0882e-08 - val_loss: 2.1067e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0648e-08 - val_loss: 2.1133e-08 - lr: 0.0059\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0567e-08 - val_loss: 2.0726e-08 - lr: 0.0059\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0618e-08 - val_loss: 2.0646e-08 - lr: 0.0059\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0402e-08 - val_loss: 2.0437e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0039e-08 - val_loss: 2.0464e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9877e-08 - val_loss: 2.0100e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9750e-08 - val_loss: 2.1040e-08 - lr: 0.0053\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9727e-08 - val_loss: 1.9878e-08 - lr: 0.0053\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9459e-08 - val_loss: 1.9570e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9226e-08 - val_loss: 1.9571e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9359e-08 - val_loss: 1.9338e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9152e-08 - val_loss: 1.9245e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9134e-08 - val_loss: 1.9039e-08 - lr: 0.0053\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8524e-08 - val_loss: 1.8716e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8454e-08 - val_loss: 1.8695e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8355e-08 - val_loss: 1.8987e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8212e-08 - val_loss: 1.8345e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8441e-08 - val_loss: 1.8725e-08 - lr: 0.0048\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7900e-08 - val_loss: 1.8359e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7792e-08 - val_loss: 1.8193e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7648e-08 - val_loss: 1.7949e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7640e-08 - val_loss: 1.8025e-08 - lr: 0.0043\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7604e-08 - val_loss: 1.7887e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7288e-08 - val_loss: 1.7673e-08 - lr: 0.0039\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7249e-08 - val_loss: 1.7608e-08 - lr: 0.0039\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7165e-08 - val_loss: 1.7417e-08 - lr: 0.0039\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.7072e-08 - val_loss: 1.7466e-08 - lr: 0.0039\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7098e-08 - val_loss: 1.7282e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6922e-08 - val_loss: 1.7196e-08 - lr: 0.0035\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6793e-08 - val_loss: 1.7210e-08 - lr: 0.0035\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6804e-08 - val_loss: 1.7128e-08 - lr: 0.0035\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6673e-08 - val_loss: 1.6993e-08 - lr: 0.0035\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6630e-08 - val_loss: 1.6962e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6477e-08 - val_loss: 1.6790e-08 - lr: 0.0031\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6440e-08 - val_loss: 1.6644e-08 - lr: 0.0031\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6431e-08 - val_loss: 1.6637e-08 - lr: 0.0031\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6376e-08 - val_loss: 1.6742e-08 - lr: 0.0031\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6297e-08 - val_loss: 1.6822e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6160e-08 - val_loss: 1.6542e-08 - lr: 0.0028\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6064e-08 - val_loss: 1.6440e-08 - lr: 0.0028\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6074e-08 - val_loss: 1.6424e-08 - lr: 0.0028\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6011e-08 - val_loss: 1.6289e-08 - lr: 0.0028\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5945e-08 - val_loss: 1.6154e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5844e-08 - val_loss: 1.6276e-08 - lr: 0.0025\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5801e-08 - val_loss: 1.6093e-08 - lr: 0.0025\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5792e-08 - val_loss: 1.6200e-08 - lr: 0.0025\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5741e-08 - val_loss: 1.6065e-08 - lr: 0.0025\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5670e-08 - val_loss: 1.6027e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5604e-08 - val_loss: 1.5904e-08 - lr: 0.0023\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5590e-08 - val_loss: 1.5837e-08 - lr: 0.0023\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5522e-08 - val_loss: 1.5806e-08 - lr: 0.0023\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5478e-08 - val_loss: 1.5776e-08 - lr: 0.0023\n",
      "Epoch 117/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5459e-08 - val_loss: 1.5657e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5368e-08 - val_loss: 1.5643e-08 - lr: 0.0021\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5352e-08 - val_loss: 1.5628e-08 - lr: 0.0021\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5307e-08 - val_loss: 1.5583e-08 - lr: 0.0021\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5280e-08 - val_loss: 1.5609e-08 - lr: 0.0021\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5264e-08 - val_loss: 1.5550e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5206e-08 - val_loss: 1.5422e-08 - lr: 0.0019\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5159e-08 - val_loss: 1.5438e-08 - lr: 0.0019\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5132e-08 - val_loss: 1.5396e-08 - lr: 0.0019\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5089e-08 - val_loss: 1.5476e-08 - lr: 0.0019\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5089e-08 - val_loss: 1.5305e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5022e-08 - val_loss: 1.5334e-08 - lr: 0.0017\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4998e-08 - val_loss: 1.5311e-08 - lr: 0.0017\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.4962e-08 - val_loss: 1.5253e-08 - lr: 0.0017\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.4944e-08 - val_loss: 1.5252e-08 - lr: 0.0017\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4911e-08 - val_loss: 1.5176e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4870e-08 - val_loss: 1.5174e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.4846e-08 - val_loss: 1.5115e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4846e-08 - val_loss: 1.5093e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4803e-08 - val_loss: 1.5077e-08 - lr: 0.0015\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4797e-08 - val_loss: 1.5032e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4728e-08 - val_loss: 1.5062e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3540 - val_loss: 0.2606 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1391 - val_loss: 0.0900 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0774 - val_loss: 0.0789 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0457 - val_loss: 0.0285 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0395 - val_loss: 0.1210 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0439 - val_loss: 0.0617 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0396 - val_loss: 0.0216 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0225 - val_loss: 0.0193 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0244 - val_loss: 0.0501 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0217 - val_loss: 0.0186 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0286 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0245 - val_loss: 0.0307 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0208 - val_loss: 0.0134 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0210 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0164 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0273 - val_loss: 0.0260 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0115 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0268 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0113 - val_loss: 0.0104 - lr: 0.0081\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0090 - lr: 0.0081\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0079 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0146 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0141 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0159 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0068 - lr: 0.0073\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0091 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0061 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0088 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0104 - val_loss: 0.0149 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0053 - lr: 0.0066\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0077 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0138 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0125 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0274 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0079 - lr: 0.0059\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0040 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0062 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0043 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0040 - lr: 0.0053\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0039 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0076 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0235 - val_loss: 0.0093 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0072 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0030 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0034 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0032 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0045 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0062 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0075 - lr: 0.0048\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0023 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0044 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0061 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - val_loss: 0.0025 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0084 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0028 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0038 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0032 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0037 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0029 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0051 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0100 - val_loss: 0.0065 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0034 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0026 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0022 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0037 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0024 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0022 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0019 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0023 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0065 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0040 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0019 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0014 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0018 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0024 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0027 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0015 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0017\n",
      "Early Stopping\n",
      "18\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3441e-05 - val_loss: 3.0349e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7228e-06 - val_loss: 1.0315e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6362e-07 - val_loss: 6.2136e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1540e-07 - val_loss: 4.6685e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 4.1600e-07 - val_loss: 3.3253e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0226e-07 - val_loss: 3.0923e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6630e-07 - val_loss: 2.7224e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3122e-07 - val_loss: 1.9652e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2136e-07 - val_loss: 4.0429e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1189e-07 - val_loss: 1.5450e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4776e-07 - val_loss: 1.5020e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3897e-07 - val_loss: 1.3066e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.1443e-07 - val_loss: 1.1113e-07 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5702e-07 - val_loss: 1.5231e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0771e-07 - val_loss: 9.9764e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.0649e-07 - val_loss: 1.9670e-07 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3073e-07 - val_loss: 8.9640e-08 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.3441e-08 - val_loss: 7.6696e-08 - lr: 0.0100\n",
      "Epoch 19/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 9ms/step - loss: 7.8002e-08 - val_loss: 7.5997e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3321e-07 - val_loss: 8.2143e-08 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9331e-08 - val_loss: 6.4746e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5686e-08 - val_loss: 1.9128e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4762e-07 - val_loss: 6.0841e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.7690e-08 - val_loss: 5.5595e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5517e-08 - val_loss: 6.0744e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4795e-08 - val_loss: 5.0634e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5939e-08 - val_loss: 1.0072e-07 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6180e-08 - val_loss: 4.5819e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.4461e-08 - val_loss: 1.9228e-07 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8199e-07 - val_loss: 1.1816e-07 - lr: 0.0100\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.2253e-08 - val_loss: 4.1876e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.4948e-08 - val_loss: 4.9774e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.5898e-08 - val_loss: 3.8694e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.8226e-08 - val_loss: 3.7494e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.2719e-08 - val_loss: 8.8736e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5160e-08 - val_loss: 4.3789e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.6866e-08 - val_loss: 1.2064e-07 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 5.9807e-08 - val_loss: 3.3483e-08 - lr: 0.0100\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5684e-08 - val_loss: 5.4648e-08 - lr: 0.0100\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9940e-08 - val_loss: 3.3919e-08 - lr: 0.0100\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0308e-08 - val_loss: 5.8731e-08 - lr: 0.0100\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3687e-08 - val_loss: 5.1498e-08 - lr: 0.0100\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.6262e-08 - val_loss: 3.1203e-08 - lr: 0.0100\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.2286e-08 - val_loss: 2.8237e-08 - lr: 0.0090\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.8028e-08 - val_loss: 2.8708e-08 - lr: 0.0090\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7879e-08 - val_loss: 2.8210e-08 - lr: 0.0090\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6811e-08 - val_loss: 2.7070e-08 - lr: 0.0090\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6155e-08 - val_loss: 2.6691e-08 - lr: 0.0090\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6571e-08 - val_loss: 2.5982e-08 - lr: 0.0090\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6431e-08 - val_loss: 2.6523e-08 - lr: 0.0081\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6520e-08 - val_loss: 2.5078e-08 - lr: 0.0081\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.4078e-08 - val_loss: 2.4040e-08 - lr: 0.0081\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3744e-08 - val_loss: 2.3928e-08 - lr: 0.0081\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3643e-08 - val_loss: 2.5245e-08 - lr: 0.0081\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3308e-08 - val_loss: 2.3670e-08 - lr: 0.0073\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2740e-08 - val_loss: 2.4337e-08 - lr: 0.0073\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2523e-08 - val_loss: 2.2237e-08 - lr: 0.0073\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2058e-08 - val_loss: 2.3235e-08 - lr: 0.0073\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2254e-08 - val_loss: 2.1536e-08 - lr: 0.0073\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2003e-08 - val_loss: 2.2835e-08 - lr: 0.0073\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1849e-08 - val_loss: 2.1918e-08 - lr: 0.0073\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2609e-08 - val_loss: 2.1426e-08 - lr: 0.0073\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0812e-08 - val_loss: 2.0747e-08 - lr: 0.0066\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1267e-08 - val_loss: 2.0623e-08 - lr: 0.0066\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0426e-08 - val_loss: 2.0496e-08 - lr: 0.0066\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0606e-08 - val_loss: 2.1308e-08 - lr: 0.0066\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0295e-08 - val_loss: 2.0250e-08 - lr: 0.0066\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9584e-08 - val_loss: 1.9805e-08 - lr: 0.0059\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9388e-08 - val_loss: 1.9661e-08 - lr: 0.0059\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9365e-08 - val_loss: 1.9423e-08 - lr: 0.0059\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9316e-08 - val_loss: 1.9106e-08 - lr: 0.0059\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9058e-08 - val_loss: 1.8915e-08 - lr: 0.0059\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8670e-08 - val_loss: 1.8772e-08 - lr: 0.0053\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8669e-08 - val_loss: 1.9241e-08 - lr: 0.0053\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8886e-08 - val_loss: 1.8772e-08 - lr: 0.0053\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8334e-08 - val_loss: 1.8314e-08 - lr: 0.0053\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8186e-08 - val_loss: 1.8606e-08 - lr: 0.0053\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8047e-08 - val_loss: 1.8112e-08 - lr: 0.0048\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7863e-08 - val_loss: 1.7989e-08 - lr: 0.0048\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7675e-08 - val_loss: 1.7818e-08 - lr: 0.0048\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7690e-08 - val_loss: 1.7924e-08 - lr: 0.0048\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7584e-08 - val_loss: 1.8163e-08 - lr: 0.0048\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7314e-08 - val_loss: 1.7491e-08 - lr: 0.0043\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7198e-08 - val_loss: 1.7571e-08 - lr: 0.0043\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7175e-08 - val_loss: 1.7604e-08 - lr: 0.0043\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7183e-08 - val_loss: 1.7092e-08 - lr: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7032e-08 - val_loss: 1.7550e-08 - lr: 0.0043\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6981e-08 - val_loss: 1.7358e-08 - lr: 0.0043\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6845e-08 - val_loss: 1.7093e-08 - lr: 0.0043\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6818e-08 - val_loss: 1.7279e-08 - lr: 0.0043\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6998e-08 - val_loss: 1.6930e-08 - lr: 0.0043\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6574e-08 - val_loss: 1.6845e-08 - lr: 0.0039\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6505e-08 - val_loss: 1.6611e-08 - lr: 0.0039\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6457e-08 - val_loss: 1.6527e-08 - lr: 0.0039\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6325e-08 - val_loss: 1.6414e-08 - lr: 0.0039\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6255e-08 - val_loss: 1.6536e-08 - lr: 0.0039\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6145e-08 - val_loss: 1.6346e-08 - lr: 0.0035\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6028e-08 - val_loss: 1.6249e-08 - lr: 0.0035\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5969e-08 - val_loss: 1.6155e-08 - lr: 0.0035\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5916e-08 - val_loss: 1.6026e-08 - lr: 0.0035\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5857e-08 - val_loss: 1.5981e-08 - lr: 0.0035\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5791e-08 - val_loss: 1.6006e-08 - lr: 0.0031\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5697e-08 - val_loss: 1.5925e-08 - lr: 0.0031\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5698e-08 - val_loss: 1.5945e-08 - lr: 0.0031\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5594e-08 - val_loss: 1.5785e-08 - lr: 0.0031\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5548e-08 - val_loss: 1.5738e-08 - lr: 0.0031\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5484e-08 - val_loss: 1.5656e-08 - lr: 0.0028\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5434e-08 - val_loss: 1.5571e-08 - lr: 0.0028\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5381e-08 - val_loss: 1.5571e-08 - lr: 0.0028\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5354e-08 - val_loss: 1.5562e-08 - lr: 0.0028\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5304e-08 - val_loss: 1.5424e-08 - lr: 0.0028\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5215e-08 - val_loss: 1.5461e-08 - lr: 0.0025\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5182e-08 - val_loss: 1.5333e-08 - lr: 0.0025\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.5168e-08 - val_loss: 1.5359e-08 - lr: 0.0025\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5150e-08 - val_loss: 1.5282e-08 - lr: 0.0025\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5097e-08 - val_loss: 1.5251e-08 - lr: 0.0025\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5035e-08 - val_loss: 1.5161e-08 - lr: 0.0023\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4981e-08 - val_loss: 1.5129e-08 - lr: 0.0023\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4936e-08 - val_loss: 1.5100e-08 - lr: 0.0023\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4897e-08 - val_loss: 1.5092e-08 - lr: 0.0023\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4873e-08 - val_loss: 1.5012e-08 - lr: 0.0023\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4832e-08 - val_loss: 1.4972e-08 - lr: 0.0021\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4770e-08 - val_loss: 1.4959e-08 - lr: 0.0021\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4759e-08 - val_loss: 1.4961e-08 - lr: 0.0021\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4722e-08 - val_loss: 1.4897e-08 - lr: 0.0021\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4701e-08 - val_loss: 1.4896e-08 - lr: 0.0021\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4668e-08 - val_loss: 1.4841e-08 - lr: 0.0019\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4622e-08 - val_loss: 1.4831e-08 - lr: 0.0019\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4596e-08 - val_loss: 1.4759e-08 - lr: 0.0019\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4584e-08 - val_loss: 1.4740e-08 - lr: 0.0019\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4552e-08 - val_loss: 1.4708e-08 - lr: 0.0019\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4498e-08 - val_loss: 1.4721e-08 - lr: 0.0017\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4484e-08 - val_loss: 1.4762e-08 - lr: 0.0017\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4469e-08 - val_loss: 1.4652e-08 - lr: 0.0017\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4438e-08 - val_loss: 1.4610e-08 - lr: 0.0017\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4409e-08 - val_loss: 1.4598e-08 - lr: 0.0017\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4379e-08 - val_loss: 1.4591e-08 - lr: 0.0015\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4365e-08 - val_loss: 1.4496e-08 - lr: 0.0015\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4326e-08 - val_loss: 1.4487e-08 - lr: 0.0015\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4322e-08 - val_loss: 1.4541e-08 - lr: 0.0015\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4316e-08 - val_loss: 1.4456e-08 - lr: 0.0015\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4272e-08 - val_loss: 1.4437e-08 - lr: 0.0014\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4243e-08 - val_loss: 1.4402e-08 - lr: 0.0014\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4235e-08 - val_loss: 1.4409e-08 - lr: 0.0014\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.3022 - val_loss: 0.1954 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1214 - val_loss: 0.0634 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0609 - val_loss: 0.0539 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0416 - val_loss: 0.0547 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0446 - val_loss: 0.0455 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0786 - val_loss: 0.0207 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0138 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0244 - val_loss: 0.0186 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0202 - val_loss: 0.0243 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0208 - val_loss: 0.0305 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0299 - val_loss: 0.0276 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0188 - val_loss: 0.0193 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0107 - lr: 0.0090\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0202 - lr: 0.0090\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0143 - lr: 0.0090\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.0079 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0194 - val_loss: 0.0325 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0300 - val_loss: 0.0343 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0207 - val_loss: 0.0121 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0122 - val_loss: 0.0151 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0139 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0083 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0064 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0054 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0230 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0465 - val_loss: 0.0419 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0396 - val_loss: 0.0087 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0057 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0050 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0042 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0054 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0034 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0042 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0067 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0095 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0068 - val_loss: 0.0068 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0062 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0055 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0081 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0094 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0045 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0043 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0037 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0038 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0106 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - val_loss: 0.0035 - lr: 0.0048\n",
      "Early Stopping\n",
      "19\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Train Autoencoder\n",
      "Model Compiled: AutoEncoder\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3987e-05 - val_loss: 3.4764e-06 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8932e-06 - val_loss: 1.1001e-06 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.2056e-07 - val_loss: 5.0492e-07 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9269e-07 - val_loss: 3.9699e-07 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.8369e-07 - val_loss: 3.4477e-07 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6517e-07 - val_loss: 2.3575e-07 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0537e-07 - val_loss: 2.3385e-07 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9463e-07 - val_loss: 1.7431e-07 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8188e-07 - val_loss: 1.7239e-07 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6824e-07 - val_loss: 2.3896e-07 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7948e-07 - val_loss: 1.2697e-07 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4488e-07 - val_loss: 1.1253e-07 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0736e-07 - val_loss: 9.6230e-08 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4123e-07 - val_loss: 1.3196e-07 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1523e-07 - val_loss: 9.3677e-08 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 9.1895e-08 - val_loss: 9.9053e-08 - lr: 0.0100\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0852e-07 - val_loss: 1.2662e-07 - lr: 0.0100\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 8.3849e-08 - val_loss: 7.4116e-08 - lr: 0.0100\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9493e-08 - val_loss: 6.6582e-08 - lr: 0.0100\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4230e-08 - val_loss: 1.1131e-07 - lr: 0.0100\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.9171e-08 - val_loss: 6.2042e-08 - lr: 0.0100\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.3131e-08 - val_loss: 1.4243e-07 - lr: 0.0100\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.4990e-08 - val_loss: 5.3396e-08 - lr: 0.0100\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4206e-08 - val_loss: 5.7003e-08 - lr: 0.0100\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3398e-08 - val_loss: 5.8068e-08 - lr: 0.0100\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0127e-08 - val_loss: 6.1374e-08 - lr: 0.0100\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.0733e-08 - val_loss: 7.0310e-08 - lr: 0.0100\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.2822e-08 - val_loss: 4.6105e-08 - lr: 0.0100\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.3219e-08 - val_loss: 4.8941e-08 - lr: 0.0100\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.1633e-07 - val_loss: 1.1847e-07 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5427e-08 - val_loss: 4.1857e-08 - lr: 0.0100\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.0329e-08 - val_loss: 3.9788e-08 - lr: 0.0100\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.9490e-08 - val_loss: 3.8111e-08 - lr: 0.0100\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.1914e-08 - val_loss: 5.3338e-08 - lr: 0.0100\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9717e-08 - val_loss: 4.2649e-08 - lr: 0.0100\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.4911e-08 - val_loss: 4.5760e-08 - lr: 0.0100\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 7.6331e-08 - val_loss: 5.2611e-08 - lr: 0.0100\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4904e-08 - val_loss: 3.2080e-08 - lr: 0.0090\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.5442e-08 - val_loss: 4.2371e-08 - lr: 0.0090\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 3.4362e-08 - val_loss: 3.1007e-08 - lr: 0.0090\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.4316e-08 - val_loss: 3.5485e-08 - lr: 0.0090\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.6429e-08 - val_loss: 3.6155e-08 - lr: 0.0090\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.1703e-08 - val_loss: 3.9899e-08 - lr: 0.0090\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.9191e-08 - val_loss: 2.9460e-08 - lr: 0.0081\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 3.0184e-08 - val_loss: 2.9813e-08 - lr: 0.0081\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7454e-08 - val_loss: 2.7419e-08 - lr: 0.0081\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.8935e-08 - val_loss: 2.7160e-08 - lr: 0.0081\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.7406e-08 - val_loss: 2.8302e-08 - lr: 0.0081\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.6661e-08 - val_loss: 2.5844e-08 - lr: 0.0073\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5205e-08 - val_loss: 2.6665e-08 - lr: 0.0073\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5943e-08 - val_loss: 2.5548e-08 - lr: 0.0073\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5623e-08 - val_loss: 2.5017e-08 - lr: 0.0073\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.5011e-08 - val_loss: 3.2871e-08 - lr: 0.0073\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.7092e-08 - val_loss: 2.5901e-08 - lr: 0.0073\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.4198e-08 - val_loss: 2.4270e-08 - lr: 0.0066\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3125e-08 - val_loss: 2.3600e-08 - lr: 0.0066\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3128e-08 - val_loss: 2.4904e-08 - lr: 0.0066\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2723e-08 - val_loss: 2.4712e-08 - lr: 0.0066\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.3001e-08 - val_loss: 2.3099e-08 - lr: 0.0066\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.2394e-08 - val_loss: 2.2166e-08 - lr: 0.0059\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1833e-08 - val_loss: 2.1532e-08 - lr: 0.0059\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1704e-08 - val_loss: 2.1890e-08 - lr: 0.0059\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.1204e-08 - val_loss: 2.1689e-08 - lr: 0.0059\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.2226e-08 - val_loss: 2.1729e-08 - lr: 0.0059\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 2.0699e-08 - val_loss: 2.0807e-08 - lr: 0.0053\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0790e-08 - val_loss: 2.1266e-08 - lr: 0.0053\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0722e-08 - val_loss: 2.0753e-08 - lr: 0.0053\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0222e-08 - val_loss: 2.1210e-08 - lr: 0.0053\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0580e-08 - val_loss: 2.0723e-08 - lr: 0.0053\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9903e-08 - val_loss: 2.0183e-08 - lr: 0.0053\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9690e-08 - val_loss: 2.0038e-08 - lr: 0.0048\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9614e-08 - val_loss: 1.9956e-08 - lr: 0.0048\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 2.0188e-08 - val_loss: 1.9665e-08 - lr: 0.0048\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.9321e-08 - val_loss: 1.9761e-08 - lr: 0.0048\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9193e-08 - val_loss: 1.9607e-08 - lr: 0.0048\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.9152e-08 - val_loss: 1.9240e-08 - lr: 0.0043\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8916e-08 - val_loss: 1.9308e-08 - lr: 0.0043\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8875e-08 - val_loss: 1.9171e-08 - lr: 0.0043\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.8635e-08 - val_loss: 1.8641e-08 - lr: 0.0043\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8574e-08 - val_loss: 1.8593e-08 - lr: 0.0043\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8534e-08 - val_loss: 1.8619e-08 - lr: 0.0039\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8311e-08 - val_loss: 1.8277e-08 - lr: 0.0039\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8145e-08 - val_loss: 1.8554e-08 - lr: 0.0039\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.8222e-08 - val_loss: 1.8388e-08 - lr: 0.0039\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.8084e-08 - val_loss: 1.8109e-08 - lr: 0.0039\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.7804e-08 - val_loss: 1.7960e-08 - lr: 0.0035\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7826e-08 - val_loss: 1.7958e-08 - lr: 0.0035\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7692e-08 - val_loss: 1.7945e-08 - lr: 0.0035\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.7638e-08 - val_loss: 1.7712e-08 - lr: 0.0035\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7525e-08 - val_loss: 1.7725e-08 - lr: 0.0035\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7413e-08 - val_loss: 1.7597e-08 - lr: 0.0031\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7393e-08 - val_loss: 1.7447e-08 - lr: 0.0031\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7333e-08 - val_loss: 1.7382e-08 - lr: 0.0031\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7295e-08 - val_loss: 1.7429e-08 - lr: 0.0031\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7254e-08 - val_loss: 1.7631e-08 - lr: 0.0031\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7146e-08 - val_loss: 1.7277e-08 - lr: 0.0028\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7070e-08 - val_loss: 1.7172e-08 - lr: 0.0028\n",
      "Epoch 98/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.7002e-08 - val_loss: 1.7306e-08 - lr: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 1.6932e-08 - val_loss: 1.7198e-08 - lr: 0.0028\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6976e-08 - val_loss: 1.7029e-08 - lr: 0.0028\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6803e-08 - val_loss: 1.6901e-08 - lr: 0.0025\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.6719e-08 - val_loss: 1.6833e-08 - lr: 0.0025\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6685e-08 - val_loss: 1.6987e-08 - lr: 0.0025\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6684e-08 - val_loss: 1.6858e-08 - lr: 0.0025\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6576e-08 - val_loss: 1.6808e-08 - lr: 0.0025\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6516e-08 - val_loss: 1.6679e-08 - lr: 0.0023\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6489e-08 - val_loss: 1.6677e-08 - lr: 0.0023\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6481e-08 - val_loss: 1.6683e-08 - lr: 0.0023\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6412e-08 - val_loss: 1.6570e-08 - lr: 0.0023\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6390e-08 - val_loss: 1.6535e-08 - lr: 0.0023\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6315e-08 - val_loss: 1.6418e-08 - lr: 0.0021\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6248e-08 - val_loss: 1.6464e-08 - lr: 0.0021\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6221e-08 - val_loss: 1.6332e-08 - lr: 0.0021\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6233e-08 - val_loss: 1.6318e-08 - lr: 0.0021\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6167e-08 - val_loss: 1.6297e-08 - lr: 0.0021\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6090e-08 - val_loss: 1.6343e-08 - lr: 0.0019\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6077e-08 - val_loss: 1.6289e-08 - lr: 0.0019\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6044e-08 - val_loss: 1.6237e-08 - lr: 0.0019\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6003e-08 - val_loss: 1.6133e-08 - lr: 0.0019\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.6018e-08 - val_loss: 1.6111e-08 - lr: 0.0019\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5949e-08 - val_loss: 1.6139e-08 - lr: 0.0017\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5927e-08 - val_loss: 1.6097e-08 - lr: 0.0017\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5898e-08 - val_loss: 1.6117e-08 - lr: 0.0017\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5866e-08 - val_loss: 1.5962e-08 - lr: 0.0017\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5829e-08 - val_loss: 1.5974e-08 - lr: 0.0017\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5769e-08 - val_loss: 1.5911e-08 - lr: 0.0015\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5757e-08 - val_loss: 1.5981e-08 - lr: 0.0015\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5743e-08 - val_loss: 1.5874e-08 - lr: 0.0015\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5718e-08 - val_loss: 1.5879e-08 - lr: 0.0015\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5686e-08 - val_loss: 1.5795e-08 - lr: 0.0015\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5676e-08 - val_loss: 1.5816e-08 - lr: 0.0015\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5649e-08 - val_loss: 1.5831e-08 - lr: 0.0015\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5625e-08 - val_loss: 1.5902e-08 - lr: 0.0015\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5634e-08 - val_loss: 1.5752e-08 - lr: 0.0015\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5583e-08 - val_loss: 1.5688e-08 - lr: 0.0015\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5557e-08 - val_loss: 1.5690e-08 - lr: 0.0014\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5534e-08 - val_loss: 1.5770e-08 - lr: 0.0014\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5510e-08 - val_loss: 1.5674e-08 - lr: 0.0014\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 1.5507e-08 - val_loss: 1.5655e-08 - lr: 0.0014\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5474e-08 - val_loss: 1.5673e-08 - lr: 0.0014\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.5433e-08 - val_loss: 1.5593e-08 - lr: 0.0012\n",
      "Early Stopping\n",
      "Train Emulator\n",
      "Model Compiled: AE_Emulator\n",
      "Epoch 1/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4086 - val_loss: 0.2388 - lr: 0.0100\n",
      "Epoch 2/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1648 - val_loss: 0.0974 - lr: 0.0100\n",
      "Epoch 3/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0654 - val_loss: 0.0685 - lr: 0.0100\n",
      "Epoch 4/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0531 - val_loss: 0.0386 - lr: 0.0100\n",
      "Epoch 5/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0529 - val_loss: 0.0392 - lr: 0.0100\n",
      "Epoch 6/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0344 - val_loss: 0.0474 - lr: 0.0100\n",
      "Epoch 7/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0486 - val_loss: 0.0359 - lr: 0.0100\n",
      "Epoch 8/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0350 - val_loss: 0.0304 - lr: 0.0100\n",
      "Epoch 9/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0380 - val_loss: 0.0449 - lr: 0.0100\n",
      "Epoch 10/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0313 - val_loss: 0.0223 - lr: 0.0100\n",
      "Epoch 11/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0236 - val_loss: 0.0247 - lr: 0.0100\n",
      "Epoch 12/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0221 - val_loss: 0.0457 - lr: 0.0100\n",
      "Epoch 13/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0399 - val_loss: 0.0968 - lr: 0.0100\n",
      "Epoch 14/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0477 - val_loss: 0.0365 - lr: 0.0100\n",
      "Epoch 15/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0251 - val_loss: 0.0267 - lr: 0.0100\n",
      "Epoch 16/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0122 - val_loss: 0.0085 - lr: 0.0090\n",
      "Epoch 17/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0116 - lr: 0.0090\n",
      "Epoch 18/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0232 - val_loss: 0.0506 - lr: 0.0090\n",
      "Epoch 19/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0261 - val_loss: 0.0154 - lr: 0.0090\n",
      "Epoch 20/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0221 - val_loss: 0.0112 - lr: 0.0090\n",
      "Epoch 21/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0361 - lr: 0.0090\n",
      "Epoch 22/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0092 - lr: 0.0081\n",
      "Epoch 23/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0097 - val_loss: 0.0121 - lr: 0.0081\n",
      "Epoch 24/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0112 - val_loss: 0.0118 - lr: 0.0081\n",
      "Epoch 25/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0098 - val_loss: 0.0091 - lr: 0.0081\n",
      "Epoch 26/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0093 - val_loss: 0.0118 - lr: 0.0081\n",
      "Epoch 27/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0067 - lr: 0.0073\n",
      "Epoch 28/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - val_loss: 0.0100 - lr: 0.0073\n",
      "Epoch 29/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0094 - lr: 0.0073\n",
      "Epoch 30/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0129 - val_loss: 0.0192 - lr: 0.0073\n",
      "Epoch 31/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0656 - val_loss: 0.0520 - lr: 0.0073\n",
      "Epoch 32/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0228 - val_loss: 0.0073 - lr: 0.0066\n",
      "Epoch 33/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0064 - lr: 0.0066\n",
      "Epoch 34/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0047 - lr: 0.0066\n",
      "Epoch 35/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0040 - lr: 0.0066\n",
      "Epoch 36/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0045 - lr: 0.0066\n",
      "Epoch 37/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0035 - lr: 0.0059\n",
      "Epoch 38/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0060 - lr: 0.0059\n",
      "Epoch 39/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0050 - lr: 0.0059\n",
      "Epoch 40/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0052 - lr: 0.0059\n",
      "Epoch 41/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0070 - lr: 0.0059\n",
      "Epoch 42/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0049 - lr: 0.0053\n",
      "Epoch 43/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0050 - lr: 0.0053\n",
      "Epoch 44/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0053 - lr: 0.0053\n",
      "Epoch 45/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0059 - lr: 0.0053\n",
      "Epoch 46/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0106 - lr: 0.0053\n",
      "Epoch 47/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0073 - lr: 0.0048\n",
      "Epoch 48/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0071 - lr: 0.0048\n",
      "Epoch 49/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0037 - lr: 0.0048\n",
      "Epoch 50/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0060 - lr: 0.0048\n",
      "Epoch 51/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0081 - lr: 0.0048\n",
      "Epoch 52/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0034 - lr: 0.0043\n",
      "Epoch 53/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048 - lr: 0.0043\n",
      "Epoch 54/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0061 - val_loss: 0.0071 - lr: 0.0043\n",
      "Epoch 55/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0082 - val_loss: 0.0104 - lr: 0.0043\n",
      "Epoch 56/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0072 - lr: 0.0043\n",
      "Epoch 57/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0035 - lr: 0.0043\n",
      "Epoch 58/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 59/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0033 - lr: 0.0039\n",
      "Epoch 60/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 0.0039\n",
      "Epoch 61/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0039 - lr: 0.0039\n",
      "Epoch 62/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0034 - lr: 0.0039\n",
      "Epoch 63/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0031 - lr: 0.0035\n",
      "Epoch 64/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0041 - lr: 0.0035\n",
      "Epoch 65/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0042 - lr: 0.0035\n",
      "Epoch 66/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0023 - lr: 0.0035\n",
      "Epoch 67/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0039 - lr: 0.0035\n",
      "Epoch 68/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0060 - lr: 0.0031\n",
      "Epoch 69/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0028 - lr: 0.0031\n",
      "Epoch 70/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0031 - lr: 0.0031\n",
      "Epoch 71/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0039 - lr: 0.0031\n",
      "Epoch 72/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0048 - lr: 0.0031\n",
      "Epoch 73/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0029 - lr: 0.0028\n",
      "Epoch 74/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0028 - lr: 0.0028\n",
      "Epoch 75/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0028\n",
      "Epoch 76/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0027 - lr: 0.0028\n",
      "Epoch 77/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0026 - lr: 0.0028\n",
      "Epoch 78/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0028 - lr: 0.0025\n",
      "Epoch 79/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0023 - lr: 0.0025\n",
      "Epoch 80/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0029 - lr: 0.0025\n",
      "Epoch 81/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0038 - lr: 0.0025\n",
      "Epoch 82/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0030 - lr: 0.0025\n",
      "Epoch 83/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0020 - lr: 0.0023\n",
      "Epoch 84/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0023\n",
      "Epoch 85/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0025 - lr: 0.0023\n",
      "Epoch 86/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0022 - lr: 0.0023\n",
      "Epoch 87/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0019 - val_loss: 0.0026 - lr: 0.0023\n",
      "Epoch 88/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0033 - lr: 0.0021\n",
      "Epoch 89/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0021 - lr: 0.0021\n",
      "Epoch 90/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0021\n",
      "Epoch 91/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0024 - lr: 0.0021\n",
      "Epoch 92/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0021\n",
      "Epoch 93/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0024 - lr: 0.0019\n",
      "Epoch 94/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0020 - lr: 0.0019\n",
      "Epoch 95/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 96/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0019\n",
      "Epoch 97/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0017 - val_loss: 0.0021 - lr: 0.0019\n",
      "Epoch 98/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0016 - lr: 0.0017\n",
      "Epoch 99/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0022 - lr: 0.0017\n",
      "Epoch 100/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0040 - lr: 0.0017\n",
      "Epoch 101/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0017 - lr: 0.0017\n",
      "Epoch 102/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0020 - lr: 0.0017\n",
      "Epoch 103/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0019 - lr: 0.0015\n",
      "Epoch 104/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 105/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0015\n",
      "Epoch 106/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0015\n",
      "Epoch 107/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0015\n",
      "Epoch 108/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 109/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.2269e-04 - val_loss: 0.0015 - lr: 0.0014\n",
      "Epoch 110/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0014\n",
      "Epoch 111/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0026 - lr: 0.0014\n",
      "Epoch 112/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0025 - lr: 0.0014\n",
      "Epoch 113/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 114/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0012\n",
      "Epoch 115/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4181e-04 - val_loss: 0.0013 - lr: 0.0012\n",
      "Epoch 116/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0012\n",
      "Epoch 117/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0017 - lr: 0.0012\n",
      "Epoch 118/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.4140e-04 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 119/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9958e-04 - val_loss: 0.0015 - lr: 0.0011\n",
      "Epoch 120/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.3038e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 121/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0011\n",
      "Epoch 122/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.9519e-04 - val_loss: 0.0013 - lr: 0.0011\n",
      "Epoch 123/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 9.8477e-04\n",
      "Epoch 124/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 9.5949e-04 - val_loss: 0.0014 - lr: 9.8477e-04\n",
      "Epoch 125/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0019 - lr: 9.8477e-04\n",
      "Epoch 126/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.9005e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 127/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.5187e-04 - val_loss: 0.0013 - lr: 9.8477e-04\n",
      "Epoch 128/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.5182e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 129/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.5573e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 130/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.6125e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 131/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9952e-04 - val_loss: 0.0012 - lr: 8.8629e-04\n",
      "Epoch 132/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.8250e-04 - val_loss: 0.0013 - lr: 8.8629e-04\n",
      "Epoch 133/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.1598e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 134/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.7821e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 135/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 8.6649e-04 - val_loss: 0.0014 - lr: 7.9766e-04\n",
      "Epoch 136/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.9951e-04 - val_loss: 0.0013 - lr: 7.9766e-04\n",
      "Epoch 137/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1830e-04 - val_loss: 0.0012 - lr: 7.9766e-04\n",
      "Epoch 138/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.2432e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 139/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.9124e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 140/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 7.0096e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 141/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 7.3326e-04 - val_loss: 0.0012 - lr: 7.1790e-04\n",
      "Epoch 142/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 8.1923e-04 - val_loss: 0.0013 - lr: 7.1790e-04\n",
      "Epoch 143/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.8638e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 144/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4093e-04 - val_loss: 0.0011 - lr: 6.4611e-04\n",
      "Epoch 145/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 6.6504e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 146/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3771e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 147/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.4624e-04 - val_loss: 0.0012 - lr: 6.4611e-04\n",
      "Epoch 148/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.3737e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 149/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9891e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 150/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9881e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 151/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2756e-04 - val_loss: 0.0011 - lr: 5.8150e-04\n",
      "Epoch 152/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.6454e-04 - val_loss: 0.0012 - lr: 5.8150e-04\n",
      "Epoch 153/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.1075e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 154/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.8358e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 155/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9792e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 156/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.0966e-04 - val_loss: 0.0010 - lr: 5.2335e-04\n",
      "Epoch 157/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 6.2346e-04 - val_loss: 0.0011 - lr: 5.2335e-04\n",
      "Epoch 158/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6671e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 159/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.6410e-04 - val_loss: 0.0011 - lr: 4.7101e-04\n",
      "Epoch 160/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.9426e-04 - val_loss: 0.0012 - lr: 4.7101e-04\n",
      "Epoch 161/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.8086e-04 - val_loss: 0.0010 - lr: 4.7101e-04\n",
      "Epoch 162/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5070e-04 - val_loss: 0.0012 - lr: 4.7101e-04\n",
      "Epoch 163/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.7018e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 164/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.3213e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 165/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4542e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 166/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.5604e-04 - val_loss: 0.0011 - lr: 4.2391e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.5734e-04 - val_loss: 0.0010 - lr: 4.2391e-04\n",
      "Epoch 168/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.2830e-04 - val_loss: 9.8101e-04 - lr: 3.8152e-04\n",
      "Epoch 169/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.1634e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 170/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4398e-04 - val_loss: 0.0010 - lr: 3.8152e-04\n",
      "Epoch 171/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.1920e-04 - val_loss: 9.8746e-04 - lr: 3.8152e-04\n",
      "Epoch 172/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 5.4128e-04 - val_loss: 9.9897e-04 - lr: 3.8152e-04\n",
      "Epoch 173/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9214e-04 - val_loss: 9.7430e-04 - lr: 3.4337e-04\n",
      "Epoch 174/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9286e-04 - val_loss: 0.0010 - lr: 3.4337e-04\n",
      "Epoch 175/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 4.9495e-04 - val_loss: 9.8667e-04 - lr: 3.4337e-04\n",
      "Epoch 176/350\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 5.2492e-04 - val_loss: 0.0011 - lr: 3.4337e-04\n",
      "Epoch 177/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9609e-04 - val_loss: 9.8258e-04 - lr: 3.4337e-04\n",
      "Epoch 178/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8757e-04 - val_loss: 9.3559e-04 - lr: 3.0903e-04\n",
      "Epoch 179/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8523e-04 - val_loss: 0.0011 - lr: 3.0903e-04\n",
      "Epoch 180/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.9559e-04 - val_loss: 9.6680e-04 - lr: 3.0903e-04\n",
      "Epoch 181/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8040e-04 - val_loss: 9.4583e-04 - lr: 3.0903e-04\n",
      "Epoch 182/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.8094e-04 - val_loss: 0.0010 - lr: 3.0903e-04\n",
      "Epoch 183/350\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 4.7428e-04 - val_loss: 9.7871e-04 - lr: 2.7813e-04\n",
      "Early Stopping\n",
      "Old Best was = \n",
      "0.0038928029\n",
      "NEW BEST is\n",
      "0.0038806251\n",
      "Old Best idx was = \n",
      "15\n",
      "NEW BEST idx is\n",
      "19\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "errs = np.empty((20, 1704))\n",
    "ae_errs = np.empty((20, 1704))\n",
    "BEST_RES = 1000\n",
    "BEST_IDX = 0\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    ae_emulator = VAE.AutoEncoderEmulator()\n",
    "    ae_emulator.train()\n",
    "    rmse = ae_emulator.compute_rms_error()\n",
    "    errs[i] = rmse\n",
    "    rmse_auto = ae_emulator.compute_rms_error(use_autoencoder=True)\n",
    "    ae_errs[i] = rmse_auto\n",
    "    if i == 0:\n",
    "        BEST_RES = rmse.mean()\n",
    "        ae_emulator.emulator.save('../RESULTS/ae_res_nov9/em0.h5')\n",
    "        ae_emulator.encoder.save('../RESULTS/ae_res_nov9/en0.h5')\n",
    "        ae_emulator.decoder.save('../RESULTS/ae_res_nov9/de0.h5')\n",
    "        ae_emulator.autoencoder.save('../RESULTS/ae_res_nov9/ae0.h5')\n",
    "    elif rmse.mean() < BEST_RES:\n",
    "        print('Old Best was = ')\n",
    "        print(BEST_RES)\n",
    "        BEST_RES = rmse.mean()\n",
    "        print('NEW BEST is')\n",
    "        print(BEST_RES)\n",
    "        print('Old Best idx was = ')\n",
    "        print(BEST_IDX)\n",
    "        BEST_IDX = i\n",
    "        print('NEW BEST idx is')\n",
    "        print(BEST_IDX)\n",
    "        ae_emulator.emulator.save('../RESULTS/ae_res_nov9/em'+str(i)+'.h5')\n",
    "        ae_emulator.encoder.save('../RESULTS/ae_res_nov9/en'+str(i)+'.h5')\n",
    "        ae_emulator.decoder.save('../RESULTS/ae_res_nov9/de'+str(i)+'.h5')\n",
    "        ae_emulator.autoencoder.save('../RESULTS/ae_res_nov9/ae'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038806251\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(BEST_RES)\n",
    "print(BEST_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('emerr.npy', errs)\n",
    "np.save('aeerr.npy', ae_errs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emulator_env] *",
   "language": "python",
   "name": "conda-env-emulator_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
